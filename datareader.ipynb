{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9d9fa73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”‘ Top-level keys: ['action', 'is_edited', 'language_raw', 'observations']\n",
      "ğŸ” [observations] ë‚´ë¶€ key ëª©ë¡: ['images', 'qpos', 'qvel']\n",
      "ğŸ“ images is a Group â†’ ë‚´ë¶€ key ëª©ë¡: ['left', 'right', 'wrist']\n",
      "âœ… qpos shape: (142, 10)\n",
      "âœ… qvel shape: (142, 10)\n",
      "(142, 10)\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "\n",
    "h5_path = \"/home/parkjeongsu/TinyVLA/Droid/droid_with_lang/droid_1dot7t_lang_succ_t0001_s-0-0/episode_2.hdf5\"\n",
    "\n",
    "with h5py.File(h5_path, 'r') as f:\n",
    "    print(\"ğŸ”‘ Top-level keys:\", list(f.keys()))\n",
    "\n",
    "    obs = f[\"observations\"]\n",
    "    print(\"ğŸ” [observations] ë‚´ë¶€ key ëª©ë¡:\", list(obs.keys()))\n",
    "\n",
    "    for k in obs.keys():\n",
    "        item = obs[k]\n",
    "        if isinstance(item, h5py.Dataset):\n",
    "            print(f\"âœ… {k} shape:\", item.shape)\n",
    "        elif isinstance(item, h5py.Group):\n",
    "            print(f\"ğŸ“ {k} is a Group â†’ ë‚´ë¶€ key ëª©ë¡:\", list(item.keys()))\n",
    "\n",
    "    print(f['action'].shape)  # â† ì´ê²Œ ë°”ë¡œ 10ì°¨ì›ì´ ë˜ì–´ì•¼ í•¨\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1390dc30",
   "metadata": {},
   "source": [
    "í…ì„œí”Œë¡œìš° ë°ì´í„°ì…‹ ì½ëŠ” ì½”ë“œì…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2bf4fc10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top keys: ['action', 'action_dict', 'discount', 'is_first', 'is_last', 'is_terminal', 'language_instruction', 'language_instruction_2', 'language_instruction_3', 'observation', 'reward']\n",
      "obs keys: ['cartesian_position', 'exterior_image_1_left', 'exterior_image_2_left', 'gripper_position', 'joint_position', 'wrist_image_left']\n",
      "action_dict keys: ['cartesian_position', 'cartesian_velocity', 'gripper_position', 'gripper_velocity', 'joint_position', 'joint_velocity']\n",
      "shapes -> actions: (166, 7) qpos: (166, 7) qvel: (166, 7)\n",
      "velocityâ†’pos scale â‰ˆ 0.058800539014447616\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# 1) ë¹Œë” & ë°ì´í„°ì…‹\n",
    "builder = tfds.builder_from_directory(\"/home/parkjeongsu/TinyVLA/Droid/droid_100/1.0.0\")\n",
    "ds = builder.as_dataset(split=\"train\")  # tf.data.Dataset (episode ë‹¨ìœ„)\n",
    "\n",
    "# 2) í•œ ì—í”¼ì†Œë“œ ë½‘ê¸° (ì—¬ê¸´ tf.data ê·¸ëŒ€ë¡œ)\n",
    "episode = next(iter(ds))\n",
    "steps_ds = episode[\"steps\"]             # ì—¬ì „íˆ tf.data.Dataset\n",
    "\n",
    "# 3) ì²« ìŠ¤í…ë§Œ numpyë¡œ í™•ì¸\n",
    "to_numpy = lambda x: x.numpy()\n",
    "first_tf = next(iter(steps_ds))\n",
    "first = tf.nest.map_structure(to_numpy, first_tf)\n",
    "\n",
    "print(\"top keys:\", list(first.keys()))\n",
    "print(\"obs keys:\", list(first[\"observation\"].keys()))\n",
    "print(\"action_dict keys:\", list(first[\"action_dict\"].keys()))\n",
    "\n",
    "# 4) ì „ ìŠ¤í…ì„ numpy dictë¡œ ìˆ˜ì§‘\n",
    "steps = [tf.nest.map_structure(to_numpy, s) for s in steps_ds]\n",
    "\n",
    "# 5) ì•ˆì „ ì¶”ì¶œ í—¬í¼\n",
    "def get_nested(d, *path):\n",
    "    cur = d\n",
    "    for k in path:\n",
    "        if isinstance(cur, dict) and k in cur:\n",
    "            cur = cur[k]\n",
    "        else:\n",
    "            return None\n",
    "    return cur\n",
    "\n",
    "# 6) ë°°ì—´í™”\n",
    "actions = np.stack([s[\"action\"] for s in steps])  # (T, 7) or (T, ?)\n",
    "qpos    = np.stack([get_nested(s, \"observation\", \"joint_position\") for s in steps])\n",
    "\n",
    "# qvel ìš°ì„ ìˆœìœ„: observation.joint_velocity -> action_dict.joint_velocity -> finite diff\n",
    "qvel_list = [get_nested(s, \"observation\", \"joint_velocity\") for s in steps]\n",
    "if qvel_list[0] is None:\n",
    "    qvel_list = [get_nested(s, \"action_dict\", \"joint_velocity\") for s in steps]\n",
    "\n",
    "if qvel_list[0] is None:\n",
    "    qvel = np.diff(qpos, axis=0, prepend=qpos[:1])  # dt=1 ê°€ì •\n",
    "else:\n",
    "    qvel = np.stack(qvel_list)\n",
    "\n",
    "print(\"shapes -> actions:\", actions.shape, \"qpos:\", qpos.shape, \"qvel:\", qvel.shape)\n",
    "\n",
    "# 1) action ì„ íƒ: joint velocityë¥¼ ì‚¬ìš©\n",
    "a = np.stack([s[\"action_dict\"][\"joint_velocity\"] for s in steps])   # (T,7)\n",
    "q = np.stack([s[\"observation\"][\"joint_position\"] for s in steps])   # (T,7)\n",
    "q_next = np.roll(q, -1, axis=0)[:-1]\n",
    "a_t = a[:-1]\n",
    "q_t = q[:-1]\n",
    "\n",
    "# 2) dt ì¶”ì •(ëŒ€ëµ): ìµœì†ŒììŠ¹ìœ¼ë¡œ q_next - q â‰ˆ dt * a\n",
    "dt_hat = np.linalg.lstsq(a_t.reshape(-1,7), (q_next - q_t).reshape(-1,7), rcond=None)[0]\n",
    "# dt_hatì€ 7x7ì´ ë‚˜ì˜¬ ìˆ˜ ìˆìœ¼ë‹ˆ í‰ê·  ìŠ¤ì¼€ì¼ë§Œ ì“°ë ¤ë©´:\n",
    "scale = np.mean(np.diag(dt_hat))  # ê°„ë‹¨ ì¶”ì •\n",
    "print(\"velocityâ†’pos scale â‰ˆ\", scale)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ae3a087",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-12 07:19:47.575274: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-08-12 07:19:47.704289: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-08-12 07:19:48.315855: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-08-12 07:19:48.977170: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-08-12 07:19:49.066877: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-08-12 07:19:49.067025: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-08-12 07:19:49.068259: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-08-12 07:19:49.068369: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-08-12 07:19:49.068436: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-08-12 07:19:49.542616: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-08-12 07:19:49.542752: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-08-12 07:19:49.542816: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-08-12 07:19:49.542889: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9883 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfds.core.DatasetInfo(\n",
      "    name='r2d2_faceblur',\n",
      "    full_name='r2d2_faceblur/1.0.0',\n",
      "    description=\"\"\"\n",
      "    \n",
      "    \"\"\",\n",
      "    homepage='https://www.tensorflow.org/datasets/catalog/r2d2_faceblur',\n",
      "    data_path='/home/parkjeongsu/TinyVLA/Droid/droid_100/1.0.0',\n",
      "    file_format=tfrecord,\n",
      "    download_size=Unknown size,\n",
      "    dataset_size=2.04 GiB,\n",
      "    features=FeaturesDict({\n",
      "        'episode_metadata': FeaturesDict({\n",
      "            'file_path': string,\n",
      "            'recording_folderpath': string,\n",
      "        }),\n",
      "        'steps': Dataset({\n",
      "            'action': Tensor(shape=(7,), dtype=float64),\n",
      "            'action_dict': FeaturesDict({\n",
      "                'cartesian_position': Tensor(shape=(6,), dtype=float64),\n",
      "                'cartesian_velocity': Tensor(shape=(6,), dtype=float64),\n",
      "                'gripper_position': Tensor(shape=(1,), dtype=float64),\n",
      "                'gripper_velocity': Tensor(shape=(1,), dtype=float64),\n",
      "                'joint_position': Tensor(shape=(7,), dtype=float64),\n",
      "                'joint_velocity': Tensor(shape=(7,), dtype=float64),\n",
      "            }),\n",
      "            'discount': Scalar(shape=(), dtype=float32),\n",
      "            'is_first': bool,\n",
      "            'is_last': bool,\n",
      "            'is_terminal': bool,\n",
      "            'language_instruction': string,\n",
      "            'language_instruction_2': string,\n",
      "            'language_instruction_3': string,\n",
      "            'observation': FeaturesDict({\n",
      "                'cartesian_position': Tensor(shape=(6,), dtype=float64),\n",
      "                'exterior_image_1_left': Image(shape=(180, 320, 3), dtype=uint8),\n",
      "                'exterior_image_2_left': Image(shape=(180, 320, 3), dtype=uint8),\n",
      "                'gripper_position': Tensor(shape=(1,), dtype=float64),\n",
      "                'joint_position': Tensor(shape=(7,), dtype=float64),\n",
      "                'wrist_image_left': Image(shape=(180, 320, 3), dtype=uint8),\n",
      "            }),\n",
      "            'reward': Scalar(shape=(), dtype=float32),\n",
      "        }),\n",
      "    }),\n",
      "    supervised_keys=None,\n",
      "    disable_shuffling=False,\n",
      "    splits={\n",
      "        'train': <SplitInfo num_examples=100, num_shards=31>,\n",
      "    },\n",
      "    citation=\"\"\"\"\"\",\n",
      ")\n",
      "dict_keys(['episode_metadata', 'steps'])\n",
      "=== Episode í™•ì¸ ===\n",
      "\n",
      "Step 0\n",
      "qpos: [ 0.15790215 -0.59770739 -0.00894702 -2.39099431  0.26069394  1.98183966\n",
      " -0.08346987]\n",
      "gripper_position: [0.]\n",
      "qpos ë§ˆì§€ë§‰ ê°’: -0.08346986770629883\n",
      "ê°™ì€ê°€?: False\n",
      "\n",
      "Step 165\n",
      "qpos: [ 0.37792704  0.1255217  -0.32022804 -2.54504514 -0.5308491   3.09443974\n",
      "  0.38908491]\n",
      "gripper_position: [0.]\n",
      "qpos ë§ˆì§€ë§‰ ê°’: 0.38908490538597107\n",
      "ê°™ì€ê°€?: False\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "builder = tfds.builder_from_directory(\"/home/parkjeongsu/TinyVLA/Droid/droid_100/1.0.0\")  # 'droid_100' ë£¨íŠ¸(ê·¸ ì•„ë˜ 1.0.0/ ì¡´ì¬)\n",
    "ds = builder.as_dataset(split=\"train\")\n",
    "info = builder.info\n",
    "print(info)\n",
    "for i, ex in enumerate(ds.take(1)):\n",
    "    print(ex.keys())\n",
    "\n",
    "# ì²« ë²ˆì§¸ episode í•˜ë‚˜ë§Œ í™•ì¸\n",
    "for episode in ds.take(1):\n",
    "    print(\"=== Episode í™•ì¸ ===\")\n",
    "    for idx, step in enumerate(episode['steps']):\n",
    "        qpos = step['observation']['joint_position'].numpy()  # (7,)\n",
    "        gripper_pos = step['observation']['gripper_position'].numpy()  # (1,)\n",
    "\n",
    "        if idx in [0, len(episode['steps'])-1]:  # ì²« ìŠ¤í…, ë§ˆì§€ë§‰ ìŠ¤í…ë§Œ\n",
    "            print(f\"\\nStep {idx}\")\n",
    "            print(\"qpos:\", qpos)\n",
    "            print(\"gripper_position:\", gripper_pos)\n",
    "            print(\"qpos ë§ˆì§€ë§‰ ê°’:\", qpos[-1])\n",
    "            print(\"ê°™ì€ê°€?:\", np.allclose(qpos[-1], gripper_pos[0], atol=1e-6))\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e29a356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfds.core.DatasetInfo(\n",
      "    name='r2d2_faceblur',\n",
      "    full_name='r2d2_faceblur/1.0.0',\n",
      "    description=\"\"\"\n",
      "    \n",
      "    \"\"\",\n",
      "    homepage='https://www.tensorflow.org/datasets/catalog/r2d2_faceblur',\n",
      "    data_path='/home/parkjeongsu/TinyVLA/Droid/droid_100/1.0.0',\n",
      "    file_format=tfrecord,\n",
      "    download_size=Unknown size,\n",
      "    dataset_size=2.04 GiB,\n",
      "    features=FeaturesDict({\n",
      "        'episode_metadata': FeaturesDict({\n",
      "            'file_path': string,\n",
      "            'recording_folderpath': string,\n",
      "        }),\n",
      "        'steps': Dataset({\n",
      "            'action': Tensor(shape=(7,), dtype=float64),\n",
      "            'action_dict': FeaturesDict({\n",
      "                'cartesian_position': Tensor(shape=(6,), dtype=float64),\n",
      "                'cartesian_velocity': Tensor(shape=(6,), dtype=float64),\n",
      "                'gripper_position': Tensor(shape=(1,), dtype=float64),\n",
      "                'gripper_velocity': Tensor(shape=(1,), dtype=float64),\n",
      "                'joint_position': Tensor(shape=(7,), dtype=float64),\n",
      "                'joint_velocity': Tensor(shape=(7,), dtype=float64),\n",
      "            }),\n",
      "            'discount': Scalar(shape=(), dtype=float32),\n",
      "            'is_first': bool,\n",
      "            'is_last': bool,\n",
      "            'is_terminal': bool,\n",
      "            'language_instruction': string,\n",
      "            'language_instruction_2': string,\n",
      "            'language_instruction_3': string,\n",
      "            'observation': FeaturesDict({\n",
      "                'cartesian_position': Tensor(shape=(6,), dtype=float64),\n",
      "                'exterior_image_1_left': Image(shape=(180, 320, 3), dtype=uint8),\n",
      "                'exterior_image_2_left': Image(shape=(180, 320, 3), dtype=uint8),\n",
      "                'gripper_position': Tensor(shape=(1,), dtype=float64),\n",
      "                'joint_position': Tensor(shape=(7,), dtype=float64),\n",
      "                'wrist_image_left': Image(shape=(180, 320, 3), dtype=uint8),\n",
      "            }),\n",
      "            'reward': Scalar(shape=(), dtype=float32),\n",
      "        }),\n",
      "    }),\n",
      "    supervised_keys=None,\n",
      "    disable_shuffling=False,\n",
      "    splits={\n",
      "        'train': <SplitInfo num_examples=100, num_shards=31>,\n",
      "    },\n",
      "    citation=\"\"\"\"\"\",\n",
      ")\n",
      "dict_keys(['episode_metadata', 'steps'])\n",
      "=== Episode í™•ì¸ ===\n",
      "\n",
      "Step 0\n",
      "joint_position: [ 1.43628523e-01 -5.97331285e-01  2.01173499e-03 -2.38619041e+00\n",
      "  2.67941624e-01  1.97807848e+00 -8.98026153e-02]\n",
      "joint_velocity: [-0.07136133  0.00333801  0.05471271  0.0106786   0.03623825 -0.01887485\n",
      " -0.03163311]\n",
      "joint_position ë§ˆì§€ë§‰ ê°’: -0.08980261534452438\n",
      "\n",
      "Step 165\n",
      "joint_position: [ 0.37776577  0.12551776 -0.32008415 -2.54504895 -0.53084087  3.09443617\n",
      "  0.38903838]\n",
      "joint_velocity: [0. 0. 0. 0. 0. 0. 0.]\n",
      "joint_position ë§ˆì§€ë§‰ ê°’: 0.3890383839607239\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "builder = tfds.builder_from_directory(\"/home/parkjeongsu/TinyVLA/Droid/droid_100/1.0.0\")  # 'droid_100' ë£¨íŠ¸(ê·¸ ì•„ë˜ 1.0.0/ ì¡´ì¬)\n",
    "ds = builder.as_dataset(split=\"train\")\n",
    "info = builder.info\n",
    "print(info)\n",
    "for i, ex in enumerate(ds.take(1)):\n",
    "    print(ex.keys())\n",
    "\n",
    "# ì²« ë²ˆì§¸ episode í•˜ë‚˜ë§Œ í™•ì¸\n",
    "for episode in ds.take(2):\n",
    "    print(\"=== Episode í™•ì¸ ===\")\n",
    "    for idx, step in enumerate(episode['steps']):\n",
    "        c_pos = step['action_dict']['joint_position'].numpy()  # (7,)\n",
    "        gripper_pos = step['action_dict']['joint_velocity'].numpy()  # (1,)\n",
    "\n",
    "        if idx in [0, len(episode['steps'])-1]:  # ì²« ìŠ¤í…, ë§ˆì§€ë§‰ ìŠ¤í…ë§Œ\n",
    "            print(f\"\\nStep {idx}\")\n",
    "            print(\"joint_position:\", c_pos)\n",
    "            print(\"joint_velocity:\", gripper_pos)\n",
    "            print(\"joint_position ë§ˆì§€ë§‰ ê°’:\", c_pos[-1])\n",
    "      \n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5adb63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== episode top-level values ===\n",
      "episode_metadata:\n",
      "  file_path: /nfs/kun2/datasets/r2d2/r2d2-data-full/RAIL/success/2023-04-17/Mon_Apr_17_14:48:05_2023/trajectory.h5\n",
      "  recording_folderpath: /nfs/kun2/datasets/r2d2/r2d2-data-full/RAIL/success/2023-04-17/Mon_Apr_17_14:48:05_2023/recordings/MP4\n",
      "steps: <_VariantDataset element_spec={'action': TensorSpec(shape=(7,), dtype=tf.float64, name=None), 'action_dict': {'cartesian_position': TensorSpec(shape=(6,), dtype=tf.float64, name=None), 'cartesian_velo...\n",
      "\n",
      "=== steps values (first 10 steps) ===\n",
      "\n",
      "--- step 0 ---\n",
      "  action: [0.38357484340667725, 0.07346952706575394, 0.5513594150543213, -2.8934216499328613, -0.1987120658159256, 0.12699034810066223, 0.0]\n",
      "  action_dict:\n",
      "    cartesian_position: [0.38357484340667725, 0.07346952706575394, 0.5513594150543213, -2.8934216499328613, -0.1987120658159256, 0.12699034810066223]\n",
      "    cartesian_velocity: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "    gripper_position: [0.0]\n",
      "    gripper_velocity: [0.0]\n",
      "    joint_position: [0.14362852275371552, -0.5973312854766846, 0.0020117349922657013, -2.386190414428711, 0.2679416239261627, 1.9780784845352173, -0.08980261534452438]\n",
      "    joint_velocity: [-0.07136133313179016, 0.0033380109816789627, 0.05471270903944969, 0.01067859586328268, 0.036238253116607666, -0.01887485384941101, -0.03163310885429382]\n",
      "  discount: 1.0\n",
      "  is_first: True\n",
      "  is_last: False\n",
      "  is_terminal: False\n",
      "  language_instruction: Put the marker in the pot\n",
      "  language_instruction_2: Get the marker from the table and put it inside the silver pot\n",
      "  language_instruction_3: Put the marker inside the silver pot\n",
      "  observation:\n",
      "    cartesian_position: [0.3833988308906555, 0.07344377785921097, 0.5499107241630554, -2.893483877182007, -0.19573815166950226, 0.12700165808200836]\n",
      "    exterior_image_1_left: [217, 235, 247, 216, 234, 246, 215, 235, 246, 215, 235, 246, 213, 233, 244, 213, 233, 244, 215, 235] ... (+172780)\n",
      "    exterior_image_2_left: [26, 28, 53, 23, 29, 53, 16, 30, 56, 15, 31, 54, 17, 32, 53, 22, 34, 56, 26, 36] ... (+172780)\n",
      "    gripper_position: [0.0]\n",
      "    joint_position: [0.15790215134620667, -0.5977073907852173, -0.008947020396590233, -2.3909943103790283, 0.2606939375400543, 1.981839656829834, -0.08346986770629883]\n",
      "    wrist_image_left: [154, 95, 61, 151, 93, 56, 157, 97, 60, 155, 96, 54, 162, 99, 55, 161, 99, 52, 162, 98] ... (+172780)\n",
      "  reward: 0.0\n",
      "\n",
      "--- step 1 ---\n",
      "  action: [0.38375794887542725, 0.07347417622804642, 0.5525535941123962, -2.8933467864990234, -0.20112468302249908, 0.1269303858280182, 0.0]\n",
      "  action_dict:\n",
      "    cartesian_position: [0.38375794887542725, 0.07347417622804642, 0.5525535941123962, -2.8933467864990234, -0.20112468302249908, 0.1269303858280182]\n",
      "    cartesian_velocity: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "    gripper_position: [0.0]\n",
      "    gripper_velocity: [0.0]\n",
      "    joint_position: [0.1436219960451126, -0.597432017326355, 0.0019641146063804626, -2.383871555328369, 0.2679431140422821, 1.9780683517456055, -0.08979938924312592]\n",
      "    joint_velocity: [-0.07135948538780212, 0.003370370017364621, 0.05463128909468651, 0.010757146403193474, 0.03625338152050972, -0.018943889066576958, -0.03161720186471939]\n",
      "  discount: 1.0\n",
      "  is_first: False\n",
      "  is_last: False\n",
      "  is_terminal: False\n",
      "  language_instruction: Put the marker in the pot\n",
      "  language_instruction_2: Get the marker from the table and put it inside the silver pot\n",
      "  language_instruction_3: Put the marker inside the silver pot\n",
      "  observation:\n",
      "    cartesian_position: [0.3835889995098114, 0.07346737384796143, 0.5514423847198486, -2.8934125900268555, -0.19887904822826385, 0.12697435915470123]\n",
      "    exterior_image_1_left: [216, 236, 247, 215, 235, 246, 216, 236, 247, 216, 236, 247, 214, 234, 245, 214, 234, 245, 214, 237] ... (+172780)\n",
      "    exterior_image_2_left: [23, 28, 58, 21, 28, 56, 16, 31, 54, 18, 33, 52, 24, 32, 53, 26, 33, 52, 28, 34] ... (+172780)\n",
      "    gripper_position: [0.0]\n",
      "    joint_position: [0.1578986793756485, -0.5980038046836853, -0.008937465026974678, -2.388164520263672, 0.26069435477256775, 1.9818555116653442, -0.08347058296203613]\n",
      "    wrist_image_left: [156, 94, 55, 159, 97, 58, 160, 97, 56, 160, 97, 56, 162, 99, 56, 161, 98, 55, 159, 96] ... (+172780)\n",
      "  reward: 0.0\n",
      "\n",
      "--- step 2 ---\n",
      "  action: [0.38265907764434814, 0.07552027702331543, 0.5495209693908691, -2.895186424255371, -0.20202067494392395, 0.12307539582252502, 0.0]\n",
      "  action_dict:\n",
      "    cartesian_position: [0.38265907764434814, 0.07552027702331543, 0.5495209693908691, -2.895186424255371, -0.20202067494392395, 0.12307539582252502]\n",
      "    cartesian_velocity: [-0.01566740870475769, 0.027024200186133385, -0.046480972319841385, -0.012023619376122952, -0.0014677648432552814, -0.028235679492354393]\n",
      "    gripper_position: [0.0]\n",
      "    gripper_velocity: [0.0]\n",
      "    joint_position: [0.14347316324710846, -0.599672257900238, 0.006975200027227402, -2.392564535140991, 0.2682308852672577, 1.9869805574417114, -0.08368264883756638]\n",
      "    joint_velocity: [-0.07213276624679565, -0.007811115123331547, 0.07960255444049835, -0.03722653537988663, 0.03768290579319, 0.02561992034316063, -0.0010522045195102692]\n",
      "  discount: 1.0\n",
      "  is_first: False\n",
      "  is_last: False\n",
      "  is_terminal: False\n",
      "  language_instruction: Put the marker in the pot\n",
      "  language_instruction_2: Get the marker from the table and put it inside the silver pot\n",
      "  language_instruction_3: Put the marker inside the silver pot\n",
      "  observation:\n",
      "    cartesian_position: [0.38376593589782715, 0.07347538322210312, 0.5525954961776733, -2.893340587615967, -0.20120766758918762, 0.12692904472351074]\n",
      "    exterior_image_1_left: [214, 233, 247, 215, 234, 248, 215, 234, 248, 215, 234, 248, 215, 235, 246, 214, 234, 245, 213, 235] ... (+172780)\n",
      "    exterior_image_2_left: [19, 28, 57, 21, 28, 56, 22, 27, 56, 24, 28, 55, 25, 31, 55, 26, 34, 57, 23, 38] ... (+172780)\n",
      "    gripper_position: [0.0]\n",
      "    joint_position: [0.1578959822654724, -0.5981036424636841, -0.008963925763964653, -2.385937452316284, 0.26069551706314087, 1.9818570613861084, -0.08347627520561218]\n",
      "    wrist_image_left: [161, 93, 54, 160, 92, 53, 162, 95, 53, 161, 94, 52, 162, 95, 53, 162, 95, 53, 160, 93] ... (+172780)\n",
      "  reward: 0.0\n",
      "\n",
      "--- step 3 ---\n",
      "  action: [0.3834379017353058, 0.0786857008934021, 0.5430759787559509, -2.9065327644348145, -0.21764414012432098, 0.12224197387695312, 0.0]\n",
      "  action_dict:\n",
      "    cartesian_position: [0.3834379017353058, 0.0786857008934021, 0.5430759787559509, -2.9065327644348145, -0.21764414012432098, 0.12224197387695312]\n",
      "    cartesian_velocity: [-0.0021388691384345293, 0.06234659627079964, -0.12059859931468964, -0.06483706086874008, -0.12516072392463684, -0.05492424964904785]\n",
      "    gripper_position: [0.0]\n",
      "    gripper_velocity: [0.0]\n",
      "    joint_position: [0.14219044148921967, -0.5995740294456482, 0.01701989397406578, -2.4095258712768555, 0.26380622386932373, 2.0206525325775146, -0.08119409531354904]\n",
      "    joint_velocity: [-0.0771586075425148, -0.007572902832180262, 0.12254606187343597, -0.11348150670528412, 0.015546049922704697, 0.19401313364505768, 0.011213591322302818]\n",
      "  discount: 1.0\n",
      "  is_first: False\n",
      "  is_last: False\n",
      "  is_terminal: False\n",
      "  language_instruction: Put the marker in the pot\n",
      "  language_instruction_2: Get the marker from the table and put it inside the silver pot\n",
      "  language_instruction_3: Put the marker inside the silver pot\n",
      "  observation:\n",
      "    cartesian_position: [0.3838363587856293, 0.07349109649658203, 0.5530181527137756, -2.893328905105591, -0.20205119252204895, 0.12693332135677338]\n",
      "    exterior_image_1_left: [216, 234, 248, 216, 234, 248, 215, 234, 248, 215, 234, 248, 215, 235, 246, 214, 234, 245, 214, 234] ... (+172780)\n",
      "    exterior_image_2_left: [20, 29, 58, 20, 29, 58, 23, 28, 60, 23, 28, 58, 24, 30, 56, 25, 33, 54, 25, 36] ... (+172780)\n",
      "    gripper_position: [0.0]\n",
      "    joint_position: [0.15789981186389923, -0.5981100797653198, -0.008951227180659771, -2.385096788406372, 0.26069319248199463, 1.9818545579910278, -0.08347144722938538]\n",
      "    wrist_image_left: [161, 96, 54, 159, 94, 52, 158, 93, 51, 159, 94, 52, 162, 95, 52, 161, 94, 51, 160, 93] ... (+172780)\n",
      "  reward: 0.0\n",
      "\n",
      "--- step 4 ---\n",
      "  action: [0.38460859656333923, 0.08175108581781387, 0.5371295809745789, -2.9117233753204346, -0.2231178730726242, 0.12000297755002975, 0.0]\n",
      "  action_dict:\n",
      "    cartesian_position: [0.38460859656333923, 0.08175108581781387, 0.5371295809745789, -2.9117233753204346, -0.2231178730726242, 0.12000297755002975]\n",
      "    cartesian_velocity: [0.020492730662226677, 0.08371778577566147, -0.15863606333732605, -0.07351165264844894, -0.187814861536026, -0.08984586596488953]\n",
      "    gripper_position: [0.0]\n",
      "    gripper_velocity: [0.0]\n",
      "    joint_position: [0.14208444952964783, -0.5959964394569397, 0.024744413793087006, -2.421877145767212, 0.2635979652404785, 2.0434069633483887, -0.07724086195230484]\n",
      "    joint_velocity: [-0.07571244984865189, 0.009016473777592182, 0.14122052490711212, -0.14225034415721893, 0.0145299406722188, 0.29135411977767944, 0.030515365302562714]\n",
      "  discount: 1.0\n",
      "  is_first: False\n",
      "  is_last: False\n",
      "  is_terminal: False\n",
      "  language_instruction: Put the marker in the pot\n",
      "  language_instruction_2: Get the marker from the table and put it inside the silver pot\n",
      "  language_instruction_3: Put the marker inside the silver pot\n",
      "  observation:\n",
      "    cartesian_position: [0.3835586607456207, 0.07408683001995087, 0.5519736409187317, -2.894322395324707, -0.19999068975448608, 0.1281754970550537]\n",
      "    exterior_image_1_left: [216, 234, 248, 216, 234, 248, 215, 235, 246, 215, 235, 246, 215, 235, 246, 214, 234, 245, 214, 234] ... (+172780)\n",
      "    exterior_image_2_left: [21, 30, 61, 19, 28, 59, 21, 26, 58, 23, 28, 57, 25, 32, 50, 25, 34, 51, 25, 36] ... (+172780)\n",
      "    gripper_position: [0.0]\n",
      "    joint_position: [0.15760530531406403, -0.598057746887207, -0.007290976587682962, -2.387120246887207, 0.2606942057609558, 1.9818521738052368, -0.08342575281858444]\n",
      "    wrist_image_left: [163, 96, 53, 160, 93, 50, 160, 93, 51, 161, 94, 52, 163, 93, 57, 162, 92, 56, 162, 92] ... (+172780)\n",
      "  reward: 0.0\n",
      "\n",
      "--- step 5 ---\n",
      "  action: [0.38626113533973694, 0.08194130659103394, 0.535659670829773, -2.913748264312744, -0.22206687927246094, 0.1158873438835144, 0.0]\n",
      "  action_dict:\n",
      "    cartesian_position: [0.38626113533973694, 0.08194130659103394, 0.535659670829773, -2.913748264312744, -0.22206687927246094, 0.1158873438835144]\n",
      "    cartesian_velocity: [0.04470914229750633, 0.05457668378949165, -0.12079720944166183, -0.05998702719807625, -0.1617831289768219, -0.1271239072084427]\n",
      "    gripper_position: [0.0]\n",
      "    gripper_velocity: [0.0]\n",
      "    joint_position: [0.14079152047634125, -0.5910434126853943, 0.026767410337924957, -2.4231457710266113, 0.26237592101097107, 2.049799919128418, -0.07331452518701553]\n",
      "    joint_velocity: [-0.08045700192451477, 0.03219075873494148, 0.1177622526884079, -0.09230691939592361, 0.008402304723858833, 0.25008320808410645, 0.047635748982429504]\n",
      "  discount: 1.0\n",
      "  is_first: False\n",
      "  is_last: False\n",
      "  is_terminal: False\n",
      "  language_instruction: Put the marker in the pot\n",
      "  language_instruction_2: Get the marker from the table and put it inside the silver pot\n",
      "  language_instruction_3: Put the marker inside the silver pot\n",
      "  observation:\n",
      "    cartesian_position: [0.3830374479293823, 0.07560061663389206, 0.5487696528434753, -2.896974563598633, -0.19648496806621552, 0.13070273399353027]\n",
      "    exterior_image_1_left: [216, 234, 248, 216, 234, 248, 215, 234, 248, 215, 234, 248, 215, 235, 246, 214, 234, 245, 214, 234] ... (+172780)\n",
      "    exterior_image_2_left: [22, 28, 64, 21, 27, 61, 22, 25, 56, 24, 28, 53, 25, 31, 47, 24, 31, 47, 25, 32] ... (+172780)\n",
      "    gripper_position: [0.0]\n",
      "    joint_position: [0.15721939504146576, -0.5977818369865417, -0.003163871355354786, -2.3940186500549316, 0.26069679856300354, 1.9856014251708984, -0.08333463966846466]\n",
      "    wrist_image_left: [160, 96, 50, 161, 97, 53, 161, 98, 55, 160, 97, 56, 160, 96, 60, 161, 97, 61, 163, 98] ... (+172780)\n",
      "  reward: 0.0\n",
      "\n",
      "--- step 6 ---\n",
      "  action: [0.3894123435020447, 0.08459073305130005, 0.5291634202003479, -2.9199347496032715, -0.2225276380777359, 0.10949983447790146, 0.0]\n",
      "  action_dict:\n",
      "    cartesian_position: [0.3894123435020447, 0.08459073305130005, 0.5291634202003479, -2.9199347496032715, -0.2225276380777359, 0.10949983447790146]\n",
      "    cartesian_velocity: [0.0851660966873169, 0.05690397694706917, -0.14063625037670135, -0.0715540200471878, -0.14182329177856445, -0.17446939647197723]\n",
      "    gripper_position: [0.0]\n",
      "    gripper_velocity: [0.0]\n",
      "    joint_position: [0.13980576395988464, -0.5802085995674133, 0.03431783616542816, -2.432145595550537, 0.26012951135635376, 2.072514057159424, -0.06496349722146988]\n",
      "    joint_velocity: [-0.08393765985965729, 0.08038249611854553, 0.11977089941501617, -0.07360656559467316, -0.0028129855636507273, 0.27129507064819336, 0.08109807968139648]\n",
      "  discount: 1.0\n",
      "  is_first: False\n",
      "  is_last: False\n",
      "  is_terminal: False\n",
      "  language_instruction: Put the marker in the pot\n",
      "  language_instruction_2: Get the marker from the table and put it inside the silver pot\n",
      "  language_instruction_3: Put the marker inside the silver pot\n",
      "  observation:\n",
      "    cartesian_position: [0.3829106390476227, 0.0780128762125969, 0.5444477200508118, -2.901637554168701, -0.19956077635288239, 0.13255563378334045]\n",
      "    exterior_image_1_left: [216, 234, 248, 216, 234, 248, 215, 234, 248, 215, 234, 248, 215, 235, 246, 214, 234, 245, 214, 234] ... (+172780)\n",
      "    exterior_image_2_left: [18, 30, 56, 18, 30, 56, 21, 28, 57, 21, 28, 54, 23, 31, 52, 23, 34, 52, 21, 37] ... (+172780)\n",
      "    gripper_position: [0.0]\n",
      "    joint_position: [0.15687821805477142, -0.597456693649292, 0.0036730302963405848, -2.405440330505371, 0.2606929838657379, 2.0009543895721436, -0.08278334140777588]\n",
      "    wrist_image_left: [156, 95, 64, 150, 91, 59, 150, 91, 61, 148, 91, 61, 150, 93, 63, 151, 95, 62, 151, 90] ... (+172780)\n",
      "  reward: 0.0\n",
      "\n",
      "--- step 7 ---\n",
      "  action: [0.39642390608787537, 0.08948386460542679, 0.5211620330810547, -2.931595802307129, -0.22686609625816345, 0.09584217518568039, 0.0]\n",
      "  action_dict:\n",
      "    cartesian_position: [0.39642390608787537, 0.08948386460542679, 0.5211620330810547, -2.931595802307129, -0.22686609625816345, 0.09584217518568039]\n",
      "    cartesian_velocity: [0.16877885162830353, 0.096034474670887, -0.18434473872184753, -0.12219041585922241, -0.15382620692253113, -0.25823599100112915]\n",
      "    gripper_position: [0.0]\n",
      "    gripper_velocity: [0.0]\n",
      "    joint_position: [0.13668552041053772, -0.557885468006134, 0.04809166118502617, -2.4371542930603027, 0.2544533908367157, 2.1087684631347656, -0.046990178525447845]\n",
      "    joint_velocity: [-0.09753662347793579, 0.17669446766376495, 0.15896229445934296, -0.044773489236831665, -0.031155593693256378, 0.35920560359954834, 0.15296408534049988]\n",
      "  discount: 1.0\n",
      "  is_first: False\n",
      "  is_last: False\n",
      "  is_terminal: False\n",
      "  language_instruction: Put the marker in the pot\n",
      "  language_instruction_2: Get the marker from the table and put it inside the silver pot\n",
      "  language_instruction_3: Put the marker inside the silver pot\n",
      "  observation:\n",
      "    cartesian_position: [0.38306376338005066, 0.08046716451644897, 0.5394048094749451, -2.90643572807312, -0.2033218890428543, 0.13281673192977905]\n",
      "    exterior_image_1_left: [214, 232, 246, 214, 232, 246, 214, 233, 247, 215, 234, 248, 215, 235, 246, 214, 234, 245, 215, 235] ... (+172780)\n",
      "    exterior_image_2_left: [16, 30, 57, 18, 29, 57, 19, 28, 57, 22, 29, 55, 24, 32, 53, 24, 36, 52, 22, 39] ... (+172780)\n",
      "    gripper_position: [0.0]\n",
      "    joint_position: [0.15658919513225555, -0.5961647033691406, 0.01078545767813921, -2.4182281494140625, 0.2606930136680603, 2.0196828842163086, -0.08107119053602219]\n",
      "    wrist_image_left: [86, 69, 51, 76, 59, 41, 66, 50, 35, 62, 46, 31, 61, 41, 30, 62, 40, 27, 70, 47] ... (+172780)\n",
      "  reward: 0.0\n",
      "\n",
      "--- step 8 ---\n",
      "  action: [0.40256744623184204, 0.09273721277713776, 0.5141305327415466, -2.940162420272827, -0.23393410444259644, 0.08500775694847107, 0.0]\n",
      "  action_dict:\n",
      "    cartesian_position: [0.40256744623184204, 0.09273721277713776, 0.5141305327415466, -2.940162420272827, -0.23393410444259644, 0.08500775694847107]\n",
      "    cartesian_velocity: [0.22275571525096893, 0.11243695765733719, -0.20808303356170654, -0.15208324790000916, -0.1651037633419037, -0.2917701005935669]\n",
      "    gripper_position: [0.0]\n",
      "    gripper_velocity: [0.0]\n",
      "    joint_position: [0.13502484560012817, -0.5380162000656128, 0.05745702236890793, -2.442122220993042, 0.2496463805437088, 2.1438064575195312, -0.0340384878218174]\n",
      "    joint_velocity: [-0.1034654825925827, 0.24044010043144226, 0.17478762567043304, -0.019901849329471588, -0.05291096866130829, 0.40930673480033875, 0.18379123508930206]\n",
      "  discount: 1.0\n",
      "  is_first: False\n",
      "  is_last: False\n",
      "  is_terminal: False\n",
      "  language_instruction: Put the marker in the pot\n",
      "  language_instruction_2: Get the marker from the table and put it inside the silver pot\n",
      "  language_instruction_3: Put the marker inside the silver pot\n",
      "  observation:\n",
      "    cartesian_position: [0.3838096559047699, 0.08238547295331955, 0.5347413420677185, -2.910064935684204, -0.2066793292760849, 0.12995046377182007]\n",
      "    exterior_image_1_left: [213, 232, 246, 213, 232, 246, 214, 233, 247, 215, 234, 248, 215, 235, 246, 214, 234, 245, 212, 234] ... (+172780)\n",
      "    exterior_image_2_left: [22, 28, 60, 21, 28, 57, 19, 29, 56, 19, 30, 50, 19, 32, 48, 19, 35, 48, 21, 38] ... (+172780)\n",
      "    gripper_position: [0.0]\n",
      "    joint_position: [0.1561911702156067, -0.5930606126785278, 0.016603438183665276, -2.4287822246551514, 0.2606886327266693, 2.0380144119262695, -0.07738178223371506]\n",
      "    wrist_image_left: [32, 24, 22, 30, 22, 20, 26, 21, 18, 23, 18, 15, 21, 13, 10, 20, 11, 6, 20, 9] ... (+172780)\n",
      "  reward: 0.0\n",
      "\n",
      "--- step 9 ---\n",
      "  action: [0.4122389554977417, 0.0974767729640007, 0.5036080479621887, -2.9498515129089355, -0.23994046449661255, 0.06913746893405914, 0.0]\n",
      "  action_dict:\n",
      "    cartesian_position: [0.4122389554977417, 0.0974767729640007, 0.5036080479621887, -2.9498515129089355, -0.23994046449661255, 0.06913746893405914]\n",
      "    cartesian_velocity: [0.29998838901519775, 0.1392492651939392, -0.25846797227859497, -0.18452952802181244, -0.1661389321088791, -0.34434637427330017]\n",
      "    gripper_position: [0.0]\n",
      "    gripper_velocity: [0.0]\n",
      "    joint_position: [0.132825568318367, -0.5045251250267029, 0.06980974227190018, -2.444986343383789, 0.24393853545188904, 2.1903536319732666, -0.015062384307384491]\n",
      "    joint_velocity: [-0.11235147714614868, 0.33772414922714233, 0.19836139678955078, 0.009768133983016014, -0.07640300691127777, 0.48313990235328674, 0.23152735829353333]\n",
      "  discount: 1.0\n",
      "  is_first: False\n",
      "  is_last: False\n",
      "  is_terminal: False\n",
      "  language_instruction: Put the marker in the pot\n",
      "  language_instruction_2: Get the marker from the table and put it inside the silver pot\n",
      "  language_instruction_3: Put the marker inside the silver pot\n",
      "  observation:\n",
      "    cartesian_position: [0.3861050307750702, 0.08450756222009659, 0.5292530059814453, -2.914074182510376, -0.2127690464258194, 0.12255126237869263]\n",
      "    exterior_image_1_left: [213, 232, 246, 213, 232, 246, 214, 233, 247, 215, 234, 248, 215, 235, 246, 214, 234, 245, 214, 234] ... (+172780)\n",
      "    exterior_image_2_left: [19, 30, 62, 18, 27, 58, 21, 26, 55, 23, 29, 51, 23, 32, 47, 22, 34, 48, 26, 33] ... (+172780)\n",
      "    gripper_position: [0.0]\n",
      "    joint_position: [0.15572470426559448, -0.5852512717247009, 0.023045307025313377, -2.4389169216156006, 0.26021161675453186, 2.064314842224121, -0.07013638317584991]\n",
      "    wrist_image_left: [19, 18, 14, 16, 15, 11, 11, 10, 8, 6, 5, 3, 6, 2, 1, 6, 2, 1, 7, 1] ... (+172780)\n",
      "  reward: 0.0\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# ===== ì¶œë ¥ ì œí•œ ì„¤ì • =====\n",
    "MAX_STEPS = 10      # steps ëª‡ ê°œë§Œ ìì„¸íˆ ë³¼ì§€\n",
    "MAX_VALS  = 20      # ë°°ì—´/í…ì„œ ê°’ ìµœëŒ€ ëª‡ ê°œê¹Œì§€ ì¶œë ¥í• ì§€\n",
    "MAX_STR   = 200     # ë¬¸ìì—´ì€ ìµœëŒ€ ëª‡ ê¸€ìê¹Œì§€ ì¶œë ¥í• ì§€\n",
    "\n",
    "def _decode_str(x):\n",
    "    if isinstance(x, (bytes, np.bytes_)):\n",
    "        return x.decode(\"utf-8\", errors=\"ignore\")\n",
    "    if isinstance(x, (str, np.str_)):\n",
    "        return str(x)\n",
    "    return str(x)\n",
    "\n",
    "def _value_preview(val, max_vals=MAX_VALS, max_str=MAX_STR):\n",
    "    \"\"\"shape/dtype ì—†ì´ 'ê°’'ë§Œ ìš”ì•½ ë¬¸ìì—´ë¡œ ë°˜í™˜\"\"\"\n",
    "    # tf.Tensor -> numpyë¡œ\n",
    "    if isinstance(val, tf.Tensor):\n",
    "        val = val.numpy()\n",
    "\n",
    "    # numpy ë°°ì—´\n",
    "    if isinstance(val, np.ndarray):\n",
    "        if val.dtype.type is np.bytes_:\n",
    "            # ë¬¸ìì—´ í…ì„œì¸ ê²½ìš°\n",
    "            flat = val.ravel()\n",
    "            shown = [ _decode_str(b)[:max_str] for b in flat[:max_vals] ]\n",
    "            return f\"{shown}\" + (f\" ... (+{flat.size-max_vals})\" if flat.size > max_vals else \"\")\n",
    "        else:\n",
    "            flat = val.ravel()\n",
    "            shown = flat[:max_vals].tolist()\n",
    "            return f\"{shown}\" + (f\" ... (+{flat.size-max_vals})\" if flat.size > max_vals else \"\")\n",
    "\n",
    "    # íŒŒì´ì¬ ê¸°ë³¸í˜•/ë¬¸ìì—´\n",
    "    if isinstance(val, (int, float, bool)):\n",
    "        return str(val)\n",
    "    s = _decode_str(val)\n",
    "    return s[:max_str] + (\"...\" if len(s) > max_str else \"\")\n",
    "\n",
    "def _print_values(key, val, indent=0):\n",
    "    pad = \"  \" * indent\n",
    "    # dictë©´ ì¬ê·€\n",
    "    if isinstance(val, dict):\n",
    "        print(f\"{pad}{key}:\")\n",
    "        for k, v in val.items():\n",
    "            _print_values(k, v, indent+1)\n",
    "        return\n",
    "    # ë‚˜ë¨¸ì§€: ê°’ë§Œ í”„ë¦°íŠ¸\n",
    "    try:\n",
    "        pv = _value_preview(val)\n",
    "    except Exception as e:\n",
    "        pv = f\"<error: {e}>\"\n",
    "    print(f\"{pad}{key}: {pv}\")\n",
    "\n",
    "# ===== ì‹¤ì œ ë¡œë“œ & ì¶œë ¥ =====\n",
    "builder = tfds.builder_from_directory(\"/home/parkjeongsu/TinyVLA/Droid/droid_100/1.0.0\")\n",
    "ds = builder.as_dataset(split=\"train\")\n",
    "\n",
    "# ì—í”¼ì†Œë“œ 1ê°œë§Œ\n",
    "for episode in ds.take(5):\n",
    "    print(\"\\n=== episode top-level values ===\")\n",
    "    for k in episode.keys():\n",
    "        _print_values(k, episode[k], indent=0)\n",
    "\n",
    "    print(f\"\\n=== steps values (first {MAX_STEPS} steps) ===\")\n",
    "    for idx, step in enumerate(episode[\"steps\"]):\n",
    "        print(f\"\\n--- step {idx} ---\")\n",
    "        # stepì€ dictì´ë¯€ë¡œ ê° keyì˜ 'ê°’'ë§Œ í‘œê¸°\n",
    "        for k in step.keys():\n",
    "            _print_values(k, step[k], indent=1)\n",
    "        if idx + 1 >= MAX_STEPS:\n",
    "            break\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34d7828d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 0: action==cart_pos? True, obsâ‰ˆaction mean_err=3.1652e-01 max_err=6.2435e+00, grip_cmd==action[-1]? True, qpos[-1]==grip_obs? False\n",
      "episode 1: action==cart_pos? True, obsâ‰ˆaction mean_err=4.7968e-01 max_err=6.2766e+00, grip_cmd==action[-1]? True, qpos[-1]==grip_obs? False\n",
      "episode 2: action==cart_pos? True, obsâ‰ˆaction mean_err=9.4281e-01 max_err=6.2768e+00, grip_cmd==action[-1]? True, qpos[-1]==grip_obs? False\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "\n",
    "builder = tfds.builder_from_directory(\"/home/parkjeongsu/TinyVLA/Droid/droid_100/1.0.0\")\n",
    "ds = builder.as_dataset(split=\"train\")\n",
    "\n",
    "def check_episode(episode):\n",
    "    ok1 = True  # action[:6] == action_dict.cartesian_position\n",
    "    ok2 = []    # ||obs.cartesian_position - action[:6]||\n",
    "    ok3 = True  # action[-1] == action_dict.gripper_position[0]\n",
    "    ok4 = True  # obs.joint_position[-1] == obs.gripper_position ? (ê¸°ëŒ€: False)\n",
    "\n",
    "    for step in episode[\"steps\"]:\n",
    "        a = step[\"action\"].numpy()\n",
    "        cd_pos = step[\"action_dict\"][\"cartesian_position\"].numpy()\n",
    "        grip_cmd = step[\"action_dict\"][\"gripper_position\"].numpy()[0]\n",
    "        obs_pose = step[\"observation\"][\"cartesian_position\"].numpy()\n",
    "        qpos = step[\"observation\"][\"joint_position\"].numpy()\n",
    "        grip_obs = step[\"observation\"][\"gripper_position\"].numpy()[0]\n",
    "\n",
    "        ok1 &= np.allclose(a[:6], cd_pos, atol=1e-8)\n",
    "        ok3 &= np.allclose(a[-1], grip_cmd, atol=1e-8)\n",
    "        ok4 &= np.allclose(qpos[-1], grip_obs, atol=1e-6)  # ëŒ€ë¶€ë¶„ Falseì¼ ê²ƒ\n",
    "        ok2.append(np.linalg.norm(obs_pose - a[:6]))\n",
    "\n",
    "    return ok1, np.mean(ok2), np.max(ok2), ok3, ok4\n",
    "\n",
    "for i, ep in enumerate(ds.take(3)):\n",
    "    ok1, m, M, ok3, ok4 = check_episode(ep)\n",
    "    print(f\"episode {i}: action==cart_pos? {ok1}, obsâ‰ˆaction mean_err={m:.4e} max_err={M:.4e}, \"\n",
    "          f\"grip_cmd==action[-1]? {ok3}, qpos[-1]==grip_obs? {ok4}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ea088a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”‘ Top-level keys: ['action', 'language_raw', 'observations']\n",
      "ğŸ” [observations] ë‚´ë¶€ key ëª©ë¡: ['images', 'joint_positions', 'qpos', 'qvel']\n",
      "ğŸ“ images is a Group â†’ ë‚´ë¶€ key ëª©ë¡: ['left', 'right', 'wrist']\n",
      "âœ… joint_positions shape: (100, 7)\n",
      "âœ… qpos shape: (100, 7)\n",
      "âœ… qvel shape: (100, 7)\n",
      "(100, 10)\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "\n",
    "h5_path = \"/home/parkjeongsu/TinyVLA/Droid/trans_data/droid_1dot7t_lang_succ_t0001_s-0-0/episode_74.hdf5\"\n",
    "\n",
    "with h5py.File(h5_path, 'r') as f:\n",
    "    print(\"ğŸ”‘ Top-level keys:\", list(f.keys()))\n",
    "\n",
    "    obs = f[\"observations\"]\n",
    "    print(\"ğŸ” [observations] ë‚´ë¶€ key ëª©ë¡:\", list(obs.keys()))\n",
    "\n",
    "    for k in obs.keys():\n",
    "        item = obs[k]\n",
    "        if isinstance(item, h5py.Dataset):\n",
    "            print(f\"âœ… {k} shape:\", item.shape)\n",
    "        elif isinstance(item, h5py.Group):\n",
    "            print(f\"ğŸ“ {k} is a Group â†’ ë‚´ë¶€ key ëª©ë¡:\", list(item.keys()))\n",
    "\n",
    "    print(f['action'].shape)  # â† ì´ê²Œ ë°”ë¡œ 10ì°¨ì›ì´ ë˜ì–´ì•¼ í•¨\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8731a28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”‘ Top-level keys: ['action', 'language_raw', 'observations']\n",
      "ğŸ” [observations] ë‚´ë¶€ key ëª©ë¡: ['images', 'joint_positions', 'qpos', 'qvel']\n",
      "ğŸ“ images is a Group â†’ ë‚´ë¶€ key ëª©ë¡: ['left', 'right', 'wrist']\n",
      "âœ… joint_positions shape: (100, 7)\n",
      "âœ… qpos shape: (100, 7)\n",
      "âœ… qvel shape: (100, 7)\n",
      "ğŸ§­ action shape: (100, 10)\n",
      "\n",
      "ğŸŸ¦ qpos (ì• 3 ìŠ¤í…):\n",
      "[[-0.149206 -0.669474 -0.404594 -2.789922 -0.141941  2.247962 -0.505818]\n",
      " [-0.149196 -0.669059 -0.404564 -2.789907 -0.14192   2.247981 -0.505812]\n",
      " [-0.149201 -0.669068 -0.40457  -2.789902 -0.141911  2.247984 -0.50582 ]]\n",
      "qpos shape: (100, 7)\n",
      "\n",
      "ğŸŸ© /observations/joint_positions (ì• 3 ìŠ¤í…):\n",
      "[[-0.149206 -0.669474 -0.404594 -2.789922 -0.141941  2.247962 -0.505818]\n",
      " [-0.149196 -0.669059 -0.404564 -2.789907 -0.14192   2.247981 -0.505812]\n",
      " [-0.149201 -0.669068 -0.40457  -2.789902 -0.141911  2.247984 -0.50582 ]]\n",
      "/observations/joint_positions shape: (100, 7)\n",
      "\n",
      "ğŸ“ ë™ì¼ shape? True\n",
      "âœ… ì™„ì „ ë™ì¼(np.array_equal)? True\n",
      "âœ… ê·¼ì‚¬ ë™ì¼(np.allclose, atol=1e-6)? True\n",
      "ğŸ” ìµœëŒ€ ì ˆëŒ€ ì˜¤ì°¨: 0.0\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "h5_path = \"/home/parkjeongsu/TinyVLA/Droid/trans_data/droid_1dot7t_lang_succ_t0001_s-0-0/episode_74.hdf5\"\n",
    "\n",
    "def safe_get(h5, path):\n",
    "    \"\"\"H5ì—ì„œ pathê°€ ìˆìœ¼ë©´ numpy ë°°ì—´ë¡œ ë°˜í™˜, ì—†ìœ¼ë©´ None\"\"\"\n",
    "    if path in h5:\n",
    "        return h5[path][()]\n",
    "    return None\n",
    "\n",
    "with h5py.File(h5_path, 'r') as f:\n",
    "    # 1) ìƒìœ„/observations êµ¬ì¡° í›‘ê¸°\n",
    "    print(\"ğŸ”‘ Top-level keys:\", list(f.keys()))\n",
    "    obs = f[\"observations\"]\n",
    "    print(\"ğŸ” [observations] ë‚´ë¶€ key ëª©ë¡:\", list(obs.keys()))\n",
    "\n",
    "    # ê° í•­ëª© shape / ê·¸ë£¹ ì—¬ë¶€ ì¶œë ¥\n",
    "    for k in obs.keys():\n",
    "        item = obs[k]\n",
    "        if isinstance(item, h5py.Dataset):\n",
    "            print(f\"âœ… {k} shape:\", item.shape)\n",
    "        elif isinstance(item, h5py.Group):\n",
    "            print(f\"ğŸ“ {k} is a Group â†’ ë‚´ë¶€ key ëª©ë¡:\", list(item.keys()))\n",
    "\n",
    "    # action shape í™•ì¸\n",
    "    print(\"ğŸ§­ action shape:\", f['action'].shape)\n",
    "\n",
    "    # 2) qposì™€ joint_positions(ë˜ëŠ” joint_position) í›„ë³´ ë¡œë“œ\n",
    "    qpos = safe_get(f, \"/observations/qpos\")\n",
    "    joint_candidates = [\"/observations/joint_positions\", \"/observations/joint_position\"]\n",
    "    joint = None\n",
    "    joint_key = None\n",
    "    for jk in joint_candidates:\n",
    "        if jk in f:\n",
    "            joint = f[jk][()]\n",
    "            joint_key = jk\n",
    "            break\n",
    "\n",
    "    # 3) ì¼ë¶€ ê°’ ì¶œë ¥(ì• 3ìŠ¤í…)\n",
    "    np.set_printoptions(precision=6, suppress=True, linewidth=140)\n",
    "\n",
    "    if qpos is not None:\n",
    "        print(\"\\nğŸŸ¦ qpos (ì• 3 ìŠ¤í…):\")\n",
    "        print(qpos[:3])\n",
    "        print(\"qpos shape:\", qpos.shape)\n",
    "    else:\n",
    "        print(\"\\nâš ï¸ '/observations/qpos'ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "    if joint is not None:\n",
    "        print(f\"\\nğŸŸ© {joint_key} (ì• 3 ìŠ¤í…):\")\n",
    "        print(joint[:3])\n",
    "        print(f\"{joint_key} shape:\", joint.shape)\n",
    "    else:\n",
    "        print(\"\\nâ„¹ï¸ H5ì— 'joint_positions' ì €ì¥ì´ ì—†ìŠµë‹ˆë‹¤. (ì´ë²ˆ ë³€í™˜ ìŠ¤í¬ë¦½íŠ¸ëŠ” ë³´í†µ qposë§Œ ì €ì¥)\")\n",
    "\n",
    "    # 4) ë‘˜ ë‹¤ ìˆìœ¼ë©´ ì™„ì „ ë™ì¼/ê·¼ì‚¬ ë™ì¼ ì—¬ë¶€ ì²´í¬\n",
    "    if (qpos is not None) and (joint is not None):\n",
    "        same_shape = (qpos.shape == joint.shape)\n",
    "        print(\"\\nğŸ“ ë™ì¼ shape?\", same_shape)\n",
    "        if same_shape:\n",
    "            exactly_equal = np.array_equal(qpos, joint)\n",
    "            allclose_equal = np.allclose(qpos, joint, atol=1e-6)\n",
    "            max_abs_diff = np.max(np.abs(qpos - joint))\n",
    "            print(\"âœ… ì™„ì „ ë™ì¼(np.array_equal)?\", exactly_equal)\n",
    "            print(\"âœ… ê·¼ì‚¬ ë™ì¼(np.allclose, atol=1e-6)?\", allclose_equal)\n",
    "            print(\"ğŸ” ìµœëŒ€ ì ˆëŒ€ ì˜¤ì°¨:\", float(max_abs_diff))\n",
    "        else:\n",
    "            print(\"âŒ shapeì´ ë‹¬ë¼ ë¹„êµ ë¶ˆê°€.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00b6b2a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”‘ Top-level keys: ['Trial0']\n",
      "ğŸ” [observations] ë‚´ë¶€ key ëª©ë¡: ['data']\n",
      "ğŸ“ data is a Group â†’ ë‚´ë¶€ key ëª©ë¡: ['ctrl_arm', 'ctrl_ee', 'd_left', 'd_right', 'd_top', 'qp_arm', 'qp_ee', 'qv_arm', 'qv_ee', 'rgb_left', 'rgb_right', 'rgb_top', 'time']\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"Unable to synchronously open object (object 'action' doesn't exist)\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(item, h5py\u001b[38;5;241m.\u001b[39mGroup):\n\u001b[1;32m     17\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mğŸ“ \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is a Group â†’ ë‚´ë¶€ key ëª©ë¡:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlist\u001b[39m(item\u001b[38;5;241m.\u001b[39mkeys()))\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43maction\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mshape)  \u001b[38;5;66;03m# â† ì´ê²Œ ë°”ë¡œ 10ì°¨ì›ì´ ë˜ì–´ì•¼ í•¨\u001b[39;00m\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/tinysuite/lib/python3.10/site-packages/h5py/_hl/group.py:357\u001b[0m, in \u001b[0;36mGroup.__getitem__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid HDF5 object reference\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(name, (\u001b[38;5;28mbytes\u001b[39m, \u001b[38;5;28mstr\u001b[39m)):\n\u001b[0;32m--> 357\u001b[0m     oid \u001b[38;5;241m=\u001b[39m \u001b[43mh5o\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_e\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlapl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_lapl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    359\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccessing a group is done with bytes or str, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    360\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnot \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mtype\u001b[39m(name)))\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/h5o.pyx:241\u001b[0m, in \u001b[0;36mh5py.h5o.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"Unable to synchronously open object (object 'action' doesn't exist)\""
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "\n",
    "h5_path = \"/home/parkjeongsu/Downloads/set_8_pick_bottle_10/robopen05_20230528-222842_paths_roboset.h5\"\n",
    "\n",
    "with h5py.File(h5_path, 'r') as f:\n",
    "    print(\"ğŸ”‘ Top-level keys:\", list(f.keys()))\n",
    "\n",
    "    #bs1 = f[\"observations\"]\n",
    "    obs2 = f[\"Trial0\"]\n",
    "    #print(\"ğŸ” [observations] ë‚´ë¶€ key ëª©ë¡:\", list(obs1.keys()))\n",
    "    print(\"ğŸ” [observations] ë‚´ë¶€ key ëª©ë¡:\", list(obs2.keys()))\n",
    "    for k in obs2.keys():\n",
    "        item = obs2[k]\n",
    "        if isinstance(item, h5py.Dataset):\n",
    "            print(f\"âœ… {k} shape:\", item.shape)\n",
    "        elif isinstance(item, h5py.Group):\n",
    "            print(f\"ğŸ“ {k} is a Group â†’ ë‚´ë¶€ key ëª©ë¡:\", list(item.keys()))\n",
    "\n",
    "    print(f['action'].shape)  # â† ì´ê²Œ ë°”ë¡œ 10ì°¨ì›ì´ ë˜ì–´ì•¼ í•¨\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d710e20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tinysuite",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
