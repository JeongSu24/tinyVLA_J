{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f506bc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-08 16:10:22.334079: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-08-08 16:10:22.358281: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-08-08 16:10:22.358308: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-08-08 16:10:22.359169: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-08-08 16:10:22.363602: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-08-08 16:10:22.871578: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-08-08 16:10:23.410490: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-08-08 16:10:23.432021: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-08-08 16:10:23.432141: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-08-08 16:10:23.432867: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-08-08 16:10:23.432942: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-08-08 16:10:23.432988: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-08-08 16:10:23.803789: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-08-08 16:10:23.803896: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-08-08 16:10:23.803952: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-08-08 16:10:23.804003: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9699 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "  5%|▌         | 5/100 [00:00<00:14,  6.46it/s]"
     ]
    }
   ],
   "source": [
    "import itertools  # 반복문과 조합 관련 유틸리티\n",
    "import os  # 운영체제 파일 경로 등 처리\n",
    "import os.path as osp  # 경로(join, split 등) 처리 단축\n",
    "import time  # 시간 측정 및 대기\n",
    "from collections import OrderedDict, defaultdict  # 순서 있는 dict, 기본값 딕셔너리\n",
    "from datetime import datetime  # 날짜/시간 객체\n",
    "from tqdm import tqdm  # 진행 바 표시\n",
    "\n",
    "import h5py  # HDF5 파일 입출력\n",
    "\n",
    "import torch  # PyTorch 텐서 연산\n",
    "import collections  # 컬렉션 관련 타입\n",
    "import tensorflow_datasets as tfds  # TFDS 데이터셋 로드\n",
    "import numpy as np  # 수치 연산\n",
    "import tkinter as tk  # 간단한 GUI (언어 입력 등)\n",
    "from tkinter import simpledialog  # 간단한 입력 다이얼로그\n",
    "from PIL import Image, ImageTk  # 이미지 처리 및 표시\n",
    "import argparse  # 명령행 인자 파싱\n",
    "\n",
    "from IPython.display import display, Image as IPyImage\n",
    "\n",
    "# === 전역 디렉토리 설정 ===\n",
    "BASE_ROOT_DIR = \"/home/parkjeongsu/TinyVLA\"\n",
    "GIF_SAVE_DIR = os.path.join(BASE_ROOT_DIR, \"droid_image\")\n",
    "SMOOTH_ACTION_FIG_DIR = os.path.join(BASE_ROOT_DIR, \"droid_traj\", \"smooth_action_results\")\n",
    "DATASET_DIR = os.path.join(BASE_ROOT_DIR, \"/home/parkjeongsu/TinyVLA/Droid\")\n",
    "OUTPUT_H5_DIR = os.path.join(DATASET_DIR, \"droid_with_lang\")\n",
    "\n",
    "def get_image_list_np(img_rgb_dir_path, remove_index_list):\n",
    "    \"\"\"\n",
    "    지정한 디렉토리에서 RGB 이미지 파일 목록을 불러와 numpy 배열로 반환합니다.\n",
    "    remove_index_list에 포함된 인덱스는 건너뜁니다.\n",
    "    \"\"\"\n",
    "    cur_camera_rgb_list = []  # 개별 프레임 저장할 리스트\n",
    "    img_name_list = os.listdir(img_rgb_dir_path)  # 디렉토리 내 파일 이름 목록\n",
    "    img_name_list = sorted(img_name_list)  # 정렬하여 순서 보장\n",
    "\n",
    "    for idx, img_name in enumerate(img_name_list):  # 각 이미지 파일에 대해\n",
    "        if idx in remove_index_list:  # 제거할 인덱스면 건너뜀\n",
    "            continue\n",
    "\n",
    "        img_path = os.path.join(img_rgb_dir_path, img_name)  # 전체 경로 생성\n",
    "\n",
    "        # (w 640, h 480)\n",
    "        img_frame = Image.open(img_path).convert('RGB')  # PIL로 열어 RGB로 변환\n",
    "        img_np = np.array(img_frame)  # numpy 배열로 변환 (H,W,3)\n",
    "        cur_camera_rgb_list.append(img_np)  # 리스트에 추가\n",
    "\n",
    "    cur_camera_rgb_np = np.array(cur_camera_rgb_list)  # 전체 시퀀스 배열화\n",
    "    print('+++++++++++++++')\n",
    "    print(f\"img_rgb_dir_path: {img_rgb_dir_path}\")  # 경로 정보 출력\n",
    "    print(f'cur_camera_rgb_np size: {cur_camera_rgb_np.shape}')  # 배열 크기 출력\n",
    "\n",
    "    return cur_camera_rgb_np  # 반환\n",
    "\n",
    "\n",
    "def plot_smooth_action(traj_act_xyz_np, fig_name):\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    figure_name = [\"x\", \"y\", \"z\"]\n",
    "    for i in range(3):\n",
    "        plt.subplot(1, 3, i + 1)\n",
    "        plt.plot(range(traj_act_xyz_np.shape[0]), traj_act_xyz_np[:, i], label='cur_action')\n",
    "        plt.title(figure_name[i])\n",
    "        plt.legend()\n",
    "    plt.suptitle(f\"Differences between predicted and target actions_traj\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    os.makedirs(SMOOTH_ACTION_FIG_DIR, exist_ok=True)\n",
    "    figure_path = os.path.join(SMOOTH_ACTION_FIG_DIR, f\"{fig_name}.png\")\n",
    "    plt.savefig(figure_path)\n",
    "    plt.clf()\n",
    "\n",
    "\n",
    "def print_h5_structure(group, indent=0):\n",
    "    \"\"\"\n",
    "    HDF5 파일 그룹 구조를 재귀적으로 출력합니다.\n",
    "    \"\"\"\n",
    "    for name in group:\n",
    "        item = group[name]\n",
    "        print(\" \" * indent + f\"name: {name}\")\n",
    "        if isinstance(item, h5py.Group):  # 그룹일 경우\n",
    "            print(\" \" * indent + f\"Group: {name}\")\n",
    "            print_h5_structure(item, indent + 2)  # 재귀 호출\n",
    "        elif isinstance(item, h5py.Dataset):  # 데이터셋일 경우\n",
    "            print(\" \" * indent + f\"Dataset: {name} (Shape: {item.shape}, Dtype: {item.dtype})\")\n",
    "        else:\n",
    "            print(\" \" * indent + f\"Unknown item: {name}\")\n",
    "\n",
    "\n",
    "def print_dict_structure(cur_dict, indent=0):\n",
    "    \"\"\"\n",
    "    Python dict 구조를 재귀적으로 출력합니다.\n",
    "    \"\"\"\n",
    "    for name in cur_dict.keys():\n",
    "        item = cur_dict[name]\n",
    "        print(\" \" * indent + f\"name: {name}\")\n",
    "        if isinstance(item, dict):\n",
    "            print(\" \" * indent + f\"Dict: {name}\")\n",
    "            print_dict_structure(item, indent + 2)\n",
    "        elif isinstance(item, np.ndarray):\n",
    "            print(\" \" * indent + f\"Array: {name} (Shape: {item.shape}, Dtype: {item.dtype})\")\n",
    "        else:\n",
    "            print(\" \" * indent + f\"Unknown item: {name}\")\n",
    "\n",
    "\n",
    "def to_numpy(x):\n",
    "    \"\"\"\n",
    "    중첩된 torch.Tensor를 재귀적으로 numpy 배열로 변환합니다.\n",
    "    \"\"\"\n",
    "    def f(tensor):\n",
    "        if tensor.is_cuda:\n",
    "            return tensor.detach().cpu().numpy()\n",
    "        else:\n",
    "            return tensor.detach().numpy()\n",
    "\n",
    "    return recursive_dict_list_tuple_apply(\n",
    "        x,\n",
    "        {\n",
    "            torch.Tensor: f,\n",
    "            np.ndarray: lambda x: x,\n",
    "            type(None): lambda x: x,\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "def recursive_dict_list_tuple_apply(x, type_func_dict):\n",
    "    \"\"\"\n",
    "    중첩된 dict/list/tuple 내부 요소에 주어진 함수를 적용합니다.\n",
    "    \"\"\"\n",
    "    assert (list not in type_func_dict)\n",
    "    assert (tuple not in type_func_dict)\n",
    "    assert (dict not in type_func_dict)\n",
    "\n",
    "    if isinstance(x, (dict, collections.OrderedDict)):\n",
    "        new_x = collections.OrderedDict() if isinstance(x, collections.OrderedDict) else dict()\n",
    "        for k, v in x.items():\n",
    "            new_x[k] = recursive_dict_list_tuple_apply(v, type_func_dict)\n",
    "        return new_x\n",
    "    elif isinstance(x, (list, tuple)):\n",
    "        ret = [recursive_dict_list_tuple_apply(v, type_func_dict) for v in x]\n",
    "        return tuple(ret) if isinstance(x, tuple) else ret\n",
    "    else:\n",
    "        for t, f in type_func_dict.items():\n",
    "            if isinstance(x, t):\n",
    "                return f(x)\n",
    "        return x  # 그 외 타입은 그대로 반환\n",
    "\n",
    "\n",
    "def matrix_to_rotation_6d(matrix):\n",
    "    batch_dim = matrix.size()[:-2]\n",
    "    return matrix[..., :2, :].clone().reshape(batch_dim + (6,))\n",
    "\n",
    "def _axis_angle_rotation(axis, angle):\n",
    "    cos = torch.cos(angle)\n",
    "    sin = torch.sin(angle)\n",
    "    one = torch.ones_like(angle)\n",
    "    zero = torch.zeros_like(angle)\n",
    "    if axis == \"X\":\n",
    "        R = (one, zero, zero, zero, cos, -sin, zero, sin, cos)\n",
    "    elif axis == \"Y\":\n",
    "        R = (cos, zero, sin, zero, one, zero, -sin, zero, cos)\n",
    "    elif axis == \"Z\":\n",
    "        R = (cos, -sin, zero, sin, cos, zero, zero, zero, one)\n",
    "    else:\n",
    "        raise ValueError(\"Axis must be X, Y, or Z\")\n",
    "    return torch.stack(R, -1).reshape(angle.shape + (3, 3))\n",
    "\n",
    "def euler_angles_to_matrix(euler_angles, convention):\n",
    "    matrices = [_axis_angle_rotation(c, e) for c, e in zip(convention, torch.unbind(euler_angles, -1))]\n",
    "    return torch.matmul(torch.matmul(matrices[0], matrices[1]), matrices[2])\n",
    "\n",
    "def euler_angles_to_rot_6d(euler_angles, convention=\"XYZ\"):\n",
    "    return matrix_to_rotation_6d(euler_angles_to_matrix(euler_angles, convention))\n",
    "\n",
    "def show_gif(images, save_dir=GIF_SAVE_DIR):\n",
    "    os.makedirs(save_dir, exist_ok=True)  # ← 디렉토리 생성 추가\n",
    "    path = os.path.join(save_dir, 'result.gif')\n",
    "    images[0].save(path, save_all=True, append_images=images[1:], duration=int(1000/15), loop=0)\n",
    "    display(IPyImage(filename=path))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def convert_h5py2np_dict(group, state_np_dict, indent=0):\n",
    "    \"\"\"\n",
    "    HDF5 그룹을 순회하며 numpy dict로 변환하고 구조 출력합니다.\n",
    "    \"\"\"\n",
    "    for name in group:\n",
    "        item = group[name]\n",
    "        print(\" \" * indent + f\"name: {name}\")\n",
    "        if isinstance(item, h5py.Group):\n",
    "            state_np_dict[name] = {}\n",
    "            convert_h5py2np_dict(item, state_np_dict[name], indent + 2)\n",
    "        elif isinstance(item, h5py.Dataset):\n",
    "            state_np_dict[name] = item[...]\n",
    "            print(\" \" * indent + f\"Dataset: {name} (Shape: {item.shape}, Dtype: {item.dtype})\")\n",
    "        else:\n",
    "            state_np_dict[name] = item\n",
    "\n",
    "\n",
    "def print_name(name):\n",
    "    \"\"\"단순히 이름을 출력\"\"\"\n",
    "    print(name)\n",
    "\n",
    "def generate_h5(obs_replay, action_replay, cfg, total_traj_cnt, act_root_dir_path, edit_flag):\n",
    "    data_dict = {\n",
    "        '/observations/qpos': obs_replay['qpos'],\n",
    "        '/observations/qvel': obs_replay['qvel'],\n",
    "        '/action': action_replay,\n",
    "        'is_edited': np.array(edit_flag)\n",
    "    }\n",
    "    for cam_name in cfg['camera_names']:\n",
    "        data_dict[f'/observations/images/{cam_name}'] = obs_replay['images'][cam_name]\n",
    "    data_dict['/observations/images/wrist'] = obs_replay['images']['wrist']\n",
    "\n",
    "    max_timesteps = len(data_dict['/observations/qpos'])\n",
    "    dataset_path = os.path.join(act_root_dir_path, f'episode_{total_traj_cnt}')\n",
    "    with h5py.File(dataset_path + '.hdf5', 'w', rdcc_nbytes=1024**2*2) as root:\n",
    "        root.attrs['sim'] = True\n",
    "        obs = root.create_group('observations')\n",
    "        image = obs.create_group('images')\n",
    "        for cam_name in cfg['camera_names'] + ['wrist']:\n",
    "            image.create_dataset(cam_name,\n",
    "                (max_timesteps, cfg['cam_height'], cfg['cam_width'], 3),\n",
    "                dtype='uint8', chunks=(1, cfg['cam_height'], cfg['cam_width'], 3))\n",
    "        obs.create_dataset('qpos', (max_timesteps, cfg['qpos_dim']))\n",
    "        obs.create_dataset('qvel', (max_timesteps, cfg['qpos_dim']))\n",
    "        root.create_dataset('action', (max_timesteps, cfg['action_dim']))\n",
    "        root.create_dataset('is_edited', (1,))\n",
    "        root.create_dataset(\"language_raw\", data=[np.string_(cfg['lang_intrs'])])\n",
    "        for name, array in data_dict.items():\n",
    "            root[name][...] = array\n",
    "\n",
    "# === 설정 ===\n",
    "args_src_root = DATASET_DIR\n",
    "dataset_name = \"droid_100\"\n",
    "cfg = {\n",
    "    \"task_name\": \"droid_1dot7t_lang\",\n",
    "    \"camera_names\": [\"left\", \"right\"],\n",
    "    \"cam_height\": 180,\n",
    "    \"cam_width\": 320,\n",
    "    \"state_dim\": 7,\n",
    "    \"qpos_dim\": 10,\n",
    "    \"action_dim\": 10,\n",
    "    \"lang_intrs\": \"close the lid of the box\"\n",
    "}\n",
    "act_target_root = OUTPUT_H5_DIR\n",
    "os.makedirs(act_target_root, exist_ok=True)\n",
    "act_root_dir_name = f'{cfg[\"task_name\"]}_succ_t0001_s-0-0'\n",
    "act_root_dir_path = os.path.join(act_target_root, act_root_dir_name)\n",
    "os.makedirs(act_root_dir_path, exist_ok=True)\n",
    "\n",
    "# === 데이터셋 로드 ===\n",
    "ds = tfds.load(dataset_name, data_dir=args_src_root, split=\"train\")\n",
    "total_traj_cnt = 0\n",
    "\n",
    "# === 변환 루프 ===\n",
    "for episode in tqdm(ds):\n",
    "    save_path = os.path.join(act_root_dir_path, f'episode_{total_traj_cnt}.hdf5')\n",
    "    if os.path.exists(save_path):\n",
    "        total_traj_cnt += 1\n",
    "        continue\n",
    "\n",
    "    cur_actions_dict = {}\n",
    "    cur_obs_image = {'1': [], '2': []}\n",
    "    cur_obs_wrist_image = []\n",
    "    cur_obs_gripper_pos = []\n",
    "    cur_obs_joint_state = []\n",
    "    cur_obs_ee_pos = []\n",
    "    cur_actions = []\n",
    "    edit_flag = 0\n",
    "\n",
    "    for idx, step in enumerate(episode['steps']):\n",
    "        if idx == 0:\n",
    "            cur_actions_dict = {k: [] for k in step['action_dict'].keys()}\n",
    "\n",
    "        l1 = step['language_instruction'].numpy().decode('utf-8')\n",
    "        l2 = step['language_instruction_2'].numpy().decode('utf-8')\n",
    "        l3 = step['language_instruction_3'].numpy().decode('utf-8')\n",
    "        raw_lang = l1 if len(l1) >= 4 else (l2 if len(l2) >= 4 else l3)\n",
    "        if len(raw_lang) < 4:\n",
    "            edit_flag = 1\n",
    "\n",
    "        cur_actions.append(step['action'].numpy()[:-1])\n",
    "        cur_obs_image['1'].append(step['observation']['exterior_image_1_left'].numpy())\n",
    "        cur_obs_image['2'].append(step['observation']['exterior_image_2_left'].numpy())\n",
    "        cur_obs_wrist_image.append(step['observation']['wrist_image_left'].numpy())\n",
    "        cur_obs_gripper_pos.append(step['observation']['gripper_position'].numpy())\n",
    "        cur_obs_joint_state.append(step['observation']['joint_position'].numpy())\n",
    "        cur_obs_ee_pos.append(step['observation']['cartesian_position'].numpy()[:2])\n",
    "\n",
    "        for k in cur_actions_dict:\n",
    "            cur_actions_dict[k].append(step['action_dict'][k].numpy())\n",
    "\n",
    "    if edit_flag:\n",
    "        left_imgs = np.array(cur_obs_image['1'])\n",
    "        right_imgs = np.array(cur_obs_image['2'])\n",
    "        wrist_imgs = np.array(cur_obs_wrist_image)\n",
    "\n",
    "        # 최소 길이만큼 잘라서 일치시킴\n",
    "        min_len = min(len(left_imgs), len(right_imgs), len(wrist_imgs))\n",
    "        left_imgs = left_imgs[:min_len]\n",
    "        right_imgs = right_imgs[:min_len]\n",
    "        wrist_imgs = wrist_imgs[:min_len]\n",
    "\n",
    "        # 이미지 연결 전에 dtype, shape 확인\n",
    "        print(f\"[DEBUG] left: {left_imgs.shape}, right: {right_imgs.shape}, wrist: {wrist_imgs.shape}\")\n",
    "        print(f\"[DEBUG] dtype check: {left_imgs.dtype}, {right_imgs.dtype}, {wrist_imgs.dtype}\")\n",
    "\n",
    "        # 수직 연결 또는 수평 연결 중 선택\n",
    "        try:\n",
    "            all_images_np = np.concatenate((left_imgs, right_imgs, wrist_imgs), axis=2)  # (T, H, W*3, 3)\n",
    "            all_images = [Image.fromarray(each.astype(np.uint8)) for each in all_images_np]\n",
    "            show_gif(all_images)\n",
    "        except Exception as e:\n",
    "            print(\"❌ GIF 생성 실패:\", e)\n",
    "\n",
    "        # 언어 입력 받기\n",
    "        raw_lang = input(\"please write a language instruction:\")\n",
    "\n",
    "\n",
    "\n",
    "    traj_len = min(len(cur_obs_image['1']), len(cur_obs_image['2']), len(cur_obs_wrist_image))\n",
    "\n",
    "    in_action = np.array(cur_actions_dict['cartesian_position'])\n",
    "    in_pos = in_action[:, :3]\n",
    "    in_rot = in_action[:, 3:6]\n",
    "    rot_6d = euler_angles_to_rot_6d(torch.from_numpy(in_rot)).numpy()\n",
    "    gripper = np.array(cur_actions_dict['gripper_position'])\n",
    "    traj_actions = np.concatenate((in_pos, rot_6d, gripper), axis=-1)[:traj_len]\n",
    "\n",
    "    traj_qpos = np.concatenate((np.array(cur_obs_joint_state),\n",
    "                                np.array(cur_obs_gripper_pos),\n",
    "                                np.array(cur_obs_ee_pos)), axis=-1)[:traj_len]\n",
    "    traj_qvel = np.zeros_like(traj_qpos)\n",
    "\n",
    "    obs_replay = {\n",
    "        'qpos': traj_qpos,\n",
    "        'qvel': traj_qvel,\n",
    "        'images': {\n",
    "            'left': np.array(cur_obs_image['1'])[:traj_len],\n",
    "            'right': np.array(cur_obs_image['2'])[:traj_len],\n",
    "            'wrist': np.array(cur_obs_wrist_image)[:traj_len]\n",
    "        }\n",
    "    }\n",
    "    cfg['lang_intrs'] = raw_lang\n",
    "    generate_h5(obs_replay, traj_actions, cfg, total_traj_cnt, act_root_dir_path, edit_flag)\n",
    "    total_traj_cnt += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tiny_data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
