{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6fae320",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/parkjeongsu/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-08-08 10:30:10.152808: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-08-08 10:30:10.181560: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-08-08 10:30:10.600085: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-08 10:30:11,766] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mNo private macro file found! (macros.py:53)\n",
      "\u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mIt is recommended to use a private macro file (macros.py:54)\n",
      "\u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mTo setup, run: python /home/parkjeongsu/anaconda3/envs/tinysuite/lib/python3.10/site-packages/robosuite/scripts/setup_macros.py (macros.py:55)\n",
      "/home/parkjeongsu/.local/lib/python3.10/site-packages/numba/core/errors.py:175: UserWarning: Insufficiently recent colorama version found. Numba requires colorama >= 0.3.9\n",
      "  warnings.warn(msg)\n",
      "\u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mCould not import robosuite_models. Some robots may not be available. If you want to use these robots, please install robosuite_models from source (https://github.com/ARISE-Initiative/robosuite_models) or through pip install. (__init__.py:30)\n",
      "\u001b[1m\u001b[33m[robosuite WARNING] \u001b[0mCould not load the mink-based whole-body IK. Make sure you install related import properly, otherwise you will not be able to use the default IK controller setting for GR1 robot. (__init__.py:40)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "from torchvision import transforms\n",
    "from einops import rearrange\n",
    "from llava_pythia.constants import IMAGE_TOKEN_INDEX, DEFAULT_IMAGE_TOKEN, DEFAULT_IM_START_TOKEN, DEFAULT_IM_END_TOKEN\n",
    "from llava_pythia.mm_utils import tokenizer_image_token, get_model_name_from_path\n",
    "from llava_pythia.model.builder import load_pretrained_model\n",
    "from llava_pythia.conversation import conv_templates\n",
    "from llava_pythia.model.language_model.pythia.llava_pythia import LlavaPythiaConfig\n",
    "import robosuite as suite\n",
    "from robosuite.controllers import load_composite_controller_config\n",
    "\n",
    "\n",
    "def get_image(ts, camera_names, rand_crop_resize=False):\n",
    "    imgs = [rearrange(ts.observation['images'][cam], 'h w c -> c h w') for cam in camera_names]\n",
    "    img_tensor = torch.from_numpy(np.stack(imgs) / 255.0).float().cuda().unsqueeze(0)\n",
    "    if rand_crop_resize:\n",
    "        print('rand crop resize is used!')\n",
    "        h, w = img_tensor.shape[-2:]\n",
    "        ratio = 0.95\n",
    "        dh, dw = int(h * (1 - ratio) / 2), int(w * (1 - ratio) / 2)\n",
    "        img_tensor = img_tensor[..., dh:h - dh, dw:w - dw].squeeze(0)\n",
    "        img_tensor = transforms.Resize((h, w), antialias=True)(img_tensor).unsqueeze(0)\n",
    "    return img_tensor\n",
    "\n",
    "\n",
    "def convert_actions(pred_action):\n",
    "    \"\"\"\n",
    "    Convert action from 10D [x, y, z, rot6D(6), gripper] to 7D [x, y, z, axis-angle(3), gripper].\n",
    "    This prevents mat1 @ mat2 error due to state/action shape mismatch.\n",
    "    \"\"\"\n",
    "    import torch.nn.functional as F\n",
    "\n",
    "    def rotation_6d_to_matrix(d6):\n",
    "        a1 = F.normalize(d6[..., 0:3], dim=-1)\n",
    "        a2 = d6[..., 3:6]\n",
    "        b2 = F.normalize(a2 - (a1 * a2).sum(-1, keepdim=True) * a1, dim=-1)\n",
    "        b3 = torch.cross(a1, b2, dim=-1)\n",
    "        return torch.stack([a1, b2, b3], dim=-2)  # (..., 3, 3)\n",
    "\n",
    "    def matrix_to_axis_angle(R):\n",
    "        cos_theta = ((R[..., 0, 0] + R[..., 1, 1] + R[..., 2, 2]) - 1) / 2\n",
    "        theta = torch.acos(torch.clamp(cos_theta, -1.0, 1.0))\n",
    "\n",
    "        wx = R[..., 2, 1] - R[..., 1, 2]\n",
    "        wy = R[..., 0, 2] - R[..., 2, 0]\n",
    "        wz = R[..., 1, 0] - R[..., 0, 1]\n",
    "        axis = torch.stack([wx, wy, wz], dim=-1)\n",
    "        axis = F.normalize(axis, dim=-1)\n",
    "        return axis * theta.unsqueeze(-1)\n",
    "\n",
    "\n",
    "    if isinstance(pred_action, np.ndarray):\n",
    "        pred_action = torch.from_numpy(pred_action).float()\n",
    "\n",
    "    if pred_action.shape[-1] == 10:\n",
    "        pos = pred_action[..., :3]\n",
    "        rot6d = pred_action[..., 3:9]\n",
    "        gripper = pred_action[..., 9:]\n",
    "\n",
    "        R = rotation_6d_to_matrix(rot6d)\n",
    "        axis_angle = matrix_to_axis_angle(R)\n",
    "        print(\"ğŸ” 10D Action:\", pred_action)\n",
    "        print(\"ğŸ“¦ Position:\", pos)\n",
    "        print(\"ğŸŒ€ rot6d:\", rot6d)\n",
    "        print(\"âœŠ Gripper:\", gripper)\n",
    "        return torch.cat([pos, axis_angle, gripper], dim=-1).cpu().numpy()\n",
    "    else:\n",
    "        return pred_action.cpu().numpy() if torch.is_tensor(pred_action) else pred_action\n",
    "        \n",
    "\n",
    "\n",
    "class llava_pythia_act_policy:\n",
    "    def __init__(self, policy_config, data_args=None):\n",
    "        self.policy_config = policy_config\n",
    "        self.data_args = data_args\n",
    "        self._load_policy()\n",
    "\n",
    "    def _load_policy(self):\n",
    "        base = self.policy_config[\"model_base\"] if self.policy_config['enable_lora'] else None\n",
    "        name = get_model_name_from_path(self.policy_config['model_path'])\n",
    "        path = self.policy_config[\"model_path\"]\n",
    "        self.tokenizer, self.policy, self.image_processor, self.context_len = load_pretrained_model(path, base, name, False, False)\n",
    "        self.config = LlavaPythiaConfig.from_pretrained('/'.join(path.split('/')[:-1]), trust_remote_code=True)\n",
    "\n",
    "    def _expand2square(self, imgs, bg_color):\n",
    "        b, c, h, w = imgs.shape\n",
    "        size = max(h, w)\n",
    "        canvas = np.full((b, size, size, c), bg_color, dtype=np.float32)\n",
    "        imgs_np = imgs.permute(0, 2, 3, 1).cpu().numpy()\n",
    "        if h >= w:\n",
    "            offset = (size - w) // 2\n",
    "            canvas[:, :h, offset:offset + w, :] = imgs_np\n",
    "        else:\n",
    "            offset = (size - h) // 2\n",
    "            canvas[:, offset:offset + h, :w, :] = imgs_np\n",
    "        return torch.tensor(canvas).to(dtype=imgs.dtype, device=imgs.device)\n",
    "\n",
    "    def process_batch_to_llava(self, curr_image, robo_state, raw_lang):\n",
    "        self.conv = conv_templates[self.policy_config['conv_mode']].copy()\n",
    "        curr_image = curr_image.squeeze(0) if curr_image.dim() == 5 else curr_image\n",
    "        img1, img2 = torch.chunk(curr_image, 2, dim=0)\n",
    "\n",
    "        # âœ… ì—¬ê¸°ì— states ì¶”ê°€\n",
    "        states = robo_state.unsqueeze(0) if robo_state.dim() == 1 else robo_state\n",
    "        print(\"âœ… DEBUG: states shape:\", states.shape)\n",
    "        \n",
    "        def prep(img):\n",
    "            img = self._expand2square(img, tuple(self.image_processor.image_mean))\n",
    "            return self.image_processor.preprocess(img, return_tensors='pt', do_normalize=True, do_rescale=False, do_center_crop=False)['pixel_values'].float().to(self.policy.device)\n",
    "\n",
    "        image_tensor, image_tensor_r = prep(img1), prep(img2)\n",
    "\n",
    "        prompt = DEFAULT_IMAGE_TOKEN + '\\n' + raw_lang\n",
    "        if self.policy.config.mm_use_im_start_end:\n",
    "            prompt = DEFAULT_IM_START_TOKEN + DEFAULT_IMAGE_TOKEN + DEFAULT_IM_END_TOKEN + '\\n' + raw_lang\n",
    "\n",
    "        self.conv.append_message(self.conv.roles[0], prompt)\n",
    "        self.conv.append_message(self.conv.roles[1], None)\n",
    "        prompt = self.conv.get_prompt() + \" <|endoftext|>\"\n",
    "\n",
    "        input_ids = tokenizer_image_token(prompt, self.tokenizer, IMAGE_TOKEN_INDEX, return_tensors='pt').unsqueeze(0).cuda().long()\n",
    "        attn_mask = input_ids.ne(self.tokenizer.pad_token_id).long()\n",
    "        robot_state_tensor = robo_state.to(self.policy.device, dtype=torch.float32)\n",
    "\n",
    "        return dict(input_ids=input_ids, attention_mask=attn_mask, images=image_tensor, images_r=image_tensor_r, states=states) # âœ… states=states\n",
    "\n",
    "\n",
    "class RobosuiteDeployEnv:\n",
    "    def __init__(self, env_name=\"Lift\", cameras=(\"sideview\", \"frontview\"), control_freq=20):\n",
    "        controller_config = load_composite_controller_config(robot=\"Panda\")\n",
    "        self.env = suite.make(env_name=env_name, robots=\"Panda\", controller_configs=controller_config,\n",
    "                              has_renderer=False, has_offscreen_renderer=True, render_camera=None,\n",
    "                              use_object_obs=True, use_camera_obs=True, control_freq=control_freq,\n",
    "                              camera_names=list(cameras), camera_heights=240, camera_widths=320)\n",
    "        sim = self.env.sim\n",
    "        cam_config = {\"sideview\": ([0.4, 0.8, 1.0], [0.653, 0.271, -0.653, 0.271]),\n",
    "                      \"frontview\": ([-0.4, -0.8, 1.0], [0.653, -0.271, 0.653, 0.271])}\n",
    "        for cam, (pos, quat) in cam_config.items():\n",
    "            cam_id = sim.model.camera_name2id(cam)\n",
    "            sim.model.cam_pos[cam_id] = pos\n",
    "            sim.model.cam_quat[cam_id] = quat\n",
    "        self.obs = self.env.reset()\n",
    "\n",
    "    def get_observation(self):\n",
    "        ts = type(\"Timestep\", (), {})()\n",
    "        ts.observation = {'images': {cam: self.obs[f'{cam}_image'] for cam in self.env.camera_names}}\n",
    "        eef = self.obs['robot0_eef_pos'], self.obs['robot0_eef_quat']        \n",
    "        robot_state = np.concatenate([*eef])\n",
    "        return ts, robot_state\n",
    "\n",
    "    def reset(self):\n",
    "        self.obs = self.env.reset()\n",
    "        return self.obs\n",
    "\n",
    "    def step(self, action):\n",
    "        self.obs, reward, done, info = self.env.step(action)\n",
    "        return self.obs, reward, done, info\n",
    "\n",
    "    def render_cameras(self, cameras=(\"sideview\", \"frontview\"), width=320, height=240):\n",
    "        self.env.sim.forward()\n",
    "        return [self.env.sim.render(camera_name=c, width=width, height=height, depth=False, mode=\"offscreen\")[..., ::-1] for c in cameras]\n",
    "\n",
    "\n",
    "def eval_bc(policy, deploy_env, policy_config, save_episode=True, num_rollouts=1,\n",
    "            raw_lang=None, n_steps=50, fps=20, camera_names=(\"sideview\", \"frontview\")):\n",
    "    \n",
    "    print(\"ğŸ” Combine layer í™•ì¸:\")\n",
    "    print(policy.policy.embed_out.combine)\n",
    "    assert raw_lang is not None\n",
    "\n",
    "    all_frames = []\n",
    "\n",
    "    for rollout_idx in range(num_rollouts):\n",
    "        deploy_env.reset()\n",
    "\n",
    "        for t in range(n_steps):\n",
    "            ts, robot_state = deploy_env.get_observation()\n",
    "            robot_state = robot_state[:7]\n",
    "            robot_tensor = torch.from_numpy(robot_state).float().cuda()\n",
    "\n",
    "            print(\"ğŸ¤– robot_state shape:\", robot_state.shape)\n",
    "            print(\"ğŸ¤– robot_state:\", robot_state)\n",
    "\n",
    "            image_tensor = get_image(ts, camera_names)\n",
    "            batch = policy.process_batch_to_llava(image_tensor, robot_tensor, raw_lang)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                print(\"âœ… batch keys:\", batch.keys())\n",
    "                if 'states' in batch:\n",
    "                    print(\"âœ… batch['states'] shape:\", batch['states'].shape)\n",
    "                else:\n",
    "                    print(\"âŒ 'states' not found in batch!\")\n",
    "\n",
    "                all_actions = policy.policy(**batch, eval=True)\n",
    "                action = convert_actions(all_actions[0][0].detach().cpu().numpy())\n",
    "                _, reward, done, _ = deploy_env.step(action)\n",
    "\n",
    "                # âœ… ì•ˆì •ì ì¸ í”„ë ˆì„ ì²˜ë¦¬\n",
    "                frames = deploy_env.render_cameras(cameras=camera_names, width=640, height=480)\n",
    "                cleaned_frames = []\n",
    "\n",
    "                for f_idx, f in enumerate(frames):\n",
    "                    print(f\"ğŸ“· Frame {f_idx}: shape={f.shape}, dtype={f.dtype}, min={f.min()}, max={f.max()}\")\n",
    "\n",
    "                    # NaN / Inf ì²´í¬\n",
    "                    if np.isnan(f).any() or np.isinf(f).any():\n",
    "                        print(f\"ğŸš« Frame {f_idx} contains NaN or Inf, skipping.\")\n",
    "                        continue\n",
    "\n",
    "                    # dtype ë³€í™˜\n",
    "                    if f.dtype in [np.float32, np.float64]:\n",
    "                        f = np.clip(f, 0.0, 1.0) * 255.0\n",
    "                        f = f.astype(np.uint8)\n",
    "                    elif f.dtype != np.uint8:\n",
    "                        print(f\"âš ï¸ ì˜ˆìƒì¹˜ ëª»í•œ dtype: {f.dtype}, ë³€í™˜ ì‹œë„\")\n",
    "                        f = f.astype(np.uint8)\n",
    "\n",
    "                    # ì±„ë„ ì²˜ë¦¬\n",
    "                    if f.shape[-1] == 4:\n",
    "                        f = f[..., :3]  # RGBA â†’ RGB\n",
    "                    elif f.shape[-1] == 1:\n",
    "                        f = np.repeat(f, 3, axis=-1)  # Gray â†’ RGB\n",
    "                    elif f.shape[-1] != 3:\n",
    "                        print(f\"âŒ ì•Œ ìˆ˜ ì—†ëŠ” ì±„ë„ ìˆ˜: {f.shape[-1]}, ê±´ë„ˆëœ€\")\n",
    "                        continue\n",
    "\n",
    "                    # í•´ìƒë„ ë§ì¶¤\n",
    "                    if f.shape[:2] != (480, 640):\n",
    "                        print(f\"ğŸ“ í•´ìƒë„ ë³€í™˜: {f.shape[:2]} â†’ (480, 640)\")\n",
    "                        f = cv2.resize(f, (640, 480))\n",
    "\n",
    "                    # RGB â†’ BGR\n",
    "                    try:\n",
    "                        f = cv2.cvtColor(f, cv2.COLOR_RGB2BGR)\n",
    "                    except Exception as e:\n",
    "                        print(f\"âŒ cvtColor ì‹¤íŒ¨: {e}\")\n",
    "                        continue\n",
    "\n",
    "                    cleaned_frames.append(f)\n",
    "\n",
    "                # í”„ë ˆì„ì´ ìœ íš¨í•  ê²½ìš° ì €ì¥\n",
    "                if cleaned_frames:\n",
    "                    try:\n",
    "                        frame_concat = np.concatenate(cleaned_frames, axis=1)\n",
    "                        all_frames.append(frame_concat)\n",
    "                    except Exception as e:\n",
    "                        print(f\"ğŸš¨ í”„ë ˆì„ ì—°ê²° ì‹¤íŒ¨: {e}\")\n",
    "\n",
    "                if done:\n",
    "                    break\n",
    "\n",
    "    # âœ… ì˜ìƒ ì €ì¥\n",
    "    if save_episode and all_frames:\n",
    "        h, w, _ = all_frames[0].shape\n",
    "        out = cv2.VideoWriter(\"rollout2.mp4\", cv2.VideoWriter_fourcc(*\"mp4v\"), fps, (w, h))\n",
    "        for f in all_frames:\n",
    "            out.write(f)\n",
    "        out.release()\n",
    "        print(\"ğŸ¥ rollout.mp4 ì €ì¥ ì™„ë£Œ\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4cf9eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load llaVA-Pythia MLLM!!!\n",
      "combine layer: Linear(in_features=519, out_features=512, bias=True)\n",
      "number of parameters: 7.283150e+07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.\n",
      "\u001b[1m\u001b[32m[robosuite INFO] \u001b[0mLoading controller configuration from: /home/parkjeongsu/anaconda3/envs/tinysuite/lib/python3.10/site-packages/robosuite/controllers/config/robots/default_panda.json (composite_controller_factory.py:121)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'device_map': 'cuda', 'torch_dtype': torch.float32}\n",
      "ğŸ” Combine layer í™•ì¸:\n",
      "Linear(in_features=519, out_features=512, bias=True)\n",
      "ğŸ¤– robot_state shape: (7,)\n",
      "ğŸ¤– robot_state: [-1.18559632e-01  4.97243169e-04  9.92006110e-01  9.99078308e-01\n",
      " -4.31242887e-03  4.27075767e-02 -3.24216032e-05]\n",
      "âœ… DEBUG: states shape: torch.Size([1, 7])\n",
      "âœ… batch keys: dict_keys(['input_ids', 'attention_mask', 'images', 'images_r', 'states'])\n",
      "âœ… batch['states'] shape: torch.Size([1, 7])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” 10D Action: tensor([-0.8237, -0.4657, -0.9315, -0.7792, -0.2652,  0.6735, -0.3490,  0.9388,\n",
      "         0.3686, -0.6870])\n",
      "ğŸ“¦ Position: tensor([-0.8237, -0.4657, -0.9315])\n",
      "ğŸŒ€ rot6d: tensor([-0.7792, -0.2652,  0.6735, -0.3490,  0.9388,  0.3686])\n",
      "âœŠ Gripper: tensor([-0.6870])\n",
      "ğŸ“· Frame 0: shape=(480, 640, 3), dtype=uint8, min=6, max=255\n",
      "ğŸ“· Frame 1: shape=(480, 640, 3), dtype=uint8, min=5, max=255\n",
      "ğŸ¤– robot_state shape: (7,)\n",
      "ğŸ¤– robot_state: [-0.13242507 -0.00938042  0.98043232  0.99961526  0.00173238  0.02663363\n",
      "  0.00754882]\n",
      "âœ… DEBUG: states shape: torch.Size([1, 7])\n",
      "âœ… batch keys: dict_keys(['input_ids', 'attention_mask', 'images', 'images_r', 'states'])\n",
      "âœ… batch['states'] shape: torch.Size([1, 7])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” 10D Action: tensor([-0.8367,  0.8281, -0.9516, -0.6911, -0.0803,  0.8389, -0.2463,  0.8176,\n",
      "        -0.6218,  0.7151])\n",
      "ğŸ“¦ Position: tensor([-0.8367,  0.8281, -0.9516])\n",
      "ğŸŒ€ rot6d: tensor([-0.6911, -0.0803,  0.8389, -0.2463,  0.8176, -0.6218])\n",
      "âœŠ Gripper: tensor([0.7151])\n",
      "ğŸ“· Frame 0: shape=(480, 640, 3), dtype=uint8, min=6, max=255\n",
      "ğŸ“· Frame 1: shape=(480, 640, 3), dtype=uint8, min=5, max=255\n",
      "ğŸ¤– robot_state shape: (7,)\n",
      "ğŸ¤– robot_state: [-0.15410474 -0.02572068  0.96267194  0.99969634  0.00954343 -0.00186055\n",
      "  0.02264282]\n",
      "âœ… DEBUG: states shape: torch.Size([1, 7])\n",
      "âœ… batch keys: dict_keys(['input_ids', 'attention_mask', 'images', 'images_r', 'states'])\n",
      "âœ… batch['states'] shape: torch.Size([1, 7])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” 10D Action: tensor([-0.8506,  0.7499, -0.9608, -0.9132,  0.8067,  0.6094, -0.0492, -0.5169,\n",
      "        -0.5512, -0.2338])\n",
      "ğŸ“¦ Position: tensor([-0.8506,  0.7499, -0.9608])\n",
      "ğŸŒ€ rot6d: tensor([-0.9132,  0.8067,  0.6094, -0.0492, -0.5169, -0.5512])\n",
      "âœŠ Gripper: tensor([-0.2338])\n",
      "ğŸ“· Frame 0: shape=(480, 640, 3), dtype=uint8, min=6, max=255\n",
      "ğŸ“· Frame 1: shape=(480, 640, 3), dtype=uint8, min=5, max=255\n",
      "ğŸ¤– robot_state shape: (7,)\n",
      "ğŸ¤– robot_state: [-0.17614387 -0.03288234  0.945566    0.9988496   0.00195834 -0.03306871\n",
      "  0.0346714 ]\n",
      "âœ… DEBUG: states shape: torch.Size([1, 7])\n",
      "âœ… batch keys: dict_keys(['input_ids', 'attention_mask', 'images', 'images_r', 'states'])\n",
      "âœ… batch['states'] shape: torch.Size([1, 7])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” 10D Action: tensor([-0.8235,  0.6701, -0.9348, -0.7825,  0.4182,  0.3959, -0.4842,  0.9269,\n",
      "        -0.2627,  0.4406])\n",
      "ğŸ“¦ Position: tensor([-0.8235,  0.6701, -0.9348])\n",
      "ğŸŒ€ rot6d: tensor([-0.7825,  0.4182,  0.3959, -0.4842,  0.9269, -0.2627])\n",
      "âœŠ Gripper: tensor([0.4406])\n",
      "ğŸ“· Frame 0: shape=(480, 640, 3), dtype=uint8, min=6, max=255\n",
      "ğŸ“· Frame 1: shape=(480, 640, 3), dtype=uint8, min=5, max=255\n",
      "ğŸ¤– robot_state shape: (7,)\n",
      "ğŸ¤– robot_state: [-0.20601776 -0.02039048  0.92663245  0.99699912 -0.02605136 -0.06611069\n",
      "  0.03071579]\n",
      "âœ… DEBUG: states shape: torch.Size([1, 7])\n",
      "âœ… batch keys: dict_keys(['input_ids', 'attention_mask', 'images', 'images_r', 'states'])\n",
      "âœ… batch['states'] shape: torch.Size([1, 7])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” 10D Action: tensor([-0.7863, -0.7661, -0.9764, -0.9007, -0.2837,  0.4680,  0.1523,  0.3748,\n",
      "         0.4625,  0.5689])\n",
      "ğŸ“¦ Position: tensor([-0.7863, -0.7661, -0.9764])\n",
      "ğŸŒ€ rot6d: tensor([-0.9007, -0.2837,  0.4680,  0.1523,  0.3748,  0.4625])\n",
      "âœŠ Gripper: tensor([0.5689])\n",
      "ğŸ“· Frame 0: shape=(480, 640, 3), dtype=uint8, min=6, max=255\n",
      "ğŸ“· Frame 1: shape=(480, 640, 3), dtype=uint8, min=5, max=255\n",
      "ğŸ¤– robot_state shape: (7,)\n",
      "ğŸ¤– robot_state: [-0.23039171 -0.01279267  0.9098191   0.99451542 -0.03478527 -0.09442772\n",
      "  0.02850371]\n",
      "âœ… DEBUG: states shape: torch.Size([1, 7])\n",
      "âœ… batch keys: dict_keys(['input_ids', 'attention_mask', 'images', 'images_r', 'states'])\n",
      "âœ… batch['states'] shape: torch.Size([1, 7])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” 10D Action: tensor([-0.8090,  0.4234, -0.9307, -0.8913,  0.9010,  0.8030, -0.1526,  0.9027,\n",
      "         0.1513,  0.8208])\n",
      "ğŸ“¦ Position: tensor([-0.8090,  0.4234, -0.9307])\n",
      "ğŸŒ€ rot6d: tensor([-0.8913,  0.9010,  0.8030, -0.1526,  0.9027,  0.1513])\n",
      "âœŠ Gripper: tensor([0.8208])\n",
      "ğŸ“· Frame 0: shape=(480, 640, 3), dtype=uint8, min=6, max=255\n",
      "ğŸ“· Frame 1: shape=(480, 640, 3), dtype=uint8, min=5, max=255\n",
      "ğŸ¤– robot_state shape: (7,)\n",
      "ğŸ¤– robot_state: [-0.26265446 -0.00240488  0.89238178  0.99148293 -0.03261928 -0.12444526\n",
      "  0.02027199]\n",
      "âœ… DEBUG: states shape: torch.Size([1, 7])\n",
      "âœ… batch keys: dict_keys(['input_ids', 'attention_mask', 'images', 'images_r', 'states'])\n",
      "âœ… batch['states'] shape: torch.Size([1, 7])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” 10D Action: tensor([-0.8187,  0.4726, -0.9552, -0.7245,  0.9585,  0.4844, -0.4016,  0.9266,\n",
      "         0.7524,  0.3455])\n",
      "ğŸ“¦ Position: tensor([-0.8187,  0.4726, -0.9552])\n",
      "ğŸŒ€ rot6d: tensor([-0.7245,  0.9585,  0.4844, -0.4016,  0.9266,  0.7524])\n",
      "âœŠ Gripper: tensor([0.3455])\n",
      "ğŸ“· Frame 0: shape=(480, 640, 3), dtype=uint8, min=6, max=255\n",
      "ğŸ“· Frame 1: shape=(480, 640, 3), dtype=uint8, min=5, max=255\n",
      "ğŸ¤– robot_state shape: (7,)\n",
      "ğŸ¤– robot_state: [-0.27932241  0.00839142  0.88166595  0.99063275 -0.03144365 -0.13247607\n",
      "  0.01039895]\n",
      "âœ… DEBUG: states shape: torch.Size([1, 7])\n",
      "âœ… batch keys: dict_keys(['input_ids', 'attention_mask', 'images', 'images_r', 'states'])\n",
      "âœ… batch['states'] shape: torch.Size([1, 7])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” 10D Action: tensor([-0.8546, -0.7386, -0.9704, -0.9588,  0.9153, -0.6135,  0.8090,  0.9135,\n",
      "        -0.2447, -0.5723])\n",
      "ğŸ“¦ Position: tensor([-0.8546, -0.7386, -0.9704])\n",
      "ğŸŒ€ rot6d: tensor([-0.9588,  0.9153, -0.6135,  0.8090,  0.9135, -0.2447])\n",
      "âœŠ Gripper: tensor([-0.5723])\n",
      "ğŸ“· Frame 0: shape=(480, 640, 3), dtype=uint8, min=6, max=255\n",
      "ğŸ“· Frame 1: shape=(480, 640, 3), dtype=uint8, min=5, max=255\n",
      "ğŸ¤– robot_state shape: (7,)\n",
      "ğŸ¤– robot_state: [-0.26270755 -0.00439144  0.87687487  0.99309806 -0.01035968 -0.11435369\n",
      "  0.02391987]\n",
      "âœ… DEBUG: states shape: torch.Size([1, 7])\n",
      "âœ… batch keys: dict_keys(['input_ids', 'attention_mask', 'images', 'images_r', 'states'])\n",
      "âœ… batch['states'] shape: torch.Size([1, 7])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” 10D Action: tensor([-0.8074, -0.6895, -0.9769,  0.1812, -0.5954, -0.2762,  0.5221,  0.8727,\n",
      "        -0.6052, -0.0824])\n",
      "ğŸ“¦ Position: tensor([-0.8074, -0.6895, -0.9769])\n",
      "ğŸŒ€ rot6d: tensor([ 0.1812, -0.5954, -0.2762,  0.5221,  0.8727, -0.6052])\n",
      "âœŠ Gripper: tensor([-0.0824])\n",
      "ğŸ“· Frame 0: shape=(480, 640, 3), dtype=uint8, min=6, max=255\n",
      "ğŸ“· Frame 1: shape=(480, 640, 3), dtype=uint8, min=5, max=255\n",
      "ğŸ¤– robot_state shape: (7,)\n",
      "ğŸ¤– robot_state: [-0.25562509 -0.01886351  0.86995996  0.99371104  0.01678158 -0.10294999\n",
      "  0.04071913]\n",
      "âœ… DEBUG: states shape: torch.Size([1, 7])\n",
      "âœ… batch keys: dict_keys(['input_ids', 'attention_mask', 'images', 'images_r', 'states'])\n",
      "âœ… batch['states'] shape: torch.Size([1, 7])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” 10D Action: tensor([-0.8516,  0.7100, -0.9598, -0.9398,  0.1474, -0.6773, -0.8272,  0.9451,\n",
      "         0.0439,  0.5406])\n",
      "ğŸ“¦ Position: tensor([-0.8516,  0.7100, -0.9598])\n",
      "ğŸŒ€ rot6d: tensor([-0.9398,  0.1474, -0.6773, -0.8272,  0.9451,  0.0439])\n",
      "âœŠ Gripper: tensor([0.5406])\n",
      "ğŸ“· Frame 0: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ“· Frame 1: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ¤– robot_state shape: (7,)\n",
      "ğŸ¤– robot_state: [-0.25611758 -0.01600159  0.86184293  0.99488214  0.02211914 -0.08989034\n",
      "  0.040497  ]\n",
      "âœ… DEBUG: states shape: torch.Size([1, 7])\n",
      "âœ… batch keys: dict_keys(['input_ids', 'attention_mask', 'images', 'images_r', 'states'])\n",
      "âœ… batch['states'] shape: torch.Size([1, 7])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” 10D Action: tensor([-0.7620,  0.3057, -0.9867, -0.9207,  0.4477, -0.4043,  0.8699,  0.9155,\n",
      "        -0.4709,  0.5514])\n",
      "ğŸ“¦ Position: tensor([-0.7620,  0.3057, -0.9867])\n",
      "ğŸŒ€ rot6d: tensor([-0.9207,  0.4477, -0.4043,  0.8699,  0.9155, -0.4709])\n",
      "âœŠ Gripper: tensor([0.5514])\n",
      "ğŸ“· Frame 0: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ“· Frame 1: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ¤– robot_state shape: (7,)\n",
      "ğŸ¤– robot_state: [-0.23785244 -0.02474736  0.85812473  0.99611917  0.0243719  -0.06758785\n",
      "  0.05083785]\n",
      "âœ… DEBUG: states shape: torch.Size([1, 7])\n",
      "âœ… batch keys: dict_keys(['input_ids', 'attention_mask', 'images', 'images_r', 'states'])\n",
      "âœ… batch['states'] shape: torch.Size([1, 7])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” 10D Action: tensor([-0.8411,  0.7931, -0.9375, -0.3717, -0.1192,  0.3261, -0.8949,  0.9348,\n",
      "        -0.1544,  0.8503])\n",
      "ğŸ“¦ Position: tensor([-0.8411,  0.7931, -0.9375])\n",
      "ğŸŒ€ rot6d: tensor([-0.3717, -0.1192,  0.3261, -0.8949,  0.9348, -0.1544])\n",
      "âœŠ Gripper: tensor([0.8503])\n",
      "ğŸ“· Frame 0: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ“· Frame 1: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ¤– robot_state shape: (7,)\n",
      "ğŸ¤– robot_state: [-0.23036385 -0.03385751  0.84814252  0.99496209  0.03175744 -0.06548268\n",
      "  0.06894873]\n",
      "âœ… DEBUG: states shape: torch.Size([1, 7])\n",
      "âœ… batch keys: dict_keys(['input_ids', 'attention_mask', 'images', 'images_r', 'states'])\n",
      "âœ… batch['states'] shape: torch.Size([1, 7])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” 10D Action: tensor([ 0.2411, -0.4503, -0.2982, -0.9189, -0.4556,  0.6013,  0.5039,  0.5809,\n",
      "        -0.8152, -0.8745])\n",
      "ğŸ“¦ Position: tensor([ 0.2411, -0.4503, -0.2982])\n",
      "ğŸŒ€ rot6d: tensor([-0.9189, -0.4556,  0.6013,  0.5039,  0.5809, -0.8152])\n",
      "âœŠ Gripper: tensor([-0.8745])\n",
      "ğŸ“· Frame 0: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ“· Frame 1: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ¤– robot_state shape: (7,)\n",
      "ğŸ¤– robot_state: [-0.24649387 -0.04324234  0.83539269  0.99249603  0.00877279 -0.08309952\n",
      "  0.08927001]\n",
      "âœ… DEBUG: states shape: torch.Size([1, 7])\n",
      "âœ… batch keys: dict_keys(['input_ids', 'attention_mask', 'images', 'images_r', 'states'])\n",
      "âœ… batch['states'] shape: torch.Size([1, 7])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” 10D Action: tensor([-0.8028, -0.3619,  0.4078, -0.9276, -0.1810,  0.4025, -0.1685,  0.9400,\n",
      "        -0.1154,  0.8576])\n",
      "ğŸ“¦ Position: tensor([-0.8028, -0.3619,  0.4078])\n",
      "ğŸŒ€ rot6d: tensor([-0.9276, -0.1810,  0.4025, -0.1685,  0.9400, -0.1154])\n",
      "âœŠ Gripper: tensor([0.8576])\n",
      "ğŸ“· Frame 0: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ“· Frame 1: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ¤– robot_state shape: (7,)\n",
      "ğŸ¤– robot_state: [-0.27540501 -0.04841562  0.83037418  0.98818559 -0.01016214 -0.10862301\n",
      "  0.10764298]\n",
      "âœ… DEBUG: states shape: torch.Size([1, 7])\n",
      "âœ… batch keys: dict_keys(['input_ids', 'attention_mask', 'images', 'images_r', 'states'])\n",
      "âœ… batch['states'] shape: torch.Size([1, 7])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” 10D Action: tensor([-0.8297, -0.8324, -0.2802, -0.9149, -0.7381,  0.1576, -0.1003,  0.9222,\n",
      "         0.5217,  0.8702])\n",
      "ğŸ“¦ Position: tensor([-0.8297, -0.8324, -0.2802])\n",
      "ğŸŒ€ rot6d: tensor([-0.9149, -0.7381,  0.1576, -0.1003,  0.9222,  0.5217])\n",
      "âœŠ Gripper: tensor([0.8702])\n",
      "ğŸ“· Frame 0: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ“· Frame 1: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ¤– robot_state shape: (7,)\n",
      "ğŸ¤– robot_state: [-0.29522333 -0.05935064  0.8287459   0.98253887 -0.00504666 -0.12997041\n",
      "  0.1330398 ]\n",
      "âœ… DEBUG: states shape: torch.Size([1, 7])\n",
      "âœ… batch keys: dict_keys(['input_ids', 'attention_mask', 'images', 'images_r', 'states'])\n",
      "âœ… batch['states'] shape: torch.Size([1, 7])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” 10D Action: tensor([-0.8077,  0.1905, -0.6526, -0.9660,  0.5231,  0.7675,  0.7552,  0.8412,\n",
      "        -0.0105,  0.8186])\n",
      "ğŸ“¦ Position: tensor([-0.8077,  0.1905, -0.6526])\n",
      "ğŸŒ€ rot6d: tensor([-0.9660,  0.5231,  0.7675,  0.7552,  0.8412, -0.0105])\n",
      "âœŠ Gripper: tensor([0.8186])\n",
      "ğŸ“· Frame 0: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ“· Frame 1: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ¤– robot_state shape: (7,)\n",
      "ğŸ¤– robot_state: [-0.32599846 -0.06175946  0.82261788  0.97614352  0.0198875  -0.15830575\n",
      "  0.14726714]\n",
      "âœ… DEBUG: states shape: torch.Size([1, 7])\n",
      "âœ… batch keys: dict_keys(['input_ids', 'attention_mask', 'images', 'images_r', 'states'])\n",
      "âœ… batch['states'] shape: torch.Size([1, 7])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” 10D Action: tensor([-0.8230, -0.0822, -0.9842, -0.9011,  0.9406,  0.1721, -0.0379,  0.8476,\n",
      "        -0.1153,  0.3005])\n",
      "ğŸ“¦ Position: tensor([-0.8230, -0.0822, -0.9842])\n",
      "ğŸŒ€ rot6d: tensor([-0.9011,  0.9406,  0.1721, -0.0379,  0.8476, -0.1153])\n",
      "âœŠ Gripper: tensor([0.3005])\n",
      "ğŸ“· Frame 0: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ“· Frame 1: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ¤– robot_state shape: (7,)\n",
      "ğŸ¤– robot_state: [-0.38181527 -0.0437359   0.81522089  0.97187434  0.02681504 -0.19393582\n",
      "  0.13088208]\n",
      "âœ… DEBUG: states shape: torch.Size([1, 7])\n",
      "âœ… batch keys: dict_keys(['input_ids', 'attention_mask', 'images', 'images_r', 'states'])\n",
      "âœ… batch['states'] shape: torch.Size([1, 7])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” 10D Action: tensor([-0.8463,  0.5164, -0.9573, -0.2053,  0.1135,  0.1484,  0.2609,  0.8741,\n",
      "         0.7369,  0.3286])\n",
      "ğŸ“¦ Position: tensor([-0.8463,  0.5164, -0.9573])\n",
      "ğŸŒ€ rot6d: tensor([-0.2053,  0.1135,  0.1484,  0.2609,  0.8741,  0.7369])\n",
      "âœŠ Gripper: tensor([0.3286])\n",
      "ğŸ“· Frame 0: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ“· Frame 1: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ¤– robot_state shape: (7,)\n",
      "ğŸ¤– robot_state: [-0.39473034 -0.03288977  0.81231084  0.97653492  0.02321191 -0.18612146\n",
      "  0.10582799]\n",
      "âœ… DEBUG: states shape: torch.Size([1, 7])\n",
      "âœ… batch keys: dict_keys(['input_ids', 'attention_mask', 'images', 'images_r', 'states'])\n",
      "âœ… batch['states'] shape: torch.Size([1, 7])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” 10D Action: tensor([-0.7035, -0.7664, -0.8614, -0.9648,  0.8951,  0.8311,  0.4697,  0.4150,\n",
      "        -0.2099,  0.4000])\n",
      "ğŸ“¦ Position: tensor([-0.7035, -0.7664, -0.8614])\n",
      "ğŸŒ€ rot6d: tensor([-0.9648,  0.8951,  0.8311,  0.4697,  0.4150, -0.2099])\n",
      "âœŠ Gripper: tensor([0.4000])\n",
      "ğŸ“· Frame 0: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ“· Frame 1: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ¤– robot_state shape: (7,)\n",
      "ğŸ¤– robot_state: [-0.3920504  -0.03346738  0.81159145  0.98184846  0.02668691 -0.16997713\n",
      "  0.07980712]\n",
      "âœ… DEBUG: states shape: torch.Size([1, 7])\n",
      "âœ… batch keys: dict_keys(['input_ids', 'attention_mask', 'images', 'images_r', 'states'])\n",
      "âœ… batch['states'] shape: torch.Size([1, 7])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” 10D Action: tensor([-0.8368, -0.5815, -0.9782, -0.8717, -0.5929, -0.2805, -0.2227,  0.9611,\n",
      "         0.0616,  0.3860])\n",
      "ğŸ“¦ Position: tensor([-0.8368, -0.5815, -0.9782])\n",
      "ğŸŒ€ rot6d: tensor([-0.8717, -0.5929, -0.2805, -0.2227,  0.9611,  0.0616])\n",
      "âœŠ Gripper: tensor([0.3860])\n",
      "ğŸ“· Frame 0: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ“· Frame 1: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ¤– robot_state shape: (7,)\n",
      "ğŸ¤– robot_state: [-0.39117705 -0.03583196  0.81048741  0.98615016  0.02823867 -0.15560055\n",
      "  0.04998905]\n",
      "âœ… DEBUG: states shape: torch.Size([1, 7])\n",
      "âœ… batch keys: dict_keys(['input_ids', 'attention_mask', 'images', 'images_r', 'states'])\n",
      "âœ… batch['states'] shape: torch.Size([1, 7])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” 10D Action: tensor([-0.8555, -0.3960, -0.9751, -0.9022, -0.0819, -0.2057,  0.4716,  0.9428,\n",
      "         0.8555,  0.0820])\n",
      "ğŸ“¦ Position: tensor([-0.8555, -0.3960, -0.9751])\n",
      "ğŸŒ€ rot6d: tensor([-0.9022, -0.0819, -0.2057,  0.4716,  0.9428,  0.8555])\n",
      "âœŠ Gripper: tensor([0.0820])\n",
      "ğŸ“· Frame 0: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ“· Frame 1: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ¤– robot_state shape: (7,)\n",
      "ğŸ¤– robot_state: [-0.38965373 -0.0347242   0.80991223  0.98998051  0.0028771  -0.13868304\n",
      "  0.02640712]\n",
      "âœ… DEBUG: states shape: torch.Size([1, 7])\n",
      "âœ… batch keys: dict_keys(['input_ids', 'attention_mask', 'images', 'images_r', 'states'])\n",
      "âœ… batch['states'] shape: torch.Size([1, 7])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” 10D Action: tensor([-0.8277,  0.0581, -0.9743, -0.3185, -0.5114,  0.7194,  0.4932,  0.8854,\n",
      "        -0.4261,  0.3762])\n",
      "ğŸ“¦ Position: tensor([-0.8277,  0.0581, -0.9743])\n",
      "ğŸŒ€ rot6d: tensor([-0.3185, -0.5114,  0.7194,  0.4932,  0.8854, -0.4261])\n",
      "âœŠ Gripper: tensor([0.3762])\n",
      "ğŸ“· Frame 0: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ“· Frame 1: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ¤– robot_state shape: (7,)\n",
      "ğŸ¤– robot_state: [-0.3884723  -0.03362101  0.80990538  0.99088648 -0.01770839 -0.13257351\n",
      "  0.01595779]\n",
      "âœ… DEBUG: states shape: torch.Size([1, 7])\n",
      "âœ… batch keys: dict_keys(['input_ids', 'attention_mask', 'images', 'images_r', 'states'])\n",
      "âœ… batch['states'] shape: torch.Size([1, 7])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” 10D Action: tensor([-0.8585, -0.1096, -0.9516, -0.9131,  0.9542, -0.6894,  0.3695,  0.7767,\n",
      "         0.2370, -0.9492])\n",
      "ğŸ“¦ Position: tensor([-0.8585, -0.1096, -0.9516])\n",
      "ğŸŒ€ rot6d: tensor([-0.9131,  0.9542, -0.6894,  0.3695,  0.7767,  0.2370])\n",
      "âœŠ Gripper: tensor([-0.9492])\n",
      "ğŸ“· Frame 0: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ“· Frame 1: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ¤– robot_state shape: (7,)\n",
      "ğŸ¤– robot_state: [-0.3882659  -0.03857474  0.81014876  0.99028525 -0.02913123 -0.13382952\n",
      "  0.02400326]\n",
      "âœ… DEBUG: states shape: torch.Size([1, 7])\n",
      "âœ… batch keys: dict_keys(['input_ids', 'attention_mask', 'images', 'images_r', 'states'])\n",
      "âœ… batch['states'] shape: torch.Size([1, 7])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” 10D Action: tensor([-0.8582, -0.4814, -0.3261, -0.9063, -0.5098,  0.5369, -0.1078, -0.3554,\n",
      "        -0.4350,  0.1094])\n",
      "ğŸ“¦ Position: tensor([-0.8582, -0.4814, -0.3261])\n",
      "ğŸŒ€ rot6d: tensor([-0.9063, -0.5098,  0.5369, -0.1078, -0.3554, -0.4350])\n",
      "âœŠ Gripper: tensor([0.1094])\n",
      "ğŸ“· Frame 0: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ“· Frame 1: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ¤– robot_state shape: (7,)\n",
      "ğŸ¤– robot_state: [-0.38765254 -0.03669042  0.81058069  0.9900642  -0.01752068 -0.13648458\n",
      "  0.02894589]\n",
      "âœ… DEBUG: states shape: torch.Size([1, 7])\n",
      "âœ… batch keys: dict_keys(['input_ids', 'attention_mask', 'images', 'images_r', 'states'])\n",
      "âœ… batch['states'] shape: torch.Size([1, 7])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” 10D Action: tensor([-0.8090,  0.0609, -0.3036, -0.9555,  0.3544, -0.2031, -0.7436,  0.9972,\n",
      "         0.4015,  0.9349])\n",
      "ğŸ“¦ Position: tensor([-0.8090,  0.0609, -0.3036])\n",
      "ğŸŒ€ rot6d: tensor([-0.9555,  0.3544, -0.2031, -0.7436,  0.9972,  0.4015])\n",
      "âœŠ Gripper: tensor([0.9349])\n",
      "ğŸ“· Frame 0: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ“· Frame 1: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ¤– robot_state shape: (7,)\n",
      "ğŸ¤– robot_state: [-0.38689223 -0.03859503  0.81111795  0.98941363 -0.01668674 -0.13929735\n",
      "  0.03712789]\n",
      "âœ… DEBUG: states shape: torch.Size([1, 7])\n",
      "âœ… batch keys: dict_keys(['input_ids', 'attention_mask', 'images', 'images_r', 'states'])\n",
      "âœ… batch['states'] shape: torch.Size([1, 7])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” 10D Action: tensor([-0.0548,  0.0037, -0.9701, -0.4063,  0.8471,  0.3614, -0.0953,  0.8714,\n",
      "        -0.9664,  0.1373])\n",
      "ğŸ“¦ Position: tensor([-0.0548,  0.0037, -0.9701])\n",
      "ğŸŒ€ rot6d: tensor([-0.4063,  0.8471,  0.3614, -0.0953,  0.8714, -0.9664])\n",
      "âœŠ Gripper: tensor([0.1373])\n",
      "ğŸ“· Frame 0: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ“· Frame 1: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ¤– robot_state shape: (7,)\n",
      "ğŸ¤– robot_state: [-0.3899073  -0.03099848  0.81116066  0.98909434 -0.02783994 -0.14114432\n",
      "  0.03155312]\n",
      "âœ… DEBUG: states shape: torch.Size([1, 7])\n",
      "âœ… batch keys: dict_keys(['input_ids', 'attention_mask', 'images', 'images_r', 'states'])\n",
      "âœ… batch['states'] shape: torch.Size([1, 7])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” 10D Action: tensor([-0.8335,  0.5886, -0.9250, -0.6614,  0.2204, -0.3670, -0.6186,  0.9675,\n",
      "         0.0559, -0.7914])\n",
      "ğŸ“¦ Position: tensor([-0.8335,  0.5886, -0.9250])\n",
      "ğŸŒ€ rot6d: tensor([-0.6614,  0.2204, -0.3670, -0.6186,  0.9675,  0.0559])\n",
      "âœŠ Gripper: tensor([-0.7914])\n",
      "ğŸ“· Frame 0: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ“· Frame 1: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ¤– robot_state shape: (7,)\n",
      "ğŸ¤– robot_state: [-0.38897977 -0.0305163   0.81049234  0.98871401 -0.04789082 -0.13915213\n",
      "  0.02806707]\n",
      "âœ… DEBUG: states shape: torch.Size([1, 7])\n",
      "âœ… batch keys: dict_keys(['input_ids', 'attention_mask', 'images', 'images_r', 'states'])\n",
      "âœ… batch['states'] shape: torch.Size([1, 7])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” 10D Action: tensor([-0.7974,  0.0729, -0.7563, -0.9018,  0.3874, -0.6649, -0.7535, -0.0992,\n",
      "         0.0459,  0.3927])\n",
      "ğŸ“¦ Position: tensor([-0.7974,  0.0729, -0.7563])\n",
      "ğŸŒ€ rot6d: tensor([-0.9018,  0.3874, -0.6649, -0.7535, -0.0992,  0.0459])\n",
      "âœŠ Gripper: tensor([0.3927])\n",
      "ğŸ“· Frame 0: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ“· Frame 1: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ¤– robot_state shape: (7,)\n",
      "ğŸ¤– robot_state: [-0.38915809 -0.03049233  0.81033585  0.98767655 -0.06928517 -0.13837956\n",
      "  0.02336013]\n",
      "âœ… DEBUG: states shape: torch.Size([1, 7])\n",
      "âœ… batch keys: dict_keys(['input_ids', 'attention_mask', 'images', 'images_r', 'states'])\n",
      "âœ… batch['states'] shape: torch.Size([1, 7])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” 10D Action: tensor([-0.8103,  0.3952, -0.9682, -0.9387, -0.0354,  0.6744, -0.1552, -0.0591,\n",
      "        -0.3917,  0.0839])\n",
      "ğŸ“¦ Position: tensor([-0.8103,  0.3952, -0.9682])\n",
      "ğŸŒ€ rot6d: tensor([-0.9387, -0.0354,  0.6744, -0.1552, -0.0591, -0.3917])\n",
      "âœŠ Gripper: tensor([0.0839])\n",
      "ğŸ“· Frame 0: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ“· Frame 1: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ¤– robot_state shape: (7,)\n",
      "ğŸ¤– robot_state: [-0.38939808 -0.03086412  0.81039137  0.98559045 -0.09807941 -0.13667228\n",
      "  0.01767982]\n",
      "âœ… DEBUG: states shape: torch.Size([1, 7])\n",
      "âœ… batch keys: dict_keys(['input_ids', 'attention_mask', 'images', 'images_r', 'states'])\n",
      "âœ… batch['states'] shape: torch.Size([1, 7])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” 10D Action: tensor([-0.8455, -0.8521, -0.9563, -0.8891,  0.8905,  0.6993, -0.0471,  0.7196,\n",
      "         0.6620,  0.5404])\n",
      "ğŸ“¦ Position: tensor([-0.8455, -0.8521, -0.9563])\n",
      "ğŸŒ€ rot6d: tensor([-0.8891,  0.8905,  0.6993, -0.0471,  0.7196,  0.6620])\n",
      "âœŠ Gripper: tensor([0.5404])\n",
      "ğŸ“· Frame 0: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ“· Frame 1: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ¤– robot_state shape: (7,)\n",
      "ğŸ¤– robot_state: [-0.3887435  -0.02835296  0.81040435  0.9853442  -0.10377848 -0.13529702\n",
      "  0.00464297]\n",
      "âœ… DEBUG: states shape: torch.Size([1, 7])\n",
      "âœ… batch keys: dict_keys(['input_ids', 'attention_mask', 'images', 'images_r', 'states'])\n",
      "âœ… batch['states'] shape: torch.Size([1, 7])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” 10D Action: tensor([-0.8142, -0.3479, -0.9735, -0.9432, -0.3301,  0.1475, -0.3775,  0.9016,\n",
      "        -0.6356, -0.5394])\n",
      "ğŸ“¦ Position: tensor([-0.8142, -0.3479, -0.9735])\n",
      "ğŸŒ€ rot6d: tensor([-0.9432, -0.3301,  0.1475, -0.3775,  0.9016, -0.6356])\n",
      "âœŠ Gripper: tensor([-0.5394])\n",
      "ğŸ“· Frame 0: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ“· Frame 1: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ¤– robot_state shape: (7,)\n",
      "ğŸ¤– robot_state: [-0.38765849 -0.02795476  0.81023712  0.9841197  -0.11898232 -0.13158888\n",
      " -0.00599894]\n",
      "âœ… DEBUG: states shape: torch.Size([1, 7])\n",
      "âœ… batch keys: dict_keys(['input_ids', 'attention_mask', 'images', 'images_r', 'states'])\n",
      "âœ… batch['states'] shape: torch.Size([1, 7])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” 10D Action: tensor([-0.8661, -0.8943, -0.9596, -0.4436, -0.6584,  0.8643, -0.0286,  0.5918,\n",
      "        -0.0961,  0.5029])\n",
      "ğŸ“¦ Position: tensor([-0.8661, -0.8943, -0.9596])\n",
      "ğŸŒ€ rot6d: tensor([-0.4436, -0.6584,  0.8643, -0.0286,  0.5918, -0.0961])\n",
      "âœŠ Gripper: tensor([0.5029])\n",
      "ğŸ“· Frame 0: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ“· Frame 1: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ¤– robot_state shape: (7,)\n",
      "ğŸ¤– robot_state: [-0.38677905 -0.03039206  0.81035782  0.98202634 -0.14115149 -0.12528027\n",
      " -0.00231913]\n",
      "âœ… DEBUG: states shape: torch.Size([1, 7])\n",
      "âœ… batch keys: dict_keys(['input_ids', 'attention_mask', 'images', 'images_r', 'states'])\n",
      "âœ… batch['states'] shape: torch.Size([1, 7])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” 10D Action: tensor([-0.8182, -0.6821, -0.9710, -0.9657, -0.4758,  0.1664,  0.1486,  0.9361,\n",
      "         0.4328, -0.8198])\n",
      "ğŸ“¦ Position: tensor([-0.8182, -0.6821, -0.9710])\n",
      "ğŸŒ€ rot6d: tensor([-0.9657, -0.4758,  0.1664,  0.1486,  0.9361,  0.4328])\n",
      "âœŠ Gripper: tensor([-0.8198])\n",
      "ğŸ“· Frame 0: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ“· Frame 1: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ¤– robot_state shape: (7,)\n",
      "ğŸ¤– robot_state: [-0.38579259 -0.03430308  0.81074952  0.9824569  -0.14380401 -0.11798899\n",
      "  0.01332068]\n",
      "âœ… DEBUG: states shape: torch.Size([1, 7])\n",
      "âœ… batch keys: dict_keys(['input_ids', 'attention_mask', 'images', 'images_r', 'states'])\n",
      "âœ… batch['states'] shape: torch.Size([1, 7])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” 10D Action: tensor([-0.8499,  0.8156, -0.9520, -0.0736,  0.9029,  0.1797, -0.6482,  0.9364,\n",
      "         0.3440, -0.1531])\n",
      "ğŸ“¦ Position: tensor([-0.8499,  0.8156, -0.9520])\n",
      "ğŸŒ€ rot6d: tensor([-0.0736,  0.9029,  0.1797, -0.6482,  0.9364,  0.3440])\n",
      "âœŠ Gripper: tensor([-0.1531])\n",
      "ğŸ“· Frame 0: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ“· Frame 1: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ¤– robot_state shape: (7,)\n",
      "ğŸ¤– robot_state: [-0.38516503 -0.0375808   0.81117595  0.98372242 -0.13620153 -0.11344459\n",
      "  0.02949021]\n",
      "âœ… DEBUG: states shape: torch.Size([1, 7])\n",
      "âœ… batch keys: dict_keys(['input_ids', 'attention_mask', 'images', 'images_r', 'states'])\n",
      "âœ… batch['states'] shape: torch.Size([1, 7])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” 10D Action: tensor([-0.8217, -0.2308, -0.9587, -0.0783,  0.6349, -0.2211, -0.7916,  0.8977,\n",
      "         0.8721,  0.1146])\n",
      "ğŸ“¦ Position: tensor([-0.8217, -0.2308, -0.9587])\n",
      "ğŸŒ€ rot6d: tensor([-0.0783,  0.6349, -0.2211, -0.7916,  0.8977,  0.8721])\n",
      "âœŠ Gripper: tensor([0.1146])\n",
      "ğŸ“· Frame 0: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ“· Frame 1: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ¤– robot_state shape: (7,)\n",
      "ğŸ¤– robot_state: [-0.38537718 -0.04019334  0.8114795   0.98330603 -0.13643037 -0.1131496\n",
      "  0.04114812]\n",
      "âœ… DEBUG: states shape: torch.Size([1, 7])\n",
      "âœ… batch keys: dict_keys(['input_ids', 'attention_mask', 'images', 'images_r', 'states'])\n",
      "âœ… batch['states'] shape: torch.Size([1, 7])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” 10D Action: tensor([-0.8073, -0.4535, -0.3412, -0.9813,  0.8577,  0.6911, -0.3827,  0.9445,\n",
      "         0.3218,  0.8515])\n",
      "ğŸ“¦ Position: tensor([-0.8073, -0.4535, -0.3412])\n",
      "ğŸŒ€ rot6d: tensor([-0.9813,  0.8577,  0.6911, -0.3827,  0.9445,  0.3218])\n",
      "âœŠ Gripper: tensor([0.8515])\n",
      "ğŸ“· Frame 0: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ“· Frame 1: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ¤– robot_state shape: (7,)\n",
      "ğŸ¤– robot_state: [-0.3848724  -0.03926362  0.81149381  0.98426423 -0.13119884 -0.11201819\n",
      "  0.03824553]\n",
      "âœ… DEBUG: states shape: torch.Size([1, 7])\n",
      "âœ… batch keys: dict_keys(['input_ids', 'attention_mask', 'images', 'images_r', 'states'])\n",
      "âœ… batch['states'] shape: torch.Size([1, 7])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” 10D Action: tensor([-0.8335,  0.1269, -0.9817, -0.9526, -0.0484,  0.7084, -0.8132,  0.9196,\n",
      "         0.3406, -0.2195])\n",
      "ğŸ“¦ Position: tensor([-0.8335,  0.1269, -0.9817])\n",
      "ğŸŒ€ rot6d: tensor([-0.9526, -0.0484,  0.7084, -0.8132,  0.9196,  0.3406])\n",
      "âœŠ Gripper: tensor([-0.2195])\n",
      "ğŸ“· Frame 0: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ“· Frame 1: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ¤– robot_state shape: (7,)\n",
      "ğŸ¤– robot_state: [-0.38313114 -0.03735288  0.81160524  0.98573438 -0.12759748 -0.10564906\n",
      "  0.02974729]\n",
      "âœ… DEBUG: states shape: torch.Size([1, 7])\n",
      "âœ… batch keys: dict_keys(['input_ids', 'attention_mask', 'images', 'images_r', 'states'])\n",
      "âœ… batch['states'] shape: torch.Size([1, 7])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” 10D Action: tensor([-0.7971,  0.3851, -0.9927, -0.9306,  0.3053,  0.5751,  0.9088,  0.8756,\n",
      "         0.6218, -0.0020])\n",
      "ğŸ“¦ Position: tensor([-0.7971,  0.3851, -0.9927])\n",
      "ğŸŒ€ rot6d: tensor([-0.9306,  0.3053,  0.5751,  0.9088,  0.8756,  0.6218])\n",
      "âœŠ Gripper: tensor([-0.0020])\n",
      "ğŸ“· Frame 0: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ“· Frame 1: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ¤– robot_state shape: (7,)\n",
      "ğŸ¤– robot_state: [-0.37989183 -0.0345583   0.81198041  0.98931525 -0.10959797 -0.09382304\n",
      "  0.02099645]\n",
      "âœ… DEBUG: states shape: torch.Size([1, 7])\n",
      "âœ… batch keys: dict_keys(['input_ids', 'attention_mask', 'images', 'images_r', 'states'])\n",
      "âœ… batch['states'] shape: torch.Size([1, 7])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” 10D Action: tensor([-0.7289,  0.3705, -0.9793,  0.3946, -0.0842, -0.2944, -0.8352,  0.9440,\n",
      "        -0.5589,  0.9307])\n",
      "ğŸ“¦ Position: tensor([-0.7289,  0.3705, -0.9793])\n",
      "ğŸŒ€ rot6d: tensor([ 0.3946, -0.0842, -0.2944, -0.8352,  0.9440, -0.5589])\n",
      "âœŠ Gripper: tensor([0.9307])\n",
      "ğŸ“· Frame 0: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ“· Frame 1: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ¤– robot_state shape: (7,)\n",
      "ğŸ¤– robot_state: [-0.37375046 -0.02107033  0.80882921  0.99314306 -0.08590987 -0.07909957\n",
      " -0.00544274]\n",
      "âœ… DEBUG: states shape: torch.Size([1, 7])\n",
      "âœ… batch keys: dict_keys(['input_ids', 'attention_mask', 'images', 'images_r', 'states'])\n",
      "âœ… batch['states'] shape: torch.Size([1, 7])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” 10D Action: tensor([-0.8663,  0.8582, -0.5340, -0.0940, -0.5017, -0.7067, -0.8551,  0.9628,\n",
      "         0.8568, -0.9490])\n",
      "ğŸ“¦ Position: tensor([-0.8663,  0.8582, -0.5340])\n",
      "ğŸŒ€ rot6d: tensor([-0.0940, -0.5017, -0.7067, -0.8551,  0.9628,  0.8568])\n",
      "âœŠ Gripper: tensor([-0.9490])\n",
      "ğŸ“· Frame 0: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ“· Frame 1: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ¤– robot_state shape: (7,)\n",
      "ğŸ¤– robot_state: [-0.37069627 -0.01430355  0.81023658  0.99255472 -0.09862553 -0.06134952\n",
      " -0.03666557]\n",
      "âœ… DEBUG: states shape: torch.Size([1, 7])\n",
      "âœ… batch keys: dict_keys(['input_ids', 'attention_mask', 'images', 'images_r', 'states'])\n",
      "âœ… batch['states'] shape: torch.Size([1, 7])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” 10D Action: tensor([-0.7919, -0.7316, -0.3803, -0.9507, -0.6539, -0.1398,  0.1553,  0.9140,\n",
      "         0.4924, -1.0000])\n",
      "ğŸ“¦ Position: tensor([-0.7919, -0.7316, -0.3803])\n",
      "ğŸŒ€ rot6d: tensor([-0.9507, -0.6539, -0.1398,  0.1553,  0.9140,  0.4924])\n",
      "âœŠ Gripper: tensor([-1.])\n",
      "ğŸ“· Frame 0: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ“· Frame 1: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ¤– robot_state shape: (7,)\n",
      "ğŸ¤– robot_state: [-0.36756653 -0.01280134  0.81128246  0.98816693 -0.13284131 -0.05109284\n",
      " -0.0571736 ]\n",
      "âœ… DEBUG: states shape: torch.Size([1, 7])\n",
      "âœ… batch keys: dict_keys(['input_ids', 'attention_mask', 'images', 'images_r', 'states'])\n",
      "âœ… batch['states'] shape: torch.Size([1, 7])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” 10D Action: tensor([-0.8367,  0.6028, -0.9463, -0.7772,  0.9009,  0.1739, -0.8571,  0.9440,\n",
      "        -0.1064, -0.8755])\n",
      "ğŸ“¦ Position: tensor([-0.8367,  0.6028, -0.9463])\n",
      "ğŸŒ€ rot6d: tensor([-0.7772,  0.9009,  0.1739, -0.8571,  0.9440, -0.1064])\n",
      "âœŠ Gripper: tensor([-0.8755])\n",
      "ğŸ“· Frame 0: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ“· Frame 1: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ¤– robot_state shape: (7,)\n",
      "ğŸ¤– robot_state: [-0.36528658 -0.013241    0.81203223  0.98326233 -0.16343386 -0.04325937\n",
      " -0.0679205 ]\n",
      "âœ… DEBUG: states shape: torch.Size([1, 7])\n",
      "âœ… batch keys: dict_keys(['input_ids', 'attention_mask', 'images', 'images_r', 'states'])\n",
      "âœ… batch['states'] shape: torch.Size([1, 7])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” 10D Action: tensor([-0.8501,  0.4479, -0.9491, -0.7493, -0.3136,  0.8584, -0.0053,  0.2623,\n",
      "        -0.4176, -0.2353])\n",
      "ğŸ“¦ Position: tensor([-0.8501,  0.4479, -0.9491])\n",
      "ğŸŒ€ rot6d: tensor([-0.7493, -0.3136,  0.8584, -0.0053,  0.2623, -0.4176])\n",
      "âœŠ Gripper: tensor([-0.2353])\n",
      "ğŸ“· Frame 0: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ“· Frame 1: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ¤– robot_state shape: (7,)\n",
      "ğŸ¤– robot_state: [-0.36293298 -0.01601254  0.81231408  0.97747326 -0.19588997 -0.03657537\n",
      " -0.06953695]\n",
      "âœ… DEBUG: states shape: torch.Size([1, 7])\n",
      "âœ… batch keys: dict_keys(['input_ids', 'attention_mask', 'images', 'images_r', 'states'])\n",
      "âœ… batch['states'] shape: torch.Size([1, 7])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” 10D Action: tensor([-0.8176, -0.3670, -0.4468, -0.9599,  0.9209,  0.7556, -0.0090,  0.8793,\n",
      "        -0.1321, -0.1163])\n",
      "ğŸ“¦ Position: tensor([-0.8176, -0.3670, -0.4468])\n",
      "ğŸŒ€ rot6d: tensor([-0.9599,  0.9209,  0.7556, -0.0090,  0.8793, -0.1321])\n",
      "âœŠ Gripper: tensor([-0.1163])\n",
      "ğŸ“· Frame 0: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ“· Frame 1: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ¤– robot_state shape: (7,)\n",
      "ğŸ¤– robot_state: [-0.36107045 -0.0184483   0.81244928  0.97367988 -0.21524809 -0.03172342\n",
      " -0.06789243]\n",
      "âœ… DEBUG: states shape: torch.Size([1, 7])\n",
      "âœ… batch keys: dict_keys(['input_ids', 'attention_mask', 'images', 'images_r', 'states'])\n",
      "âœ… batch['states'] shape: torch.Size([1, 7])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” 10D Action: tensor([-0.8612,  0.6960, -0.9116, -0.4582,  0.0452,  0.7409,  0.1267,  0.8364,\n",
      "        -0.2892,  0.7361])\n",
      "ğŸ“¦ Position: tensor([-0.8612,  0.6960, -0.9116])\n",
      "ğŸŒ€ rot6d: tensor([-0.4582,  0.0452,  0.7409,  0.1267,  0.8364, -0.2892])\n",
      "âœŠ Gripper: tensor([0.7361])\n",
      "ğŸ“· Frame 0: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ“· Frame 1: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ¤– robot_state shape: (7,)\n",
      "ğŸ¤– robot_state: [-0.36047351 -0.01854832  0.81262454  0.97225017 -0.22086866 -0.0314134\n",
      " -0.07042617]\n",
      "âœ… DEBUG: states shape: torch.Size([1, 7])\n",
      "âœ… batch keys: dict_keys(['input_ids', 'attention_mask', 'images', 'images_r', 'states'])\n",
      "âœ… batch['states'] shape: torch.Size([1, 7])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” 10D Action: tensor([-0.8105,  0.6680, -0.9606, -0.8087,  0.1423, -0.2727, -0.8067,  0.9424,\n",
      "         0.3886,  0.4930])\n",
      "ğŸ“¦ Position: tensor([-0.8105,  0.6680, -0.9606])\n",
      "ğŸŒ€ rot6d: tensor([-0.8087,  0.1423, -0.2727, -0.8067,  0.9424,  0.3886])\n",
      "âœŠ Gripper: tensor([0.4930])\n",
      "ğŸ“· Frame 0: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ“· Frame 1: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ¤– robot_state shape: (7,)\n",
      "ğŸ¤– robot_state: [-0.35881998 -0.01758622  0.81224374  0.97037939 -0.22823057 -0.03065367\n",
      " -0.07304103]\n",
      "âœ… DEBUG: states shape: torch.Size([1, 7])\n",
      "âœ… batch keys: dict_keys(['input_ids', 'attention_mask', 'images', 'images_r', 'states'])\n",
      "âœ… batch['states'] shape: torch.Size([1, 7])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” 10D Action: tensor([-0.8444,  0.6976, -0.9739, -0.9761, -0.6304,  0.6575,  0.0622,  0.9391,\n",
      "         0.3709,  0.8764])\n",
      "ğŸ“¦ Position: tensor([-0.8444,  0.6976, -0.9739])\n",
      "ğŸŒ€ rot6d: tensor([-0.9761, -0.6304,  0.6575,  0.0622,  0.9391,  0.3709])\n",
      "âœŠ Gripper: tensor([0.8764])\n",
      "ğŸ“· Frame 0: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ“· Frame 1: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ¤– robot_state shape: (7,)\n",
      "ğŸ¤– robot_state: [-0.35973876 -0.0203516   0.81111811  0.96879327 -0.23647142 -0.03178029\n",
      " -0.06716309]\n",
      "âœ… DEBUG: states shape: torch.Size([1, 7])\n",
      "âœ… batch keys: dict_keys(['input_ids', 'attention_mask', 'images', 'images_r', 'states'])\n",
      "âœ… batch['states'] shape: torch.Size([1, 7])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” 10D Action: tensor([-0.8218,  0.6466, -0.9857, -0.9428,  0.8891,  0.7465, -0.2547,  0.8715,\n",
      "        -0.0693,  0.4569])\n",
      "ğŸ“¦ Position: tensor([-0.8218,  0.6466, -0.9857])\n",
      "ğŸŒ€ rot6d: tensor([-0.9428,  0.8891,  0.7465, -0.2547,  0.8715, -0.0693])\n",
      "âœŠ Gripper: tensor([0.4569])\n",
      "ğŸ“· Frame 0: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ“· Frame 1: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ¤– robot_state shape: (7,)\n",
      "ğŸ¤– robot_state: [-0.3602385  -0.0206564   0.81075014  0.97037218 -0.23110551 -0.03221787\n",
      " -0.0626904 ]\n",
      "âœ… DEBUG: states shape: torch.Size([1, 7])\n",
      "âœ… batch keys: dict_keys(['input_ids', 'attention_mask', 'images', 'images_r', 'states'])\n",
      "âœ… batch['states'] shape: torch.Size([1, 7])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” 10D Action: tensor([-0.8630,  0.0916, -0.9776, -0.9044, -0.4402,  0.5701, -0.6433,  0.8929,\n",
      "        -0.7236,  0.2457])\n",
      "ğŸ“¦ Position: tensor([-0.8630,  0.0916, -0.9776])\n",
      "ğŸŒ€ rot6d: tensor([-0.9044, -0.4402,  0.5701, -0.6433,  0.8929, -0.7236])\n",
      "âœŠ Gripper: tensor([0.2457])\n",
      "ğŸ“· Frame 0: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ“· Frame 1: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ¤– robot_state shape: (7,)\n",
      "ğŸ¤– robot_state: [-0.36100112 -0.02334169  0.80967237  0.96899096 -0.23905008 -0.03408223\n",
      " -0.05244035]\n",
      "âœ… DEBUG: states shape: torch.Size([1, 7])\n",
      "âœ… batch keys: dict_keys(['input_ids', 'attention_mask', 'images', 'images_r', 'states'])\n",
      "âœ… batch['states'] shape: torch.Size([1, 7])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” 10D Action: tensor([-0.8172,  0.0194, -0.9654, -0.9400,  0.8090, -0.7056,  0.8168,  0.9500,\n",
      "         0.5069, -0.4807])\n",
      "ğŸ“¦ Position: tensor([-0.8172,  0.0194, -0.9654])\n",
      "ğŸŒ€ rot6d: tensor([-0.9400,  0.8090, -0.7056,  0.8168,  0.9500,  0.5069])\n",
      "âœŠ Gripper: tensor([-0.4807])\n",
      "ğŸ“· Frame 0: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ“· Frame 1: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ¤– robot_state shape: (7,)\n",
      "ğŸ¤– robot_state: [-0.36281904 -0.0274583   0.80800189  0.96854072 -0.24320452 -0.04142708\n",
      " -0.03262247]\n",
      "âœ… DEBUG: states shape: torch.Size([1, 7])\n",
      "âœ… batch keys: dict_keys(['input_ids', 'attention_mask', 'images', 'images_r', 'states'])\n",
      "âœ… batch['states'] shape: torch.Size([1, 7])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” 10D Action: tensor([-0.8325, -0.5072, -0.9770, -0.8884,  0.3227,  0.3625,  0.3104,  0.9463,\n",
      "         0.8470,  0.7194])\n",
      "ğŸ“¦ Position: tensor([-0.8325, -0.5072, -0.9770])\n",
      "ğŸŒ€ rot6d: tensor([-0.8884,  0.3227,  0.3625,  0.3104,  0.9463,  0.8470])\n",
      "âœŠ Gripper: tensor([0.7194])\n",
      "ğŸ“· Frame 0: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ“· Frame 1: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ¤– robot_state shape: (7,)\n",
      "ğŸ¤– robot_state: [-0.3634671  -0.02562407  0.8097995   0.97309189 -0.2256803  -0.04054587\n",
      " -0.0227291 ]\n",
      "âœ… DEBUG: states shape: torch.Size([1, 7])\n",
      "âœ… batch keys: dict_keys(['input_ids', 'attention_mask', 'images', 'images_r', 'states'])\n",
      "âœ… batch['states'] shape: torch.Size([1, 7])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” 10D Action: tensor([-0.8439,  0.4923, -0.9767, -0.9085, -0.1613, -0.4041, -0.0553,  0.8821,\n",
      "        -0.6086,  0.6545])\n",
      "ğŸ“¦ Position: tensor([-0.8439,  0.4923, -0.9767])\n",
      "ğŸŒ€ rot6d: tensor([-0.9085, -0.1613, -0.4041, -0.0553,  0.8821, -0.6086])\n",
      "âœŠ Gripper: tensor([0.6545])\n",
      "ğŸ“· Frame 0: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ“· Frame 1: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ¤– robot_state shape: (7,)\n",
      "ğŸ¤– robot_state: [-0.36145221 -0.02030167  0.80906221  0.97979791 -0.19572436 -0.03398653\n",
      " -0.02308565]\n",
      "âœ… DEBUG: states shape: torch.Size([1, 7])\n",
      "âœ… batch keys: dict_keys(['input_ids', 'attention_mask', 'images', 'images_r', 'states'])\n",
      "âœ… batch['states'] shape: torch.Size([1, 7])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” 10D Action: tensor([-0.8433, -0.4321, -0.9669, -0.9880,  0.1991,  0.8630,  0.2891,  0.9086,\n",
      "         0.5898,  0.7510])\n",
      "ğŸ“¦ Position: tensor([-0.8433, -0.4321, -0.9669])\n",
      "ğŸŒ€ rot6d: tensor([-0.9880,  0.1991,  0.8630,  0.2891,  0.9086,  0.5898])\n",
      "âœŠ Gripper: tensor([0.7510])\n",
      "ğŸ“· Frame 0: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ“· Frame 1: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ¤– robot_state shape: (7,)\n",
      "ğŸ¤– robot_state: [-0.36234648 -0.01928478  0.80932342  0.98436797 -0.17114733 -0.03508715\n",
      " -0.02229738]\n",
      "âœ… DEBUG: states shape: torch.Size([1, 7])\n",
      "âœ… batch keys: dict_keys(['input_ids', 'attention_mask', 'images', 'images_r', 'states'])\n",
      "âœ… batch['states'] shape: torch.Size([1, 7])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” 10D Action: tensor([-0.8573, -0.7719, -0.9758, -0.9768, -0.0591,  0.9086,  0.8318,  0.8128,\n",
      "        -0.7594, -0.7524])\n",
      "ğŸ“¦ Position: tensor([-0.8573, -0.7719, -0.9758])\n",
      "ğŸŒ€ rot6d: tensor([-0.9768, -0.0591,  0.9086,  0.8318,  0.8128, -0.7594])\n",
      "âœŠ Gripper: tensor([-0.7524])\n",
      "ğŸ“· Frame 0: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ“· Frame 1: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ¤– robot_state shape: (7,)\n",
      "ğŸ¤– robot_state: [-0.36612812 -0.02830449  0.80891017  0.98644093 -0.15940551 -0.0373707\n",
      " -0.01129604]\n",
      "âœ… DEBUG: states shape: torch.Size([1, 7])\n",
      "âœ… batch keys: dict_keys(['input_ids', 'attention_mask', 'images', 'images_r', 'states'])\n",
      "âœ… batch['states'] shape: torch.Size([1, 7])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” 10D Action: tensor([-0.7966, -0.3136, -0.9782, -0.9475, -0.6339, -0.1250, -0.7950,  0.9004,\n",
      "        -0.0506,  0.4242])\n",
      "ğŸ“¦ Position: tensor([-0.7966, -0.3136, -0.9782])\n",
      "ğŸŒ€ rot6d: tensor([-0.9475, -0.6339, -0.1250, -0.7950,  0.9004, -0.0506])\n",
      "âœŠ Gripper: tensor([0.4242])\n",
      "ğŸ“· Frame 0: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ“· Frame 1: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ¤– robot_state shape: (7,)\n",
      "ğŸ¤– robot_state: [-0.36509594 -0.02518015  0.80890191  0.98779258 -0.15009735 -0.03628152\n",
      " -0.02049996]\n",
      "âœ… DEBUG: states shape: torch.Size([1, 7])\n",
      "âœ… batch keys: dict_keys(['input_ids', 'attention_mask', 'images', 'images_r', 'states'])\n",
      "âœ… batch['states'] shape: torch.Size([1, 7])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” 10D Action: tensor([-0.8497, -0.7751, -0.7352, -0.6979,  0.8557,  0.7612,  0.1291,  0.1137,\n",
      "        -0.1954,  0.6958])\n",
      "ğŸ“¦ Position: tensor([-0.8497, -0.7751, -0.7352])\n",
      "ğŸŒ€ rot6d: tensor([-0.6979,  0.8557,  0.7612,  0.1291,  0.1137, -0.1954])\n",
      "âœŠ Gripper: tensor([0.6958])\n",
      "ğŸ“· Frame 0: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ“· Frame 1: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ¤– robot_state shape: (7,)\n",
      "ğŸ¤– robot_state: [-0.36441285 -0.02296846  0.8099368   0.98641414 -0.15586171 -0.03440893\n",
      " -0.03886252]\n",
      "âœ… DEBUG: states shape: torch.Size([1, 7])\n",
      "âœ… batch keys: dict_keys(['input_ids', 'attention_mask', 'images', 'images_r', 'states'])\n",
      "âœ… batch['states'] shape: torch.Size([1, 7])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” 10D Action: tensor([-0.8333,  0.7796,  0.0507, -0.3828,  0.9062,  0.8856, -0.8254,  0.8862,\n",
      "         0.8268, -0.4819])\n",
      "ğŸ“¦ Position: tensor([-0.8333,  0.7796,  0.0507])\n",
      "ğŸŒ€ rot6d: tensor([-0.3828,  0.9062,  0.8856, -0.8254,  0.8862,  0.8268])\n",
      "âœŠ Gripper: tensor([-0.4819])\n",
      "ğŸ“· Frame 0: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ“· Frame 1: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ¤– robot_state shape: (7,)\n",
      "ğŸ¤– robot_state: [-0.36470374 -0.02649016  0.81048246  0.98143588 -0.18325019 -0.03421734\n",
      " -0.04507943]\n",
      "âœ… DEBUG: states shape: torch.Size([1, 7])\n",
      "âœ… batch keys: dict_keys(['input_ids', 'attention_mask', 'images', 'images_r', 'states'])\n",
      "âœ… batch['states'] shape: torch.Size([1, 7])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” 10D Action: tensor([-0.7957, -0.6051, -0.9837, -0.7774,  0.5749, -0.7382, -0.2500,  0.8865,\n",
      "         0.0115, -0.2766])\n",
      "ğŸ“¦ Position: tensor([-0.7957, -0.6051, -0.9837])\n",
      "ğŸŒ€ rot6d: tensor([-0.7774,  0.5749, -0.7382, -0.2500,  0.8865,  0.0115])\n",
      "âœŠ Gripper: tensor([-0.2766])\n",
      "ğŸ“· Frame 0: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ“· Frame 1: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ¤– robot_state shape: (7,)\n",
      "ğŸ¤– robot_state: [-0.36494649 -0.03089723  0.80958847  0.97631414 -0.20947517 -0.03530282\n",
      " -0.04104352]\n",
      "âœ… DEBUG: states shape: torch.Size([1, 7])\n",
      "âœ… batch keys: dict_keys(['input_ids', 'attention_mask', 'images', 'images_r', 'states'])\n",
      "âœ… batch['states'] shape: torch.Size([1, 7])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” 10D Action: tensor([-0.8410, -0.8112, -0.9532, -0.9631, -0.4429,  0.7536, -0.8549,  0.9611,\n",
      "         0.8491,  0.7600])\n",
      "ğŸ“¦ Position: tensor([-0.8410, -0.8112, -0.9532])\n",
      "ğŸŒ€ rot6d: tensor([-0.9631, -0.4429,  0.7536, -0.8549,  0.9611,  0.8491])\n",
      "âœŠ Gripper: tensor([0.7600])\n",
      "ğŸ“· Frame 0: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ“· Frame 1: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ¤– robot_state shape: (7,)\n",
      "ğŸ¤– robot_state: [-0.36543975 -0.03327596  0.80909729  0.97536713 -0.21535823 -0.03525968\n",
      " -0.03219544]\n",
      "âœ… DEBUG: states shape: torch.Size([1, 7])\n",
      "âœ… batch keys: dict_keys(['input_ids', 'attention_mask', 'images', 'images_r', 'states'])\n",
      "âœ… batch['states'] shape: torch.Size([1, 7])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” 10D Action: tensor([-0.8602,  0.2459, -0.9538, -0.9406, -0.5183,  0.3108,  0.2004, -0.1325,\n",
      "        -0.1030, -0.8146])\n",
      "ğŸ“¦ Position: tensor([-0.8602,  0.2459, -0.9538])\n",
      "ğŸŒ€ rot6d: tensor([-0.9406, -0.5183,  0.3108,  0.2004, -0.1325, -0.1030])\n",
      "âœŠ Gripper: tensor([-0.8146])\n",
      "ğŸ“· Frame 0: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ“· Frame 1: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ¤– robot_state shape: (7,)\n",
      "ğŸ¤– robot_state: [-0.36384073 -0.02845292  0.80913657  0.98063253 -0.1901193  -0.03461641\n",
      " -0.03187775]\n",
      "âœ… DEBUG: states shape: torch.Size([1, 7])\n",
      "âœ… batch keys: dict_keys(['input_ids', 'attention_mask', 'images', 'images_r', 'states'])\n",
      "âœ… batch['states'] shape: torch.Size([1, 7])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” 10D Action: tensor([-0.8009,  0.7318, -0.0358, -0.9618, -0.1659,  0.1418, -0.8310,  0.9454,\n",
      "        -0.3021,  0.5064])\n",
      "ğŸ“¦ Position: tensor([-0.8009,  0.7318, -0.0358])\n",
      "ğŸŒ€ rot6d: tensor([-0.9618, -0.1659,  0.1418, -0.8310,  0.9454, -0.3021])\n",
      "âœŠ Gripper: tensor([0.5064])\n",
      "ğŸ“· Frame 0: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ“· Frame 1: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ¤– robot_state shape: (7,)\n",
      "ğŸ¤– robot_state: [-0.36603909 -0.03018055  0.81001594  0.98254712 -0.18079611 -0.03600937\n",
      " -0.02484447]\n",
      "âœ… DEBUG: states shape: torch.Size([1, 7])\n",
      "âœ… batch keys: dict_keys(['input_ids', 'attention_mask', 'images', 'images_r', 'states'])\n",
      "âœ… batch['states'] shape: torch.Size([1, 7])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” 10D Action: tensor([-0.7980, -0.7213, -0.8105, -0.7059,  0.9539, -0.2378, -0.8238,  0.8895,\n",
      "        -0.3744,  0.5021])\n",
      "ğŸ“¦ Position: tensor([-0.7980, -0.7213, -0.8105])\n",
      "ğŸŒ€ rot6d: tensor([-0.7059,  0.9539, -0.2378, -0.8238,  0.8895, -0.3744])\n",
      "âœŠ Gripper: tensor([0.5021])\n",
      "ğŸ“· Frame 0: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ“· Frame 1: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ¤– robot_state shape: (7,)\n",
      "ğŸ¤– robot_state: [-0.36602314 -0.0312721   0.80982489  0.98171651 -0.18562781 -0.0360609\n",
      " -0.02178581]\n",
      "âœ… DEBUG: states shape: torch.Size([1, 7])\n",
      "âœ… batch keys: dict_keys(['input_ids', 'attention_mask', 'images', 'images_r', 'states'])\n",
      "âœ… batch['states'] shape: torch.Size([1, 7])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” 10D Action: tensor([-0.8396, -0.8289, -0.9437, -0.9315, -0.0821,  0.4027,  0.3793,  0.8723,\n",
      "         0.8279,  0.6584])\n",
      "ğŸ“¦ Position: tensor([-0.8396, -0.8289, -0.9437])\n",
      "ğŸŒ€ rot6d: tensor([-0.9315, -0.0821,  0.4027,  0.3793,  0.8723,  0.8279])\n",
      "âœŠ Gripper: tensor([0.6584])\n",
      "ğŸ“· Frame 0: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ“· Frame 1: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ¤– robot_state shape: (7,)\n",
      "ğŸ¤– robot_state: [-0.36589452 -0.03107183  0.80954351  0.98191825 -0.18439175 -0.03602237\n",
      " -0.02320802]\n",
      "âœ… DEBUG: states shape: torch.Size([1, 7])\n",
      "âœ… batch keys: dict_keys(['input_ids', 'attention_mask', 'images', 'images_r', 'states'])\n",
      "âœ… batch['states'] shape: torch.Size([1, 7])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” 10D Action: tensor([-0.7949, -0.6624, -0.8915, -0.9338,  0.3799, -0.0787,  0.3646,  0.4436,\n",
      "         0.8558,  0.7707])\n",
      "ğŸ“¦ Position: tensor([-0.7949, -0.6624, -0.8915])\n",
      "ğŸŒ€ rot6d: tensor([-0.9338,  0.3799, -0.0787,  0.3646,  0.4436,  0.8558])\n",
      "âœŠ Gripper: tensor([0.7707])\n",
      "ğŸ“· Frame 0: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ“· Frame 1: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ¤– robot_state shape: (7,)\n",
      "ğŸ¤– robot_state: [-0.36602083 -0.03210894  0.80900411  0.98119062 -0.18860545 -0.03638664\n",
      " -0.01920822]\n",
      "âœ… DEBUG: states shape: torch.Size([1, 7])\n",
      "âœ… batch keys: dict_keys(['input_ids', 'attention_mask', 'images', 'images_r', 'states'])\n",
      "âœ… batch['states'] shape: torch.Size([1, 7])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” 10D Action: tensor([-0.6856, -0.3933, -0.9823, -0.6756,  0.9228,  0.8652, -0.7324,  0.8458,\n",
      "        -0.4786, -0.9423])\n",
      "ğŸ“¦ Position: tensor([-0.6856, -0.3933, -0.9823])\n",
      "ğŸŒ€ rot6d: tensor([-0.6756,  0.9228,  0.8652, -0.7324,  0.8458, -0.4786])\n",
      "âœŠ Gripper: tensor([-0.9423])\n",
      "ğŸ“· Frame 0: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ“· Frame 1: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ¤– robot_state shape: (7,)\n",
      "ğŸ¤– robot_state: [-0.36610463 -0.03314361  0.80890575  0.97844943 -0.20255626 -0.03647426\n",
      " -0.01665241]\n",
      "âœ… DEBUG: states shape: torch.Size([1, 7])\n",
      "âœ… batch keys: dict_keys(['input_ids', 'attention_mask', 'images', 'images_r', 'states'])\n",
      "âœ… batch['states'] shape: torch.Size([1, 7])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” 10D Action: tensor([-0.8021, -0.6577, -0.9794, -0.9207,  0.8721,  0.7296,  0.4125,  0.6360,\n",
      "         0.0237, -0.4520])\n",
      "ğŸ“¦ Position: tensor([-0.8021, -0.6577, -0.9794])\n",
      "ğŸŒ€ rot6d: tensor([-0.9207,  0.8721,  0.7296,  0.4125,  0.6360,  0.0237])\n",
      "âœŠ Gripper: tensor([-0.4520])\n",
      "ğŸ“· Frame 0: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ“· Frame 1: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ¤– robot_state shape: (7,)\n",
      "ğŸ¤– robot_state: [-0.36525615 -0.03144094  0.80931319  0.97737668 -0.20681249 -0.03572236\n",
      " -0.02621719]\n",
      "âœ… DEBUG: states shape: torch.Size([1, 7])\n",
      "âœ… batch keys: dict_keys(['input_ids', 'attention_mask', 'images', 'images_r', 'states'])\n",
      "âœ… batch['states'] shape: torch.Size([1, 7])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” 10D Action: tensor([-0.8075, -0.0920, -0.9886, -0.9587,  0.5291, -0.3806,  0.2629,  0.8887,\n",
      "        -0.8302,  0.2431])\n",
      "ğŸ“¦ Position: tensor([-0.8075, -0.0920, -0.9886])\n",
      "ğŸŒ€ rot6d: tensor([-0.9587,  0.5291, -0.3806,  0.2629,  0.8887, -0.8302])\n",
      "âœŠ Gripper: tensor([0.2431])\n",
      "ğŸ“· Frame 0: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ“· Frame 1: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ¤– robot_state shape: (7,)\n",
      "ğŸ¤– robot_state: [-0.36555596 -0.03292909  0.80926794  0.97698332 -0.20812827 -0.03621149\n",
      " -0.02957959]\n",
      "âœ… DEBUG: states shape: torch.Size([1, 7])\n",
      "âœ… batch keys: dict_keys(['input_ids', 'attention_mask', 'images', 'images_r', 'states'])\n",
      "âœ… batch['states'] shape: torch.Size([1, 7])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” 10D Action: tensor([-0.8333, -0.2571, -0.9616, -0.8863,  0.7464, -0.1191,  0.9129,  0.8618,\n",
      "         0.3664, -0.0974])\n",
      "ğŸ“¦ Position: tensor([-0.8333, -0.2571, -0.9616])\n",
      "ğŸŒ€ rot6d: tensor([-0.8863,  0.7464, -0.1191,  0.9129,  0.8618,  0.3664])\n",
      "âœŠ Gripper: tensor([-0.0974])\n",
      "ğŸ“· Frame 0: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ“· Frame 1: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ¤– robot_state shape: (7,)\n",
      "ğŸ¤– robot_state: [-0.36599426 -0.03510195  0.809293    0.97808331 -0.20425837 -0.03561208\n",
      " -0.01906121]\n",
      "âœ… DEBUG: states shape: torch.Size([1, 7])\n",
      "âœ… batch keys: dict_keys(['input_ids', 'attention_mask', 'images', 'images_r', 'states'])\n",
      "âœ… batch['states'] shape: torch.Size([1, 7])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” 10D Action: tensor([-0.8251, -0.7864, -0.9063, -0.1450, -0.0525,  0.8739, -0.6784,  0.8964,\n",
      "         0.2449, -0.7422])\n",
      "ğŸ“¦ Position: tensor([-0.8251, -0.7864, -0.9063])\n",
      "ğŸŒ€ rot6d: tensor([-0.1450, -0.0525,  0.8739, -0.6784,  0.8964,  0.2449])\n",
      "âœŠ Gripper: tensor([-0.7422])\n",
      "ğŸ“· Frame 0: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ“· Frame 1: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ¤– robot_state shape: (7,)\n",
      "ğŸ¤– robot_state: [-3.67159101e-01 -3.82213323e-02  8.08997057e-01  9.77792890e-01\n",
      " -2.06365699e-01 -3.65157439e-02  9.28955754e-04]\n",
      "âœ… DEBUG: states shape: torch.Size([1, 7])\n",
      "âœ… batch keys: dict_keys(['input_ids', 'attention_mask', 'images', 'images_r', 'states'])\n",
      "âœ… batch['states'] shape: torch.Size([1, 7])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” 10D Action: tensor([-0.8204, -0.4409, -0.9833, -0.9133, -0.4830,  0.8918,  0.3207,  0.2571,\n",
      "        -0.0859, -0.0531])\n",
      "ğŸ“¦ Position: tensor([-0.8204, -0.4409, -0.9833])\n",
      "ğŸŒ€ rot6d: tensor([-0.9133, -0.4830,  0.8918,  0.3207,  0.2571, -0.0859])\n",
      "âœŠ Gripper: tensor([-0.0531])\n",
      "ğŸ“· Frame 0: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ“· Frame 1: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ¤– robot_state shape: (7,)\n",
      "ğŸ¤– robot_state: [-0.36687505 -0.03952885  0.80969179  0.98179978 -0.18569589 -0.03570125\n",
      "  0.01765343]\n",
      "âœ… DEBUG: states shape: torch.Size([1, 7])\n",
      "âœ… batch keys: dict_keys(['input_ids', 'attention_mask', 'images', 'images_r', 'states'])\n",
      "âœ… batch['states'] shape: torch.Size([1, 7])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” 10D Action: tensor([-0.8225,  0.7013, -0.9769, -0.9385, -0.4275, -0.7023,  0.0041,  0.9426,\n",
      "         0.2912, -0.6626])\n",
      "ğŸ“¦ Position: tensor([-0.8225,  0.7013, -0.9769])\n",
      "ğŸŒ€ rot6d: tensor([-0.9385, -0.4275, -0.7023,  0.0041,  0.9426,  0.2912])\n",
      "âœŠ Gripper: tensor([-0.6626])\n",
      "ğŸ“· Frame 0: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ“· Frame 1: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ¤– robot_state shape: (7,)\n",
      "ğŸ¤– robot_state: [-0.36174006 -0.02796954  0.80880682  0.98613541 -0.16208431 -0.03298694\n",
      "  0.01332284]\n",
      "âœ… DEBUG: states shape: torch.Size([1, 7])\n",
      "âœ… batch keys: dict_keys(['input_ids', 'attention_mask', 'images', 'images_r', 'states'])\n",
      "âœ… batch['states'] shape: torch.Size([1, 7])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” 10D Action: tensor([-0.8303, -0.3632, -0.9785, -0.9359,  0.0424, -0.7201, -0.3250,  0.8649,\n",
      "        -0.6945, -0.5633])\n",
      "ğŸ“¦ Position: tensor([-0.8303, -0.3632, -0.9785])\n",
      "ğŸŒ€ rot6d: tensor([-0.9359,  0.0424, -0.7201, -0.3250,  0.8649, -0.6945])\n",
      "âœŠ Gripper: tensor([-0.5633])\n",
      "ğŸ“· Frame 0: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ“· Frame 1: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ¤– robot_state shape: (7,)\n",
      "ğŸ¤– robot_state: [-0.36147978 -0.02788792  0.80862443  0.98745855 -0.15368217 -0.03283488\n",
      "  0.0151418 ]\n",
      "âœ… DEBUG: states shape: torch.Size([1, 7])\n",
      "âœ… batch keys: dict_keys(['input_ids', 'attention_mask', 'images', 'images_r', 'states'])\n",
      "âœ… batch['states'] shape: torch.Size([1, 7])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” 10D Action: tensor([-0.7248,  0.1371, -0.9446, -0.9865,  0.2337,  0.8896, -0.8765,  0.5213,\n",
      "         0.3046,  0.7116])\n",
      "ğŸ“¦ Position: tensor([-0.7248,  0.1371, -0.9446])\n",
      "ğŸŒ€ rot6d: tensor([-0.9865,  0.2337,  0.8896, -0.8765,  0.5213,  0.3046])\n",
      "âœŠ Gripper: tensor([0.7116])\n",
      "ğŸ“· Frame 0: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ“· Frame 1: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ¤– robot_state shape: (7,)\n",
      "ğŸ¤– robot_state: [-0.36332219 -0.03339098  0.8092166   0.98708912 -0.15481906 -0.03354724\n",
      "  0.02367949]\n",
      "âœ… DEBUG: states shape: torch.Size([1, 7])\n",
      "âœ… batch keys: dict_keys(['input_ids', 'attention_mask', 'images', 'images_r', 'states'])\n",
      "âœ… batch['states'] shape: torch.Size([1, 7])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” 10D Action: tensor([-0.8818, -0.7326, -0.4782, -0.0434,  0.3536,  0.8614, -0.7749, -0.5455,\n",
      "        -0.4617, -0.3806])\n",
      "ğŸ“¦ Position: tensor([-0.8818, -0.7326, -0.4782])\n",
      "ğŸŒ€ rot6d: tensor([-0.0434,  0.3536,  0.8614, -0.7749, -0.5455, -0.4617])\n",
      "âœŠ Gripper: tensor([-0.3806])\n",
      "ğŸ“· Frame 0: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ“· Frame 1: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ¤– robot_state shape: (7,)\n",
      "ğŸ¤– robot_state: [-0.37009964 -0.04922685  0.81153536  0.98170168 -0.18027058 -0.03659455\n",
      "  0.04924592]\n",
      "âœ… DEBUG: states shape: torch.Size([1, 7])\n",
      "âœ… batch keys: dict_keys(['input_ids', 'attention_mask', 'images', 'images_r', 'states'])\n",
      "âœ… batch['states'] shape: torch.Size([1, 7])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” 10D Action: tensor([-0.8244,  0.7404, -0.9738, -0.0407, -0.0296,  0.8305, -0.2745,  0.8889,\n",
      "        -0.0446,  0.1731])\n",
      "ğŸ“¦ Position: tensor([-0.8244,  0.7404, -0.9738])\n",
      "ğŸŒ€ rot6d: tensor([-0.0407, -0.0296,  0.8305, -0.2745,  0.8889, -0.0446])\n",
      "âœŠ Gripper: tensor([0.1731])\n",
      "ğŸ“· Frame 0: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ“· Frame 1: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ¤– robot_state shape: (7,)\n",
      "ğŸ¤– robot_state: [-0.37128414 -0.05326216  0.81196585  0.98095794 -0.1786554  -0.03857195\n",
      "  0.0656961 ]\n",
      "âœ… DEBUG: states shape: torch.Size([1, 7])\n",
      "âœ… batch keys: dict_keys(['input_ids', 'attention_mask', 'images', 'images_r', 'states'])\n",
      "âœ… batch['states'] shape: torch.Size([1, 7])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” 10D Action: tensor([-0.7875,  0.5213, -0.9786, -0.1457, -0.4862,  0.1691, -0.1470,  0.8658,\n",
      "        -0.7244, -0.0281])\n",
      "ğŸ“¦ Position: tensor([-0.7875,  0.5213, -0.9786])\n",
      "ğŸŒ€ rot6d: tensor([-0.1457, -0.4862,  0.1691, -0.1470,  0.8658, -0.7244])\n",
      "âœŠ Gripper: tensor([-0.0281])\n",
      "ğŸ“· Frame 0: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ“· Frame 1: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ¤– robot_state shape: (7,)\n",
      "ğŸ¤– robot_state: [-0.36571976 -0.04364513  0.81098497  0.98605044 -0.15174167 -0.03574542\n",
      "  0.0583203 ]\n",
      "âœ… DEBUG: states shape: torch.Size([1, 7])\n",
      "âœ… batch keys: dict_keys(['input_ids', 'attention_mask', 'images', 'images_r', 'states'])\n",
      "âœ… batch['states'] shape: torch.Size([1, 7])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” 10D Action: tensor([-0.8012,  0.0334, -0.9712, -0.8889,  0.1445,  0.1392, -0.5249,  0.3179,\n",
      "        -0.8071, -0.7932])\n",
      "ğŸ“¦ Position: tensor([-0.8012,  0.0334, -0.9712])\n",
      "ğŸŒ€ rot6d: tensor([-0.8889,  0.1445,  0.1392, -0.5249,  0.3179, -0.8071])\n",
      "âœŠ Gripper: tensor([-0.7932])\n",
      "ğŸ“· Frame 0: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ“· Frame 1: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ¤– robot_state shape: (7,)\n",
      "ğŸ¤– robot_state: [-0.36421574 -0.03890869  0.81055727  0.98653581 -0.15175631 -0.03258162\n",
      "  0.05153199]\n",
      "âœ… DEBUG: states shape: torch.Size([1, 7])\n",
      "âœ… batch keys: dict_keys(['input_ids', 'attention_mask', 'images', 'images_r', 'states'])\n",
      "âœ… batch['states'] shape: torch.Size([1, 7])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” 10D Action: tensor([-0.8367,  0.7378, -0.9702, -0.9207,  0.6652,  0.1755, -0.7569,  0.9735,\n",
      "         0.7006,  0.4326])\n",
      "ğŸ“¦ Position: tensor([-0.8367,  0.7378, -0.9702])\n",
      "ğŸŒ€ rot6d: tensor([-0.9207,  0.6652,  0.1755, -0.7569,  0.9735,  0.7006])\n",
      "âœŠ Gripper: tensor([0.4326])\n",
      "ğŸ“· Frame 0: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ“· Frame 1: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ¤– robot_state shape: (7,)\n",
      "ğŸ¤– robot_state: [-0.36768253 -0.04552403  0.81185576  0.98193703 -0.17580621 -0.03445124\n",
      "  0.06086831]\n",
      "âœ… DEBUG: states shape: torch.Size([1, 7])\n",
      "âœ… batch keys: dict_keys(['input_ids', 'attention_mask', 'images', 'images_r', 'states'])\n",
      "âœ… batch['states'] shape: torch.Size([1, 7])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” 10D Action: tensor([-0.8466,  0.0695, -0.7692, -0.8907,  0.6439,  0.6391, -0.4394,  0.8524,\n",
      "        -0.2667, -0.0764])\n",
      "ğŸ“¦ Position: tensor([-0.8466,  0.0695, -0.7692])\n",
      "ğŸŒ€ rot6d: tensor([-0.8907,  0.6439,  0.6391, -0.4394,  0.8524, -0.2667])\n",
      "âœŠ Gripper: tensor([-0.0764])\n",
      "ğŸ“· Frame 0: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ“· Frame 1: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ¤– robot_state shape: (7,)\n",
      "ğŸ¤– robot_state: [-0.36905159 -0.04683424  0.81239465  0.97870312 -0.19185229 -0.0350032\n",
      "  0.06409114]\n",
      "âœ… DEBUG: states shape: torch.Size([1, 7])\n",
      "âœ… batch keys: dict_keys(['input_ids', 'attention_mask', 'images', 'images_r', 'states'])\n",
      "âœ… batch['states'] shape: torch.Size([1, 7])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” 10D Action: tensor([-0.7649, -0.8333,  0.2769, -0.9531,  0.9496,  0.7210,  0.6157,  0.8421,\n",
      "        -0.8762, -0.9057])\n",
      "ğŸ“¦ Position: tensor([-0.7649, -0.8333,  0.2769])\n",
      "ğŸŒ€ rot6d: tensor([-0.9531,  0.9496,  0.7210,  0.6157,  0.8421, -0.8762])\n",
      "âœŠ Gripper: tensor([-0.9057])\n",
      "ğŸ“· Frame 0: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ“· Frame 1: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ¤– robot_state shape: (7,)\n",
      "ğŸ¤– robot_state: [-0.36856211 -0.04531409  0.81242565  0.97830382 -0.19654587 -0.03533203\n",
      "  0.05516335]\n",
      "âœ… DEBUG: states shape: torch.Size([1, 7])\n",
      "âœ… batch keys: dict_keys(['input_ids', 'attention_mask', 'images', 'images_r', 'states'])\n",
      "âœ… batch['states'] shape: torch.Size([1, 7])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” 10D Action: tensor([-0.8475,  0.2673, -0.3743, -0.9196, -0.6152, -0.3440,  0.0535,  0.2757,\n",
      "        -0.0630, -0.0526])\n",
      "ğŸ“¦ Position: tensor([-0.8475,  0.2673, -0.3743])\n",
      "ğŸŒ€ rot6d: tensor([-0.9196, -0.6152, -0.3440,  0.0535,  0.2757, -0.0630])\n",
      "âœŠ Gripper: tensor([-0.0526])\n",
      "ğŸ“· Frame 0: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ“· Frame 1: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ¤– robot_state shape: (7,)\n",
      "ğŸ¤– robot_state: [-0.3610115  -0.03605389  0.81154076  0.98107557 -0.18887555 -0.03060669\n",
      "  0.02966448]\n",
      "âœ… DEBUG: states shape: torch.Size([1, 7])\n",
      "âœ… batch keys: dict_keys(['input_ids', 'attention_mask', 'images', 'images_r', 'states'])\n",
      "âœ… batch['states'] shape: torch.Size([1, 7])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” 10D Action: tensor([-0.8107, -0.7370, -0.9815, -0.6729, -0.7101,  0.1850, -0.8082,  0.9581,\n",
      "         0.4541,  0.7030])\n",
      "ğŸ“¦ Position: tensor([-0.8107, -0.7370, -0.9815])\n",
      "ğŸŒ€ rot6d: tensor([-0.6729, -0.7101,  0.1850, -0.8082,  0.9581,  0.4541])\n",
      "âœŠ Gripper: tensor([0.7030])\n",
      "ğŸ“· Frame 0: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ“· Frame 1: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ¤– robot_state shape: (7,)\n",
      "ğŸ¤– robot_state: [-0.36225077 -0.04261111  0.81066359  0.98178689 -0.18549182 -0.03122933\n",
      "  0.02668349]\n",
      "âœ… DEBUG: states shape: torch.Size([1, 7])\n",
      "âœ… batch keys: dict_keys(['input_ids', 'attention_mask', 'images', 'images_r', 'states'])\n",
      "âœ… batch['states'] shape: torch.Size([1, 7])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” 10D Action: tensor([-0.6996,  0.5954, -0.2361, -0.9252,  0.4542, -0.5160,  0.7132,  0.9516,\n",
      "         0.8066,  0.0156])\n",
      "ğŸ“¦ Position: tensor([-0.6996,  0.5954, -0.2361])\n",
      "ğŸŒ€ rot6d: tensor([-0.9252,  0.4542, -0.5160,  0.7132,  0.9516,  0.8066])\n",
      "âœŠ Gripper: tensor([0.0156])\n",
      "ğŸ“· Frame 0: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ“· Frame 1: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ¤– robot_state shape: (7,)\n",
      "ğŸ¤– robot_state: [-0.36451789 -0.05023802  0.81281731  0.98165627 -0.18479233 -0.03223976\n",
      "  0.03410806]\n",
      "âœ… DEBUG: states shape: torch.Size([1, 7])\n",
      "âœ… batch keys: dict_keys(['input_ids', 'attention_mask', 'images', 'images_r', 'states'])\n",
      "âœ… batch['states'] shape: torch.Size([1, 7])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” 10D Action: tensor([-0.7903,  0.6991, -0.5016, -0.9511,  0.5779, -0.5250, -0.7441,  0.2793,\n",
      "        -0.5745,  0.7814])\n",
      "ğŸ“¦ Position: tensor([-0.7903,  0.6991, -0.5016])\n",
      "ğŸŒ€ rot6d: tensor([-0.9511,  0.5779, -0.5250, -0.7441,  0.2793, -0.5745])\n",
      "âœŠ Gripper: tensor([0.7814])\n",
      "ğŸ“· Frame 0: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ“· Frame 1: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ¤– robot_state shape: (7,)\n",
      "ğŸ¤– robot_state: [-0.36903882 -0.04020144  0.81287463  0.98131699 -0.18755321 -0.03708526\n",
      "  0.02157423]\n",
      "âœ… DEBUG: states shape: torch.Size([1, 7])\n",
      "âœ… batch keys: dict_keys(['input_ids', 'attention_mask', 'images', 'images_r', 'states'])\n",
      "âœ… batch['states'] shape: torch.Size([1, 7])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” 10D Action: tensor([-0.8039,  0.1030, -0.8299, -0.9189,  0.8902, -0.2413, -0.7777,  0.9111,\n",
      "        -0.2305, -0.0224])\n",
      "ğŸ“¦ Position: tensor([-0.8039,  0.1030, -0.8299])\n",
      "ğŸŒ€ rot6d: tensor([-0.9189,  0.8902, -0.2413, -0.7777,  0.9111, -0.2305])\n",
      "âœŠ Gripper: tensor([-0.0224])\n",
      "ğŸ“· Frame 0: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ“· Frame 1: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ¤– robot_state shape: (7,)\n",
      "ğŸ¤– robot_state: [-0.36800266 -0.04748856  0.81109881  0.97993839 -0.19434799 -0.03586635\n",
      "  0.02575278]\n",
      "âœ… DEBUG: states shape: torch.Size([1, 7])\n",
      "âœ… batch keys: dict_keys(['input_ids', 'attention_mask', 'images', 'images_r', 'states'])\n",
      "âœ… batch['states'] shape: torch.Size([1, 7])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” 10D Action: tensor([-0.8324,  0.0196, -0.9543, -0.4584,  0.7563,  0.4190, -0.2331,  0.7714,\n",
      "         0.2347,  0.4657])\n",
      "ğŸ“¦ Position: tensor([-0.8324,  0.0196, -0.9543])\n",
      "ğŸŒ€ rot6d: tensor([-0.4584,  0.7563,  0.4190, -0.2331,  0.7714,  0.2347])\n",
      "âœŠ Gripper: tensor([0.4657])\n",
      "ğŸ“· Frame 0: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ“· Frame 1: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ¤– robot_state shape: (7,)\n",
      "ğŸ¤– robot_state: [-0.36675982 -0.04457864  0.81087848  0.98101112 -0.18980063 -0.03529164\n",
      "  0.01863888]\n",
      "âœ… DEBUG: states shape: torch.Size([1, 7])\n",
      "âœ… batch keys: dict_keys(['input_ids', 'attention_mask', 'images', 'images_r', 'states'])\n",
      "âœ… batch['states'] shape: torch.Size([1, 7])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” 10D Action: tensor([-0.8250, -0.6528, -0.8951, -0.5381,  0.7116,  0.2167, -0.7269,  0.1685,\n",
      "        -0.7226, -0.3921])\n",
      "ğŸ“¦ Position: tensor([-0.8250, -0.6528, -0.8951])\n",
      "ğŸŒ€ rot6d: tensor([-0.5381,  0.7116,  0.2167, -0.7269,  0.1685, -0.7226])\n",
      "âœŠ Gripper: tensor([-0.3921])\n",
      "ğŸ“· Frame 0: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ“· Frame 1: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ¤– robot_state shape: (7,)\n",
      "ğŸ¤– robot_state: [-0.3689073  -0.04442057  0.81019236  0.97694305 -0.21000547 -0.03717647\n",
      "  0.00989423]\n",
      "âœ… DEBUG: states shape: torch.Size([1, 7])\n",
      "âœ… batch keys: dict_keys(['input_ids', 'attention_mask', 'images', 'images_r', 'states'])\n",
      "âœ… batch['states'] shape: torch.Size([1, 7])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” 10D Action: tensor([-0.8714,  0.2040, -0.9829, -0.8743, -0.1312,  0.6338, -0.7427,  0.9583,\n",
      "         0.6436,  0.1510])\n",
      "ğŸ“¦ Position: tensor([-0.8714,  0.2040, -0.9829])\n",
      "ğŸŒ€ rot6d: tensor([-0.8743, -0.1312,  0.6338, -0.7427,  0.9583,  0.6436])\n",
      "âœŠ Gripper: tensor([0.1510])\n",
      "ğŸ“· Frame 0: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ“· Frame 1: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ¤– robot_state shape: (7,)\n",
      "ğŸ¤– robot_state: [-0.36860938 -0.04431017  0.810306    0.97540978 -0.21724934 -0.03674779\n",
      "  0.00529882]\n",
      "âœ… DEBUG: states shape: torch.Size([1, 7])\n",
      "âœ… batch keys: dict_keys(['input_ids', 'attention_mask', 'images', 'images_r', 'states'])\n",
      "âœ… batch['states'] shape: torch.Size([1, 7])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” 10D Action: tensor([-0.8369,  0.7072, -0.9309, -0.8725,  0.7317, -0.3627, -0.6720,  0.9181,\n",
      "        -0.4831, -0.5905])\n",
      "ğŸ“¦ Position: tensor([-0.8369,  0.7072, -0.9309])\n",
      "ğŸŒ€ rot6d: tensor([-0.8725,  0.7317, -0.3627, -0.6720,  0.9181, -0.4831])\n",
      "âœŠ Gripper: tensor([-0.5905])\n",
      "ğŸ“· Frame 0: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ“· Frame 1: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ¤– robot_state shape: (7,)\n",
      "ğŸ¤– robot_state: [-0.36827488 -0.04709148  0.81027302  0.97815964 -0.20422036 -0.0361176\n",
      "  0.01390242]\n",
      "âœ… DEBUG: states shape: torch.Size([1, 7])\n",
      "âœ… batch keys: dict_keys(['input_ids', 'attention_mask', 'images', 'images_r', 'states'])\n",
      "âœ… batch['states'] shape: torch.Size([1, 7])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” 10D Action: tensor([-0.8491,  0.8216,  0.3991, -0.7659, -0.5429,  0.7933, -0.5630,  0.9268,\n",
      "         0.8097, -0.4654])\n",
      "ğŸ“¦ Position: tensor([-0.8491,  0.8216,  0.3991])\n",
      "ğŸŒ€ rot6d: tensor([-0.7659, -0.5429,  0.7933, -0.5630,  0.9268,  0.8097])\n",
      "âœŠ Gripper: tensor([-0.4654])\n",
      "ğŸ“· Frame 0: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ“· Frame 1: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ¤– robot_state shape: (7,)\n",
      "ğŸ¤– robot_state: [-0.3698136  -0.05425435  0.81370185  0.98159738 -0.18420442 -0.03567849\n",
      "  0.03552979]\n",
      "âœ… DEBUG: states shape: torch.Size([1, 7])\n",
      "âœ… batch keys: dict_keys(['input_ids', 'attention_mask', 'images', 'images_r', 'states'])\n",
      "âœ… batch['states'] shape: torch.Size([1, 7])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” 10D Action: tensor([-0.8644, -0.8219, -0.9046, -0.8920,  0.1680,  0.7433, -0.0975,  0.2572,\n",
      "         0.5764,  0.3688])\n",
      "ğŸ“¦ Position: tensor([-0.8644, -0.8219, -0.9046])\n",
      "ğŸŒ€ rot6d: tensor([-0.8920,  0.1680,  0.7433, -0.0975,  0.2572,  0.5764])\n",
      "âœŠ Gripper: tensor([0.3688])\n",
      "ğŸ“· Frame 0: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ“· Frame 1: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ¤– robot_state shape: (7,)\n",
      "ğŸ¤– robot_state: [-0.37045794 -0.05372114  0.81532909  0.98626299 -0.15377657 -0.03692073\n",
      "  0.0476963 ]\n",
      "âœ… DEBUG: states shape: torch.Size([1, 7])\n",
      "âœ… batch keys: dict_keys(['input_ids', 'attention_mask', 'images', 'images_r', 'states'])\n",
      "âœ… batch['states'] shape: torch.Size([1, 7])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” 10D Action: tensor([-0.8202,  0.7349,  0.0528, -0.9426,  0.9669,  0.4632, -0.5643,  0.9299,\n",
      "         0.7453,  0.7914])\n",
      "ğŸ“¦ Position: tensor([-0.8202,  0.7349,  0.0528])\n",
      "ğŸŒ€ rot6d: tensor([-0.9426,  0.9669,  0.4632, -0.5643,  0.9299,  0.7453])\n",
      "âœŠ Gripper: tensor([0.7914])\n",
      "ğŸ“· Frame 0: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ“· Frame 1: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ¤– robot_state shape: (7,)\n",
      "ğŸ¤– robot_state: [-0.36395531 -0.06093413  0.81653776  0.98705696 -0.14338309 -0.03034142\n",
      "  0.06510943]\n",
      "âœ… DEBUG: states shape: torch.Size([1, 7])\n",
      "âœ… batch keys: dict_keys(['input_ids', 'attention_mask', 'images', 'images_r', 'states'])\n",
      "âœ… batch['states'] shape: torch.Size([1, 7])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” 10D Action: tensor([-0.7890, -0.6526, -0.7238, -0.9648,  0.6807,  0.7141, -0.6944,  0.8827,\n",
      "        -0.0236,  0.8044])\n",
      "ğŸ“¦ Position: tensor([-0.7890, -0.6526, -0.7238])\n",
      "ğŸŒ€ rot6d: tensor([-0.9648,  0.6807,  0.7141, -0.6944,  0.8827, -0.0236])\n",
      "âœŠ Gripper: tensor([0.8044])\n",
      "ğŸ“· Frame 0: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ“· Frame 1: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ¤– robot_state shape: (7,)\n",
      "ğŸ¤– robot_state: [-0.36879244 -0.06330856  0.81564979  0.98408653 -0.15500657 -0.03484222\n",
      "  0.07957819]\n",
      "âœ… DEBUG: states shape: torch.Size([1, 7])\n",
      "âœ… batch keys: dict_keys(['input_ids', 'attention_mask', 'images', 'images_r', 'states'])\n",
      "âœ… batch['states'] shape: torch.Size([1, 7])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” 10D Action: tensor([-0.5691,  0.3658, -0.2229, -0.9196,  0.9331,  0.7962, -0.4503,  0.6925,\n",
      "         0.0157, -0.3205])\n",
      "ğŸ“¦ Position: tensor([-0.5691,  0.3658, -0.2229])\n",
      "ğŸŒ€ rot6d: tensor([-0.9196,  0.9331,  0.7962, -0.4503,  0.6925,  0.0157])\n",
      "âœŠ Gripper: tensor([-0.3205])\n",
      "ğŸ“· Frame 0: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ“· Frame 1: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ¤– robot_state shape: (7,)\n",
      "ğŸ¤– robot_state: [-0.36967612 -0.05686925  0.81436164  0.97994049 -0.17917404 -0.03543302\n",
      "  0.07973584]\n",
      "âœ… DEBUG: states shape: torch.Size([1, 7])\n",
      "âœ… batch keys: dict_keys(['input_ids', 'attention_mask', 'images', 'images_r', 'states'])\n",
      "âœ… batch['states'] shape: torch.Size([1, 7])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” 10D Action: tensor([-0.8281,  0.1488, -0.8709, -0.7426,  0.9586,  0.3578, -0.7655,  0.5250,\n",
      "         0.8182,  0.7547])\n",
      "ğŸ“¦ Position: tensor([-0.8281,  0.1488, -0.8709])\n",
      "ğŸŒ€ rot6d: tensor([-0.7426,  0.9586,  0.3578, -0.7655,  0.5250,  0.8182])\n",
      "âœŠ Gripper: tensor([0.7547])\n",
      "ğŸ“· Frame 0: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ“· Frame 1: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ¤– robot_state shape: (7,)\n",
      "ğŸ¤– robot_state: [-0.37148607 -0.0567283   0.81458446  0.97377281 -0.20726105 -0.03676234\n",
      "  0.08635918]\n",
      "âœ… DEBUG: states shape: torch.Size([1, 7])\n",
      "âœ… batch keys: dict_keys(['input_ids', 'attention_mask', 'images', 'images_r', 'states'])\n",
      "âœ… batch['states'] shape: torch.Size([1, 7])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” 10D Action: tensor([-0.8408, -0.8849, -0.7495, -0.9442,  0.7956,  0.4633,  0.8115,  0.6708,\n",
      "         0.0299,  0.8656])\n",
      "ğŸ“¦ Position: tensor([-0.8408, -0.8849, -0.7495])\n",
      "ğŸŒ€ rot6d: tensor([-0.9442,  0.7956,  0.4633,  0.8115,  0.6708,  0.0299])\n",
      "âœŠ Gripper: tensor([0.8656])\n",
      "ğŸ“· Frame 0: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ“· Frame 1: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ¤– robot_state shape: (7,)\n",
      "ğŸ¤– robot_state: [-0.37077839 -0.05621921  0.81462308  0.97480703 -0.20298938 -0.03546648\n",
      "  0.0853738 ]\n",
      "âœ… DEBUG: states shape: torch.Size([1, 7])\n",
      "âœ… batch keys: dict_keys(['input_ids', 'attention_mask', 'images', 'images_r', 'states'])\n",
      "âœ… batch['states'] shape: torch.Size([1, 7])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” 10D Action: tensor([-0.8190,  0.0018, -0.8947, -0.9399,  0.9173,  0.3759,  0.7590,  0.4720,\n",
      "        -0.4631,  0.8221])\n",
      "ğŸ“¦ Position: tensor([-0.8190,  0.0018, -0.8947])\n",
      "ğŸŒ€ rot6d: tensor([-0.9399,  0.9173,  0.3759,  0.7590,  0.4720, -0.4631])\n",
      "âœŠ Gripper: tensor([0.8221])\n",
      "ğŸ“· Frame 0: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ“· Frame 1: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ¤– robot_state shape: (7,)\n",
      "ğŸ¤– robot_state: [-0.36819031 -0.05084304  0.81270521  0.97691102 -0.19935004 -0.03502632\n",
      "  0.06839282]\n",
      "âœ… DEBUG: states shape: torch.Size([1, 7])\n",
      "âœ… batch keys: dict_keys(['input_ids', 'attention_mask', 'images', 'images_r', 'states'])\n",
      "âœ… batch['states'] shape: torch.Size([1, 7])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” 10D Action: tensor([-0.8078, -0.5022, -0.8563, -0.4723,  0.9026,  0.7399, -0.2792,  0.8714,\n",
      "        -0.5054,  0.3999])\n",
      "ğŸ“¦ Position: tensor([-0.8078, -0.5022, -0.8563])\n",
      "ğŸŒ€ rot6d: tensor([-0.4723,  0.9026,  0.7399, -0.2792,  0.8714, -0.5054])\n",
      "âœŠ Gripper: tensor([0.3999])\n",
      "ğŸ“· Frame 0: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ“· Frame 1: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ¤– robot_state shape: (7,)\n",
      "ğŸ¤– robot_state: [-0.36969968 -0.05133792  0.81204276  0.97358688 -0.21882563 -0.03638263\n",
      "  0.05403926]\n",
      "âœ… DEBUG: states shape: torch.Size([1, 7])\n",
      "âœ… batch keys: dict_keys(['input_ids', 'attention_mask', 'images', 'images_r', 'states'])\n",
      "âœ… batch['states'] shape: torch.Size([1, 7])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” 10D Action: tensor([-0.7919,  0.8609, -0.3946, -0.9075, -0.6138, -0.6907, -0.8223,  0.4297,\n",
      "         0.1069,  0.7128])\n",
      "ğŸ“¦ Position: tensor([-0.7919,  0.8609, -0.3946])\n",
      "ğŸŒ€ rot6d: tensor([-0.9075, -0.6138, -0.6907, -0.8223,  0.4297,  0.1069])\n",
      "âœŠ Gripper: tensor([0.7128])\n",
      "ğŸ“· Frame 0: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ“· Frame 1: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ¤– robot_state shape: (7,)\n",
      "ğŸ¤– robot_state: [-0.36167039 -0.04082041  0.8113986   0.97204536 -0.23182326 -0.031471\n",
      "  0.01988415]\n",
      "âœ… DEBUG: states shape: torch.Size([1, 7])\n",
      "âœ… batch keys: dict_keys(['input_ids', 'attention_mask', 'images', 'images_r', 'states'])\n",
      "âœ… batch['states'] shape: torch.Size([1, 7])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” global_cond shape (forward): torch.Size([1, 1197, 512])\n",
      "ğŸ” 10D Action: tensor([-0.6793, -0.7727, -0.9731, -0.9450,  0.3530,  1.0000, -0.7939,  0.8377,\n",
      "        -0.1904, -0.9775])\n",
      "ğŸ“¦ Position: tensor([-0.6793, -0.7727, -0.9731])\n",
      "ğŸŒ€ rot6d: tensor([-0.9450,  0.3530,  1.0000, -0.7939,  0.8377, -0.1904])\n",
      "âœŠ Gripper: tensor([-0.9775])\n",
      "ğŸ“· Frame 0: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ“· Frame 1: shape=(480, 640, 3), dtype=uint8, min=0, max=255\n",
      "ğŸ¥ rollout.mp4 ì €ì¥ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    policy_config = {\n",
    "        \"model_path\": \"/home/parkjeongsu/TinyVLA/OUTPUT_llava_pythia/checkpoint-5000\",\n",
    "        \"model_base\": \"/home/parkjeongsu/TinyVLA/Llava-Pythia-400M\",\n",
    "        \"enable_lora\": False,\n",
    "        \"conv_mode\": \"pythia\",\n",
    "        \"action_head\": \"droid_diffusion\",\n",
    "        \"action_dim\": 7,\n",
    "        \"chunk_size\": 10\n",
    "    }\n",
    "    \n",
    "    policy = llava_pythia_act_policy(policy_config)\n",
    "    \n",
    "    env = RobosuiteDeployEnv(env_name=\"Lift\", cameras=(\"sideview\", \"frontview\"))\n",
    "    eval_bc(policy, env, policy_config, save_episode=True, num_rollouts=1,\n",
    "            raw_lang=\"pick up the cube \", n_steps=100, fps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b1f78f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'deploy_env' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[71], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m frames \u001b[38;5;241m=\u001b[39m \u001b[43mdeploy_env\u001b[49m\u001b[38;5;241m.\u001b[39mrender_cameras(cameras\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msideview\u001b[39m\u001b[38;5;124m\"\u001b[39m], width\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m640\u001b[39m, height\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m480\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(frames):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFrame \u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, dtype=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, min=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf\u001b[38;5;241m.\u001b[39mmin()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, max=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf\u001b[38;5;241m.\u001b[39mmax()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, nan=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39misnan(f)\u001b[38;5;241m.\u001b[39many()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'deploy_env' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if is_frame_valid(f):\n",
    "    plt.imshow(cv2.cvtColor(f, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(f\"Frame {t}\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f8821c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”Ÿ 10D Action: tensor([[ 0.7313, -0.7327,  1.2382,  0.4969, -1.5641,  0.3737, -0.2119,  1.4107,\n",
      "         -0.1909,  0.0289]])\n",
      "â 7D Converted Action: tensor([[ 0.7313, -0.7327,  1.2382, -0.2998,  0.5074,  1.1717,  0.0289]])\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tinysuite",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
