{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da170b9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading TFDS dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-08 12:07:42.772072: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-08-08 12:07:42.798124: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-08-08 12:07:42.798148: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-08-08 12:07:42.798930: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-08-08 12:07:42.803577: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-08-08 12:07:43.437039: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-08-08 12:07:44.261053: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-08-08 12:07:44.301857: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-08-08 12:07:44.301976: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-08-08 12:07:44.302789: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-08-08 12:07:44.302979: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-08-08 12:07:44.303030: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-08-08 12:07:44.858713: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-08-08 12:07:44.858824: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-08-08 12:07:44.858886: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-08-08 12:07:44.858941: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9616 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ TFDS 경로: /home/parkjeongsu/TinyVLA/Droid/droid_100\n",
      "✅ 저장 경로: /home/parkjeongsu/TinyVLA/Droid/droid_with_lang/droid_1dot7t_lang_succ_t0001_s-0-0\n",
      "raw_lang: close the lid of the box\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [00:00<00:47,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "traj_len: 166\n",
      "traj_actions shape: (166, 7)\n",
      "traj_qpos shape: (166, 7)\n",
      "traj_qvel shape: (166, 7)\n",
      "left_imgs shape: (166, 180, 320, 3)\n",
      "right_imgs shape: (166, 180, 320, 3)\n",
      "wrist_imgs shape: (166, 180, 320, 3)\n",
      "max_timesteps: 166\n",
      "==== generate h5 ======\n",
      "name: /observations/qpos, array: (166, 7)\n",
      "name: /observations/qvel, array: (166, 7)\n",
      "name: /action, array: (166, 7)\n",
      "name: is_edited, array: ()\n",
      "name: /observations/images/left, array: (166, 180, 320, 3)\n",
      "name: /observations/images/right, array: (166, 180, 320, 3)\n",
      "name: /observations/images/wrist, array: (166, 180, 320, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2/100 [00:00<00:32,  3.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "traj_len: 238\n",
      "traj_actions shape: (238, 7)\n",
      "traj_qpos shape: (238, 7)\n",
      "traj_qvel shape: (238, 7)\n",
      "left_imgs shape: (238, 180, 320, 3)\n",
      "right_imgs shape: (238, 180, 320, 3)\n",
      "wrist_imgs shape: (238, 180, 320, 3)\n",
      "max_timesteps: 238\n",
      "==== generate h5 ======\n",
      "name: /observations/qpos, array: (238, 7)\n",
      "name: /observations/qvel, array: (238, 7)\n",
      "name: /action, array: (238, 7)\n",
      "name: is_edited, array: ()\n",
      "name: /observations/images/left, array: (238, 180, 320, 3)\n",
      "name: /observations/images/right, array: (238, 180, 320, 3)\n",
      "name: /observations/images/wrist, array: (238, 180, 320, 3)\n",
      "traj_len: 142\n",
      "traj_actions shape: (142, 7)\n",
      "traj_qpos shape: (142, 7)\n",
      "traj_qvel shape: (142, 7)\n",
      "left_imgs shape: (142, 180, 320, 3)\n",
      "right_imgs shape: (142, 180, 320, 3)\n",
      "wrist_imgs shape: (142, 180, 320, 3)\n",
      "max_timesteps: 142\n",
      "==== generate h5 ======\n",
      "name: /observations/qpos, array: (142, 7)\n",
      "name: /observations/qvel, array: (142, 7)\n",
      "name: /action, array: (142, 7)\n",
      "name: is_edited, array: ()\n",
      "name: /observations/images/left, array: (142, 180, 320, 3)\n",
      "name: /observations/images/right, array: (142, 180, 320, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 4/100 [00:01<00:22,  4.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: /observations/images/wrist, array: (142, 180, 320, 3)\n",
      "traj_len: 205\n",
      "traj_actions shape: (205, 7)\n",
      "traj_qpos shape: (205, 7)\n",
      "traj_qvel shape: (205, 7)\n",
      "left_imgs shape: (205, 180, 320, 3)\n",
      "right_imgs shape: (205, 180, 320, 3)\n",
      "wrist_imgs shape: (205, 180, 320, 3)\n",
      "max_timesteps: 205\n",
      "==== generate h5 ======\n",
      "name: /observations/qpos, array: (205, 7)\n",
      "name: /observations/qvel, array: (205, 7)\n",
      "name: /action, array: (205, 7)\n",
      "name: is_edited, array: ()\n",
      "name: /observations/images/left, array: (205, 180, 320, 3)\n",
      "name: /observations/images/right, array: (205, 180, 320, 3)\n",
      "name: /observations/images/wrist, array: (205, 180, 320, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 5/100 [00:01<00:21,  4.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "traj_len: 213\n",
      "traj_actions shape: (213, 7)\n",
      "traj_qpos shape: (213, 7)\n",
      "traj_qvel shape: (213, 7)\n",
      "left_imgs shape: (213, 180, 320, 3)\n",
      "right_imgs shape: (213, 180, 320, 3)\n",
      "wrist_imgs shape: (213, 180, 320, 3)\n",
      "max_timesteps: 213\n",
      "==== generate h5 ======\n",
      "name: /observations/qpos, array: (213, 7)\n",
      "name: /observations/qvel, array: (213, 7)\n",
      "name: /action, array: (213, 7)\n",
      "name: is_edited, array: ()\n",
      "name: /observations/images/left, array: (213, 180, 320, 3)\n",
      "name: /observations/images/right, array: (213, 180, 320, 3)\n",
      "name: /observations/images/wrist, array: (213, 180, 320, 3)\n",
      "No valid language instruction in this episode....\n",
      "traj_len: 181\n",
      "traj_actions shape: (181, 7)\n",
      "traj_qpos shape: (181, 7)\n",
      "traj_qvel shape: (181, 7)\n",
      "left_imgs shape: (181, 180, 320, 3)\n",
      "right_imgs shape: (181, 180, 320, 3)\n",
      "wrist_imgs shape: (181, 180, 320, 3)\n",
      "max_timesteps: 181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 7/100 [00:01<00:15,  6.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== generate h5 ======\n",
      "name: /observations/qpos, array: (181, 7)\n",
      "name: /observations/qvel, array: (181, 7)\n",
      "name: /action, array: (181, 7)\n",
      "name: is_edited, array: ()\n",
      "name: /observations/images/left, array: (181, 180, 320, 3)\n",
      "name: /observations/images/right, array: (181, 180, 320, 3)\n",
      "name: /observations/images/wrist, array: (181, 180, 320, 3)\n",
      "No valid language instruction in this episode....\n",
      "No valid language instruction in this episode....\n",
      "No valid language instruction in this episode....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 11/100 [00:01<00:10,  8.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "traj_len: 357\n",
      "traj_actions shape: (357, 7)\n",
      "traj_qpos shape: (357, 7)\n",
      "traj_qvel shape: (357, 7)\n",
      "left_imgs shape: (357, 180, 320, 3)\n",
      "right_imgs shape: (357, 180, 320, 3)\n",
      "wrist_imgs shape: (357, 180, 320, 3)\n",
      "max_timesteps: 357\n",
      "==== generate h5 ======\n",
      "name: /observations/qpos, array: (357, 7)\n",
      "name: /observations/qvel, array: (357, 7)\n",
      "name: /action, array: (357, 7)\n",
      "name: is_edited, array: ()\n",
      "name: /observations/images/left, array: (357, 180, 320, 3)\n",
      "name: /observations/images/right, array: (357, 180, 320, 3)\n",
      "name: /observations/images/wrist, array: (357, 180, 320, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 12/100 [00:02<00:14,  5.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "traj_len: 404\n",
      "traj_actions shape: (404, 7)\n",
      "traj_qpos shape: (404, 7)\n",
      "traj_qvel shape: (404, 7)\n",
      "left_imgs shape: (404, 180, 320, 3)\n",
      "right_imgs shape: (404, 180, 320, 3)\n",
      "wrist_imgs shape: (404, 180, 320, 3)\n",
      "max_timesteps: 404\n",
      "==== generate h5 ======\n",
      "name: /observations/qpos, array: (404, 7)\n",
      "name: /observations/qvel, array: (404, 7)\n",
      "name: /action, array: (404, 7)\n",
      "name: is_edited, array: ()\n",
      "name: /observations/images/left, array: (404, 180, 320, 3)\n",
      "name: /observations/images/right, array: (404, 180, 320, 3)\n",
      "name: /observations/images/wrist, array: (404, 180, 320, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 13/100 [00:02<00:15,  5.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "traj_len: 214\n",
      "traj_actions shape: (214, 7)\n",
      "traj_qpos shape: (214, 7)\n",
      "traj_qvel shape: (214, 7)\n",
      "left_imgs shape: (214, 180, 320, 3)\n",
      "right_imgs shape: (214, 180, 320, 3)\n",
      "wrist_imgs shape: (214, 180, 320, 3)\n",
      "max_timesteps: 214\n",
      "==== generate h5 ======\n",
      "name: /observations/qpos, array: (214, 7)\n",
      "name: /observations/qvel, array: (214, 7)\n",
      "name: /action, array: (214, 7)\n",
      "name: is_edited, array: ()\n",
      "name: /observations/images/left, array: (214, 180, 320, 3)\n",
      "name: /observations/images/right, array: (214, 180, 320, 3)\n",
      "name: /observations/images/wrist, array: (214, 180, 320, 3)\n",
      "traj_len: 196\n",
      "traj_actions shape: (196, 7)\n",
      "traj_qpos shape: (196, 7)\n",
      "traj_qvel shape: (196, 7)\n",
      "left_imgs shape: (196, 180, 320, 3)\n",
      "right_imgs shape: (196, 180, 320, 3)\n",
      "wrist_imgs shape: (196, 180, 320, 3)\n",
      "max_timesteps: 196\n",
      "==== generate h5 ======\n",
      "name: /observations/qpos, array: (196, 7)\n",
      "name: /observations/qvel, array: (196, 7)\n",
      "name: /action, array: (196, 7)\n",
      "name: is_edited, array: ()\n",
      "name: /observations/images/left, array: (196, 180, 320, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 19/100 [00:02<00:06, 11.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: /observations/images/right, array: (196, 180, 320, 3)\n",
      "name: /observations/images/wrist, array: (196, 180, 320, 3)\n",
      "No valid language instruction in this episode....\n",
      "No valid language instruction in this episode....\n",
      "No valid language instruction in this episode....\n",
      "No valid language instruction in this episode....\n",
      "No valid language instruction in this episode....\n",
      "No valid language instruction in this episode....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 21/100 [00:02<00:06, 11.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "traj_len: 189\n",
      "traj_actions shape: (189, 7)\n",
      "traj_qpos shape: (189, 7)\n",
      "traj_qvel shape: (189, 7)\n",
      "left_imgs shape: (189, 180, 320, 3)\n",
      "right_imgs shape: (189, 180, 320, 3)\n",
      "wrist_imgs shape: (189, 180, 320, 3)\n",
      "max_timesteps: 189\n",
      "==== generate h5 ======\n",
      "name: /observations/qpos, array: (189, 7)\n",
      "name: /observations/qvel, array: (189, 7)\n",
      "name: /action, array: (189, 7)\n",
      "name: is_edited, array: ()\n",
      "name: /observations/images/left, array: (189, 180, 320, 3)\n",
      "name: /observations/images/right, array: (189, 180, 320, 3)\n",
      "name: /observations/images/wrist, array: (189, 180, 320, 3)\n",
      "traj_len: 92\n",
      "traj_actions shape: (92, 7)\n",
      "traj_qpos shape: (92, 7)\n",
      "traj_qvel shape: (92, 7)\n",
      "left_imgs shape: (92, 180, 320, 3)\n",
      "right_imgs shape: (92, 180, 320, 3)\n",
      "wrist_imgs shape: (92, 180, 320, 3)\n",
      "max_timesteps: 92\n",
      "==== generate h5 ======\n",
      "name: /observations/qpos, array: (92, 7)\n",
      "name: /observations/qvel, array: (92, 7)\n",
      "name: /action, array: (92, 7)\n",
      "name: is_edited, array: ()\n",
      "name: /observations/images/left, array: (92, 180, 320, 3)\n",
      "name: /observations/images/right, array: (92, 180, 320, 3)\n",
      "name: /observations/images/wrist, array: (92, 180, 320, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 23/100 [00:03<00:08,  9.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "traj_len: 213\n",
      "traj_actions shape: (213, 7)\n",
      "traj_qpos shape: (213, 7)\n",
      "traj_qvel shape: (213, 7)\n",
      "left_imgs shape: (213, 180, 320, 3)\n",
      "right_imgs shape: (213, 180, 320, 3)\n",
      "wrist_imgs shape: (213, 180, 320, 3)\n",
      "max_timesteps: 213\n",
      "==== generate h5 ======\n",
      "name: /observations/qpos, array: (213, 7)\n",
      "name: /observations/qvel, array: (213, 7)\n",
      "name: /action, array: (213, 7)\n",
      "name: is_edited, array: ()\n",
      "name: /observations/images/left, array: (213, 180, 320, 3)\n",
      "name: /observations/images/right, array: (213, 180, 320, 3)\n",
      "name: /observations/images/wrist, array: (213, 180, 320, 3)\n",
      "traj_len: 248\n",
      "traj_actions shape: (248, 7)\n",
      "traj_qpos shape: (248, 7)\n",
      "traj_qvel shape: (248, 7)\n",
      "left_imgs shape: (248, 180, 320, 3)\n",
      "right_imgs shape: (248, 180, 320, 3)\n",
      "wrist_imgs shape: (248, 180, 320, 3)\n",
      "max_timesteps: 248\n",
      "==== generate h5 ======\n",
      "name: /observations/qpos, array: (248, 7)\n",
      "name: /observations/qvel, array: (248, 7)\n",
      "name: /action, array: (248, 7)\n",
      "name: is_edited, array: ()\n",
      "name: /observations/images/left, array: (248, 180, 320, 3)\n",
      "name: /observations/images/right, array: (248, 180, 320, 3)\n",
      "name: /observations/images/wrist, array: (248, 180, 320, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 25/100 [00:04<00:18,  4.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "traj_len: 1066\n",
      "traj_actions shape: (1066, 7)\n",
      "traj_qpos shape: (1066, 7)\n",
      "traj_qvel shape: (1066, 7)\n",
      "left_imgs shape: (1066, 180, 320, 3)\n",
      "right_imgs shape: (1066, 180, 320, 3)\n",
      "wrist_imgs shape: (1066, 180, 320, 3)\n",
      "max_timesteps: 1066\n",
      "==== generate h5 ======\n",
      "name: /observations/qpos, array: (1066, 7)\n",
      "name: /observations/qvel, array: (1066, 7)\n",
      "name: /action, array: (1066, 7)\n",
      "name: is_edited, array: ()\n",
      "name: /observations/images/left, array: (1066, 180, 320, 3)\n",
      "name: /observations/images/right, array: (1066, 180, 320, 3)\n",
      "name: /observations/images/wrist, array: (1066, 180, 320, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 26/100 [00:04<00:20,  3.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "traj_len: 558\n",
      "traj_actions shape: (558, 7)\n",
      "traj_qpos shape: (558, 7)\n",
      "traj_qvel shape: (558, 7)\n",
      "left_imgs shape: (558, 180, 320, 3)\n",
      "right_imgs shape: (558, 180, 320, 3)\n",
      "wrist_imgs shape: (558, 180, 320, 3)\n",
      "max_timesteps: 558\n",
      "==== generate h5 ======\n",
      "name: /observations/qpos, array: (558, 7)\n",
      "name: /observations/qvel, array: (558, 7)\n",
      "name: /action, array: (558, 7)\n",
      "name: is_edited, array: ()\n",
      "name: /observations/images/left, array: (558, 180, 320, 3)\n",
      "name: /observations/images/right, array: (558, 180, 320, 3)\n",
      "name: /observations/images/wrist, array: (558, 180, 320, 3)\n",
      "traj_len: 119\n",
      "traj_actions shape: (119, 7)\n",
      "traj_qpos shape: (119, 7)\n",
      "traj_qvel shape: (119, 7)\n",
      "left_imgs shape: (119, 180, 320, 3)\n",
      "right_imgs shape: (119, 180, 320, 3)\n",
      "wrist_imgs shape: (119, 180, 320, 3)\n",
      "max_timesteps: 119\n",
      "==== generate h5 ======\n",
      "name: /observations/qpos, array: (119, 7)\n",
      "name: /observations/qvel, array: (119, 7)\n",
      "name: /action, array: (119, 7)\n",
      "name: is_edited, array: ()\n",
      "name: /observations/images/left, array: (119, 180, 320, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 27/100 [00:05<00:18,  3.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: /observations/images/right, array: (119, 180, 320, 3)\n",
      "name: /observations/images/wrist, array: (119, 180, 320, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 28/100 [00:05<00:20,  3.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "traj_len: 366\n",
      "traj_actions shape: (366, 7)\n",
      "traj_qpos shape: (366, 7)\n",
      "traj_qvel shape: (366, 7)\n",
      "left_imgs shape: (366, 180, 320, 3)\n",
      "right_imgs shape: (366, 180, 320, 3)\n",
      "wrist_imgs shape: (366, 180, 320, 3)\n",
      "max_timesteps: 366\n",
      "==== generate h5 ======\n",
      "name: /observations/qpos, array: (366, 7)\n",
      "name: /observations/qvel, array: (366, 7)\n",
      "name: /action, array: (366, 7)\n",
      "name: is_edited, array: ()\n",
      "name: /observations/images/left, array: (366, 180, 320, 3)\n",
      "name: /observations/images/right, array: (366, 180, 320, 3)\n",
      "name: /observations/images/wrist, array: (366, 180, 320, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 29/100 [00:05<00:21,  3.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "traj_len: 398\n",
      "traj_actions shape: (398, 7)\n",
      "traj_qpos shape: (398, 7)\n",
      "traj_qvel shape: (398, 7)\n",
      "left_imgs shape: (398, 180, 320, 3)\n",
      "right_imgs shape: (398, 180, 320, 3)\n",
      "wrist_imgs shape: (398, 180, 320, 3)\n",
      "max_timesteps: 398\n",
      "==== generate h5 ======\n",
      "name: /observations/qpos, array: (398, 7)\n",
      "name: /observations/qvel, array: (398, 7)\n",
      "name: /action, array: (398, 7)\n",
      "name: is_edited, array: ()\n",
      "name: /observations/images/left, array: (398, 180, 320, 3)\n",
      "name: /observations/images/right, array: (398, 180, 320, 3)\n",
      "name: /observations/images/wrist, array: (398, 180, 320, 3)\n",
      "No valid language instruction in this episode....\n",
      "No valid language instruction in this episode....\n",
      "No valid language instruction in this episode....\n",
      "No valid language instruction in this episode....\n",
      "No valid language instruction in this episode....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 35/100 [00:06<00:09,  7.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "traj_len: 259\n",
      "traj_actions shape: (259, 7)\n",
      "traj_qpos shape: (259, 7)\n",
      "traj_qvel shape: (259, 7)\n",
      "left_imgs shape: (259, 180, 320, 3)\n",
      "right_imgs shape: (259, 180, 320, 3)\n",
      "wrist_imgs shape: (259, 180, 320, 3)\n",
      "max_timesteps: 259\n",
      "==== generate h5 ======\n",
      "name: /observations/qpos, array: (259, 7)\n",
      "name: /observations/qvel, array: (259, 7)\n",
      "name: /action, array: (259, 7)\n",
      "name: is_edited, array: ()\n",
      "name: /observations/images/left, array: (259, 180, 320, 3)\n",
      "name: /observations/images/right, array: (259, 180, 320, 3)\n",
      "name: /observations/images/wrist, array: (259, 180, 320, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 36/100 [00:06<00:10,  6.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "traj_len: 297\n",
      "traj_actions shape: (297, 7)\n",
      "traj_qpos shape: (297, 7)\n",
      "traj_qvel shape: (297, 7)\n",
      "left_imgs shape: (297, 180, 320, 3)\n",
      "right_imgs shape: (297, 180, 320, 3)\n",
      "wrist_imgs shape: (297, 180, 320, 3)\n",
      "max_timesteps: 297\n",
      "==== generate h5 ======\n",
      "name: /observations/qpos, array: (297, 7)\n",
      "name: /observations/qvel, array: (297, 7)\n",
      "name: /action, array: (297, 7)\n",
      "name: is_edited, array: ()\n",
      "name: /observations/images/left, array: (297, 180, 320, 3)\n",
      "name: /observations/images/right, array: (297, 180, 320, 3)\n",
      "name: /observations/images/wrist, array: (297, 180, 320, 3)\n",
      "No valid language instruction in this episode....\n",
      "No valid language instruction in this episode....\n",
      "No valid language instruction in this episode....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 40/100 [00:07<00:09,  6.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "traj_len: 684\n",
      "traj_actions shape: (684, 7)\n",
      "traj_qpos shape: (684, 7)\n",
      "traj_qvel shape: (684, 7)\n",
      "left_imgs shape: (684, 180, 320, 3)\n",
      "right_imgs shape: (684, 180, 320, 3)\n",
      "wrist_imgs shape: (684, 180, 320, 3)\n",
      "max_timesteps: 684\n",
      "==== generate h5 ======\n",
      "name: /observations/qpos, array: (684, 7)\n",
      "name: /observations/qvel, array: (684, 7)\n",
      "name: /action, array: (684, 7)\n",
      "name: is_edited, array: ()\n",
      "name: /observations/images/left, array: (684, 180, 320, 3)\n",
      "name: /observations/images/right, array: (684, 180, 320, 3)\n",
      "name: /observations/images/wrist, array: (684, 180, 320, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 41/100 [00:07<00:13,  4.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "traj_len: 833\n",
      "traj_actions shape: (833, 7)\n",
      "traj_qpos shape: (833, 7)\n",
      "traj_qvel shape: (833, 7)\n",
      "left_imgs shape: (833, 180, 320, 3)\n",
      "right_imgs shape: (833, 180, 320, 3)\n",
      "wrist_imgs shape: (833, 180, 320, 3)\n",
      "max_timesteps: 833\n",
      "==== generate h5 ======\n",
      "name: /observations/qpos, array: (833, 7)\n",
      "name: /observations/qvel, array: (833, 7)\n",
      "name: /action, array: (833, 7)\n",
      "name: is_edited, array: ()\n",
      "name: /observations/images/left, array: (833, 180, 320, 3)\n",
      "name: /observations/images/right, array: (833, 180, 320, 3)\n",
      "name: /observations/images/wrist, array: (833, 180, 320, 3)\n",
      "No valid language instruction in this episode....\n",
      "No valid language instruction in this episode....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 46/100 [00:07<00:07,  7.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No valid language instruction in this episode....\n",
      "No valid language instruction in this episode....\n",
      "No valid language instruction in this episode....\n",
      "No valid language instruction in this episode....\n",
      "No valid language instruction in this episode....\n",
      "No valid language instruction in this episode....\n",
      "No valid language instruction in this episode....\n",
      "traj_len: 1347\n",
      "traj_actions shape: (1347, 7)\n",
      "traj_qpos shape: (1347, 7)\n",
      "traj_qvel shape: (1347, 7)\n",
      "left_imgs shape: (1347, 180, 320, 3)\n",
      "right_imgs shape: (1347, 180, 320, 3)\n",
      "wrist_imgs shape: (1347, 180, 320, 3)\n",
      "max_timesteps: 1347\n",
      "==== generate h5 ======\n",
      "name: /observations/qpos, array: (1347, 7)\n",
      "name: /observations/qvel, array: (1347, 7)\n",
      "name: /action, array: (1347, 7)\n",
      "name: is_edited, array: ()\n",
      "name: /observations/images/left, array: (1347, 180, 320, 3)\n",
      "name: /observations/images/right, array: (1347, 180, 320, 3)\n",
      "name: /observations/images/wrist, array: (1347, 180, 320, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 51/100 [00:09<00:08,  5.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No valid language instruction in this episode....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 53/100 [00:09<00:09,  5.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "traj_len: 605\n",
      "traj_actions shape: (605, 7)\n",
      "traj_qpos shape: (605, 7)\n",
      "traj_qvel shape: (605, 7)\n",
      "left_imgs shape: (605, 180, 320, 3)\n",
      "right_imgs shape: (605, 180, 320, 3)\n",
      "wrist_imgs shape: (605, 180, 320, 3)\n",
      "max_timesteps: 605\n",
      "==== generate h5 ======\n",
      "name: /observations/qpos, array: (605, 7)\n",
      "name: /observations/qvel, array: (605, 7)\n",
      "name: /action, array: (605, 7)\n",
      "name: is_edited, array: ()\n",
      "name: /observations/images/left, array: (605, 180, 320, 3)\n",
      "name: /observations/images/right, array: (605, 180, 320, 3)\n",
      "name: /observations/images/wrist, array: (605, 180, 320, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 54/100 [00:10<00:09,  4.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "traj_len: 388\n",
      "traj_actions shape: (388, 7)\n",
      "traj_qpos shape: (388, 7)\n",
      "traj_qvel shape: (388, 7)\n",
      "left_imgs shape: (388, 180, 320, 3)\n",
      "right_imgs shape: (388, 180, 320, 3)\n",
      "wrist_imgs shape: (388, 180, 320, 3)\n",
      "max_timesteps: 388\n",
      "==== generate h5 ======\n",
      "name: /observations/qpos, array: (388, 7)\n",
      "name: /observations/qvel, array: (388, 7)\n",
      "name: /action, array: (388, 7)\n",
      "name: is_edited, array: ()\n",
      "name: /observations/images/left, array: (388, 180, 320, 3)\n",
      "name: /observations/images/right, array: (388, 180, 320, 3)\n",
      "name: /observations/images/wrist, array: (388, 180, 320, 3)\n",
      "traj_len: 126\n",
      "traj_actions shape: (126, 7)\n",
      "traj_qpos shape: (126, 7)\n",
      "traj_qvel shape: (126, 7)\n",
      "left_imgs shape: (126, 180, 320, 3)\n",
      "right_imgs shape: (126, 180, 320, 3)\n",
      "wrist_imgs shape: (126, 180, 320, 3)\n",
      "max_timesteps: 126\n",
      "==== generate h5 ======\n",
      "name: /observations/qpos, array: (126, 7)\n",
      "name: /observations/qvel, array: (126, 7)\n",
      "name: /action, array: (126, 7)\n",
      "name: is_edited, array: ()\n",
      "name: /observations/images/left, array: (126, 180, 320, 3)\n",
      "name: /observations/images/right, array: (126, 180, 320, 3)\n",
      "name: /observations/images/wrist, array: (126, 180, 320, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 55/100 [00:10<00:09,  4.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No valid language instruction in this episode....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 57/100 [00:10<00:09,  4.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "traj_len: 602\n",
      "traj_actions shape: (602, 7)\n",
      "traj_qpos shape: (602, 7)\n",
      "traj_qvel shape: (602, 7)\n",
      "left_imgs shape: (602, 180, 320, 3)\n",
      "right_imgs shape: (602, 180, 320, 3)\n",
      "wrist_imgs shape: (602, 180, 320, 3)\n",
      "max_timesteps: 602\n",
      "==== generate h5 ======\n",
      "name: /observations/qpos, array: (602, 7)\n",
      "name: /observations/qvel, array: (602, 7)\n",
      "name: /action, array: (602, 7)\n",
      "name: is_edited, array: ()\n",
      "name: /observations/images/left, array: (602, 180, 320, 3)\n",
      "name: /observations/images/right, array: (602, 180, 320, 3)\n",
      "name: /observations/images/wrist, array: (602, 180, 320, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 58/100 [00:11<00:09,  4.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "traj_len: 304\n",
      "traj_actions shape: (304, 7)\n",
      "traj_qpos shape: (304, 7)\n",
      "traj_qvel shape: (304, 7)\n",
      "left_imgs shape: (304, 180, 320, 3)\n",
      "right_imgs shape: (304, 180, 320, 3)\n",
      "wrist_imgs shape: (304, 180, 320, 3)\n",
      "max_timesteps: 304\n",
      "==== generate h5 ======\n",
      "name: /observations/qpos, array: (304, 7)\n",
      "name: /observations/qvel, array: (304, 7)\n",
      "name: /action, array: (304, 7)\n",
      "name: is_edited, array: ()\n",
      "name: /observations/images/left, array: (304, 180, 320, 3)\n",
      "name: /observations/images/right, array: (304, 180, 320, 3)\n",
      "name: /observations/images/wrist, array: (304, 180, 320, 3)\n",
      "No valid language instruction in this episode....\n",
      "No valid language instruction in this episode....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 61/100 [00:11<00:06,  6.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "traj_len: 144\n",
      "traj_actions shape: (144, 7)\n",
      "traj_qpos shape: (144, 7)\n",
      "traj_qvel shape: (144, 7)\n",
      "left_imgs shape: (144, 180, 320, 3)\n",
      "right_imgs shape: (144, 180, 320, 3)\n",
      "wrist_imgs shape: (144, 180, 320, 3)\n",
      "max_timesteps: 144\n",
      "==== generate h5 ======\n",
      "name: /observations/qpos, array: (144, 7)\n",
      "name: /observations/qvel, array: (144, 7)\n",
      "name: /action, array: (144, 7)\n",
      "name: is_edited, array: ()\n",
      "name: /observations/images/left, array: (144, 180, 320, 3)\n",
      "name: /observations/images/right, array: (144, 180, 320, 3)\n",
      "name: /observations/images/wrist, array: (144, 180, 320, 3)\n",
      "No valid language instruction in this episode....\n",
      "No valid language instruction in this episode....\n",
      "No valid language instruction in this episode....\n",
      "No valid language instruction in this episode....\n",
      "No valid language instruction in this episode....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 67/100 [00:11<00:03, 10.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "traj_len: 140\n",
      "traj_actions shape: (140, 7)\n",
      "traj_qpos shape: (140, 7)\n",
      "traj_qvel shape: (140, 7)\n",
      "left_imgs shape: (140, 180, 320, 3)\n",
      "right_imgs shape: (140, 180, 320, 3)\n",
      "wrist_imgs shape: (140, 180, 320, 3)\n",
      "max_timesteps: 140\n",
      "==== generate h5 ======\n",
      "name: /observations/qpos, array: (140, 7)\n",
      "name: /observations/qvel, array: (140, 7)\n",
      "name: /action, array: (140, 7)\n",
      "name: is_edited, array: ()\n",
      "name: /observations/images/left, array: (140, 180, 320, 3)\n",
      "name: /observations/images/right, array: (140, 180, 320, 3)\n",
      "name: /observations/images/wrist, array: (140, 180, 320, 3)\n",
      "No valid language instruction in this episode....\n",
      "traj_len: 211\n",
      "traj_actions shape: (211, 7)\n",
      "traj_qpos shape: (211, 7)\n",
      "traj_qvel shape: (211, 7)\n",
      "left_imgs shape: (211, 180, 320, 3)\n",
      "right_imgs shape: (211, 180, 320, 3)\n",
      "wrist_imgs shape: (211, 180, 320, 3)\n",
      "max_timesteps: 211\n",
      "==== generate h5 ======\n",
      "name: /observations/qpos, array: (211, 7)\n",
      "name: /observations/qvel, array: (211, 7)\n",
      "name: /action, array: (211, 7)\n",
      "name: is_edited, array: ()\n",
      "name: /observations/images/left, array: (211, 180, 320, 3)\n",
      "name: /observations/images/right, array: (211, 180, 320, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 69/100 [00:11<00:02, 10.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: /observations/images/wrist, array: (211, 180, 320, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 71/100 [00:12<00:03,  7.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "traj_len: 401\n",
      "traj_actions shape: (401, 7)\n",
      "traj_qpos shape: (401, 7)\n",
      "traj_qvel shape: (401, 7)\n",
      "left_imgs shape: (401, 180, 320, 3)\n",
      "right_imgs shape: (401, 180, 320, 3)\n",
      "wrist_imgs shape: (401, 180, 320, 3)\n",
      "max_timesteps: 401\n",
      "==== generate h5 ======\n",
      "name: /observations/qpos, array: (401, 7)\n",
      "name: /observations/qvel, array: (401, 7)\n",
      "name: /action, array: (401, 7)\n",
      "name: is_edited, array: ()\n",
      "name: /observations/images/left, array: (401, 180, 320, 3)\n",
      "name: /observations/images/right, array: (401, 180, 320, 3)\n",
      "name: /observations/images/wrist, array: (401, 180, 320, 3)\n",
      "traj_len: 100\n",
      "traj_actions shape: (100, 7)\n",
      "traj_qpos shape: (100, 7)\n",
      "traj_qvel shape: (100, 7)\n",
      "left_imgs shape: (100, 180, 320, 3)\n",
      "right_imgs shape: (100, 180, 320, 3)\n",
      "wrist_imgs shape: (100, 180, 320, 3)\n",
      "max_timesteps: 100\n",
      "==== generate h5 ======\n",
      "name: /observations/qpos, array: (100, 7)\n",
      "name: /observations/qvel, array: (100, 7)\n",
      "name: /action, array: (100, 7)\n",
      "name: is_edited, array: ()\n",
      "name: /observations/images/left, array: (100, 180, 320, 3)\n",
      "name: /observations/images/right, array: (100, 180, 320, 3)\n",
      "name: /observations/images/wrist, array: (100, 180, 320, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 72/100 [00:12<00:04,  6.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "traj_len: 440\n",
      "traj_actions shape: (440, 7)\n",
      "traj_qpos shape: (440, 7)\n",
      "traj_qvel shape: (440, 7)\n",
      "left_imgs shape: (440, 180, 320, 3)\n",
      "right_imgs shape: (440, 180, 320, 3)\n",
      "wrist_imgs shape: (440, 180, 320, 3)\n",
      "max_timesteps: 440\n",
      "==== generate h5 ======\n",
      "name: /observations/qpos, array: (440, 7)\n",
      "name: /observations/qvel, array: (440, 7)\n",
      "name: /action, array: (440, 7)\n",
      "name: is_edited, array: ()\n",
      "name: /observations/images/left, array: (440, 180, 320, 3)\n",
      "name: /observations/images/right, array: (440, 180, 320, 3)\n",
      "name: /observations/images/wrist, array: (440, 180, 320, 3)\n",
      "No valid language instruction in this episode....\n",
      "No valid language instruction in this episode....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 75/100 [00:12<00:03,  7.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "traj_len: 167\n",
      "traj_actions shape: (167, 7)\n",
      "traj_qpos shape: (167, 7)\n",
      "traj_qvel shape: (167, 7)\n",
      "left_imgs shape: (167, 180, 320, 3)\n",
      "right_imgs shape: (167, 180, 320, 3)\n",
      "wrist_imgs shape: (167, 180, 320, 3)\n",
      "max_timesteps: 167\n",
      "==== generate h5 ======\n",
      "name: /observations/qpos, array: (167, 7)\n",
      "name: /observations/qvel, array: (167, 7)\n",
      "name: /action, array: (167, 7)\n",
      "name: is_edited, array: ()\n",
      "name: /observations/images/left, array: (167, 180, 320, 3)\n",
      "name: /observations/images/right, array: (167, 180, 320, 3)\n",
      "name: /observations/images/wrist, array: (167, 180, 320, 3)\n",
      "traj_len: 226\n",
      "traj_actions shape: (226, 7)\n",
      "traj_qpos shape: (226, 7)\n",
      "traj_qvel shape: (226, 7)\n",
      "left_imgs shape: (226, 180, 320, 3)\n",
      "right_imgs shape: (226, 180, 320, 3)\n",
      "wrist_imgs shape: (226, 180, 320, 3)\n",
      "max_timesteps: 226\n",
      "==== generate h5 ======\n",
      "name: /observations/qpos, array: (226, 7)\n",
      "name: /observations/qvel, array: (226, 7)\n",
      "name: /action, array: (226, 7)\n",
      "name: is_edited, array: ()\n",
      "name: /observations/images/left, array: (226, 180, 320, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 78/100 [00:13<00:02,  8.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: /observations/images/right, array: (226, 180, 320, 3)\n",
      "name: /observations/images/wrist, array: (226, 180, 320, 3)\n",
      "No valid language instruction in this episode....\n",
      "traj_len: 100\n",
      "traj_actions shape: (100, 7)\n",
      "traj_qpos shape: (100, 7)\n",
      "traj_qvel shape: (100, 7)\n",
      "left_imgs shape: (100, 180, 320, 3)\n",
      "right_imgs shape: (100, 180, 320, 3)\n",
      "wrist_imgs shape: (100, 180, 320, 3)\n",
      "max_timesteps: 100\n",
      "==== generate h5 ======\n",
      "name: /observations/qpos, array: (100, 7)\n",
      "name: /observations/qvel, array: (100, 7)\n",
      "name: /action, array: (100, 7)\n",
      "name: is_edited, array: ()\n",
      "name: /observations/images/left, array: (100, 180, 320, 3)\n",
      "name: /observations/images/right, array: (100, 180, 320, 3)\n",
      "name: /observations/images/wrist, array: (100, 180, 320, 3)\n",
      "No valid language instruction in this episode....\n",
      "No valid language instruction in this episode....\n",
      "No valid language instruction in this episode....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 88/100 [00:13<00:00, 16.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "traj_len: 304\n",
      "traj_actions shape: (304, 7)\n",
      "traj_qpos shape: (304, 7)\n",
      "traj_qvel shape: (304, 7)\n",
      "left_imgs shape: (304, 180, 320, 3)\n",
      "right_imgs shape: (304, 180, 320, 3)\n",
      "wrist_imgs shape: (304, 180, 320, 3)\n",
      "max_timesteps: 304\n",
      "==== generate h5 ======\n",
      "name: /observations/qpos, array: (304, 7)\n",
      "name: /observations/qvel, array: (304, 7)\n",
      "name: /action, array: (304, 7)\n",
      "name: is_edited, array: ()\n",
      "name: /observations/images/left, array: (304, 180, 320, 3)\n",
      "name: /observations/images/right, array: (304, 180, 320, 3)\n",
      "name: /observations/images/wrist, array: (304, 180, 320, 3)\n",
      "No valid language instruction in this episode....\n",
      "No valid language instruction in this episode....\n",
      "No valid language instruction in this episode....\n",
      "No valid language instruction in this episode....\n",
      "No valid language instruction in this episode....\n",
      "No valid language instruction in this episode....\n",
      "No valid language instruction in this episode....\n",
      "traj_len: 186\n",
      "traj_actions shape: (186, 7)\n",
      "traj_qpos shape: (186, 7)\n",
      "traj_qvel shape: (186, 7)\n",
      "left_imgs shape: (186, 180, 320, 3)\n",
      "right_imgs shape: (186, 180, 320, 3)\n",
      "wrist_imgs shape: (186, 180, 320, 3)\n",
      "max_timesteps: 186\n",
      "==== generate h5 ======\n",
      "name: /observations/qpos, array: (186, 7)\n",
      "name: /observations/qvel, array: (186, 7)\n",
      "name: /action, array: (186, 7)\n",
      "name: is_edited, array: ()\n",
      "name: /observations/images/left, array: (186, 180, 320, 3)\n",
      "name: /observations/images/right, array: (186, 180, 320, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 91/100 [00:13<00:00, 14.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: /observations/images/wrist, array: (186, 180, 320, 3)\n",
      "No valid language instruction in this episode....\n",
      "traj_len: 100\n",
      "traj_actions shape: (100, 7)\n",
      "traj_qpos shape: (100, 7)\n",
      "traj_qvel shape: (100, 7)\n",
      "left_imgs shape: (100, 180, 320, 3)\n",
      "right_imgs shape: (100, 180, 320, 3)\n",
      "wrist_imgs shape: (100, 180, 320, 3)\n",
      "max_timesteps: 100\n",
      "==== generate h5 ======\n",
      "name: /observations/qpos, array: (100, 7)\n",
      "name: /observations/qvel, array: (100, 7)\n",
      "name: /action, array: (100, 7)\n",
      "name: is_edited, array: ()\n",
      "name: /observations/images/left, array: (100, 180, 320, 3)\n",
      "name: /observations/images/right, array: (100, 180, 320, 3)\n",
      "name: /observations/images/wrist, array: (100, 180, 320, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 93/100 [00:14<00:00, 12.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "traj_len: 125\n",
      "traj_actions shape: (125, 7)\n",
      "traj_qpos shape: (125, 7)\n",
      "traj_qvel shape: (125, 7)\n",
      "left_imgs shape: (125, 180, 320, 3)\n",
      "right_imgs shape: (125, 180, 320, 3)\n",
      "wrist_imgs shape: (125, 180, 320, 3)\n",
      "max_timesteps: 125\n",
      "==== generate h5 ======\n",
      "name: /observations/qpos, array: (125, 7)\n",
      "name: /observations/qvel, array: (125, 7)\n",
      "name: /action, array: (125, 7)\n",
      "name: is_edited, array: ()\n",
      "name: /observations/images/left, array: (125, 180, 320, 3)\n",
      "name: /observations/images/right, array: (125, 180, 320, 3)\n",
      "name: /observations/images/wrist, array: (125, 180, 320, 3)\n",
      "traj_len: 210\n",
      "traj_actions shape: (210, 7)\n",
      "traj_qpos shape: (210, 7)\n",
      "traj_qvel shape: (210, 7)\n",
      "left_imgs shape: (210, 180, 320, 3)\n",
      "right_imgs shape: (210, 180, 320, 3)\n",
      "wrist_imgs shape: (210, 180, 320, 3)\n",
      "max_timesteps: 210\n",
      "==== generate h5 ======\n",
      "name: /observations/qpos, array: (210, 7)\n",
      "name: /observations/qvel, array: (210, 7)\n",
      "name: /action, array: (210, 7)\n",
      "name: is_edited, array: ()\n",
      "name: /observations/images/left, array: (210, 180, 320, 3)\n",
      "name: /observations/images/right, array: (210, 180, 320, 3)\n",
      "name: /observations/images/wrist, array: (210, 180, 320, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 95/100 [00:14<00:00, 12.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No valid language instruction in this episode....\n",
      "No valid language instruction in this episode....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 97/100 [00:14<00:00,  9.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "traj_len: 337\n",
      "traj_actions shape: (337, 7)\n",
      "traj_qpos shape: (337, 7)\n",
      "traj_qvel shape: (337, 7)\n",
      "left_imgs shape: (337, 180, 320, 3)\n",
      "right_imgs shape: (337, 180, 320, 3)\n",
      "wrist_imgs shape: (337, 180, 320, 3)\n",
      "max_timesteps: 337\n",
      "==== generate h5 ======\n",
      "name: /observations/qpos, array: (337, 7)\n",
      "name: /observations/qvel, array: (337, 7)\n",
      "name: /action, array: (337, 7)\n",
      "name: is_edited, array: ()\n",
      "name: /observations/images/left, array: (337, 180, 320, 3)\n",
      "name: /observations/images/right, array: (337, 180, 320, 3)\n",
      "name: /observations/images/wrist, array: (337, 180, 320, 3)\n",
      "traj_len: 577\n",
      "traj_actions shape: (577, 7)\n",
      "traj_qpos shape: (577, 7)\n",
      "traj_qvel shape: (577, 7)\n",
      "left_imgs shape: (577, 180, 320, 3)\n",
      "right_imgs shape: (577, 180, 320, 3)\n",
      "wrist_imgs shape: (577, 180, 320, 3)\n",
      "max_timesteps: 577\n",
      "==== generate h5 ======\n",
      "name: /observations/qpos, array: (577, 7)\n",
      "name: /observations/qvel, array: (577, 7)\n",
      "name: /action, array: (577, 7)\n",
      "name: is_edited, array: ()\n",
      "name: /observations/images/left, array: (577, 180, 320, 3)\n",
      "name: /observations/images/right, array: (577, 180, 320, 3)\n",
      "name: /observations/images/wrist, array: (577, 180, 320, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 99/100 [00:16<00:00,  3.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "traj_len: 1120\n",
      "traj_actions shape: (1120, 7)\n",
      "traj_qpos shape: (1120, 7)\n",
      "traj_qvel shape: (1120, 7)\n",
      "left_imgs shape: (1120, 180, 320, 3)\n",
      "right_imgs shape: (1120, 180, 320, 3)\n",
      "wrist_imgs shape: (1120, 180, 320, 3)\n",
      "max_timesteps: 1120\n",
      "==== generate h5 ======\n",
      "name: /observations/qpos, array: (1120, 7)\n",
      "name: /observations/qvel, array: (1120, 7)\n",
      "name: /action, array: (1120, 7)\n",
      "name: is_edited, array: ()\n",
      "name: /observations/images/left, array: (1120, 180, 320, 3)\n",
      "name: /observations/images/right, array: (1120, 180, 320, 3)\n",
      "name: /observations/images/wrist, array: (1120, 180, 320, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:16<00:00,  6.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No valid language instruction in this episode....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import itertools  # 반복문과 조합 관련 유틸리티\n",
    "import os  # 운영체제 파일 경로 등 처리\n",
    "import os.path as osp  # 경로(join, split 등) 처리 단축\n",
    "import time  # 시간 측정 및 대기\n",
    "from collections import OrderedDict, defaultdict  # 순서 있는 dict, 기본값 딕셔너리\n",
    "from datetime import datetime  # 날짜/시간 객체\n",
    "from tqdm import tqdm  # 진행 바 표시\n",
    "\n",
    "import h5py  # HDF5 파일 입출력\n",
    "\n",
    "import torch  # PyTorch 텐서 연산\n",
    "import collections  # 컬렉션 관련 타입\n",
    "import tensorflow_datasets as tfds  # TFDS 데이터셋 로드\n",
    "import numpy as np  # 수치 연산\n",
    "import tkinter as tk  # 간단한 GUI (언어 입력 등)\n",
    "from tkinter import simpledialog  # 간단한 입력 다이얼로그\n",
    "from PIL import Image, ImageTk  # 이미지 처리 및 표시\n",
    "import argparse  # 명령행 인자 파싱\n",
    "\n",
    "from IPython.display import display, Image as IPyImage\n",
    "def get_image_list_np(img_rgb_dir_path, remove_index_list):\n",
    "    \"\"\"\n",
    "    지정한 디렉토리에서 RGB 이미지 파일 목록을 불러와 numpy 배열로 반환합니다.\n",
    "    remove_index_list에 포함된 인덱스는 건너뜁니다.\n",
    "    \"\"\"\n",
    "    cur_camera_rgb_list = []  # 개별 프레임 저장할 리스트\n",
    "    img_name_list = os.listdir(img_rgb_dir_path)  # 디렉토리 내 파일 이름 목록\n",
    "    img_name_list = sorted(img_name_list)  # 정렬하여 순서 보장\n",
    "\n",
    "    for idx, img_name in enumerate(img_name_list):  # 각 이미지 파일에 대해\n",
    "        if idx in remove_index_list:  # 제거할 인덱스면 건너뜀\n",
    "            continue\n",
    "\n",
    "        img_path = os.path.join(img_rgb_dir_path, img_name)  # 전체 경로 생성\n",
    "\n",
    "        # (w 640, h 480)\n",
    "        img_frame = Image.open(img_path).convert('RGB')  # PIL로 열어 RGB로 변환\n",
    "        img_np = np.array(img_frame)  # numpy 배열로 변환 (H,W,3)\n",
    "        cur_camera_rgb_list.append(img_np)  # 리스트에 추가\n",
    "\n",
    "    cur_camera_rgb_np = np.array(cur_camera_rgb_list)  # 전체 시퀀스 배열화\n",
    "    print('+++++++++++++++')\n",
    "    print(f\"img_rgb_dir_path: {img_rgb_dir_path}\")  # 경로 정보 출력\n",
    "    print(f'cur_camera_rgb_np size: {cur_camera_rgb_np.shape}')  # 배열 크기 출력\n",
    "\n",
    "    return cur_camera_rgb_np  # 반환\n",
    "\n",
    "\n",
    "def plot_smooth_action(traj_act_xyz_np, fig_name):\n",
    "    \"\"\"\n",
    "    예측된 행동 값(x,y,z)에 대해 부드러운 플롯을 그리고 저장합니다.\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt  # 플롯용 라이브러리\n",
    "    plt.figure(figsize=(12, 4))  # 도표 크기 설정\n",
    "    figure_name = [\"x\", \"y\", \"z\"]  # 축 라벨\n",
    "    for i in range(3):  # 각 축별로 subplot 생성\n",
    "        plt.subplot(1, 3, i + 1)\n",
    "        plt.plot(range(traj_act_xyz_np.shape[0]), traj_act_xyz_np[:, i], label='cur_action')  # 선 그래프\n",
    "        plt.title(figure_name[i])  # 제목 설정\n",
    "        plt.legend()  # 범례 표시\n",
    "    plt.suptitle(f\"Differences between predicted and target actions_traj\")  # 전체 제목\n",
    "    plt.tight_layout()  # 레이아웃 자동 조정\n",
    "\n",
    "    work_dir = '/home/parkjeongsu/TinyVLA_pre/droid_traj'  # 저장 디렉토리 기본 경로\n",
    "    figure_dir_path = os.path.join(work_dir, f\"smooth_action_results\")  # 하위 폴더 경로\n",
    "    os.makedirs(figure_dir_path, exist_ok=True)  # 디렉토리 생성(이미 있으면 무시)\n",
    "    figure_path = os.path.join(figure_dir_path, f\"{fig_name}.png\")  # 파일 경로\n",
    "    plt.savefig(figure_path)  # 이미지 저장\n",
    "    plt.clf()  # 현재 figure 초기화\n",
    "\n",
    "\n",
    "def print_h5_structure(group, indent=0):\n",
    "    \"\"\"\n",
    "    HDF5 파일 그룹 구조를 재귀적으로 출력합니다.\n",
    "    \"\"\"\n",
    "    for name in group:\n",
    "        item = group[name]\n",
    "        print(\" \" * indent + f\"name: {name}\")\n",
    "        if isinstance(item, h5py.Group):  # 그룹일 경우\n",
    "            print(\" \" * indent + f\"Group: {name}\")\n",
    "            print_h5_structure(item, indent + 2)  # 재귀 호출\n",
    "        elif isinstance(item, h5py.Dataset):  # 데이터셋일 경우\n",
    "            print(\" \" * indent + f\"Dataset: {name} (Shape: {item.shape}, Dtype: {item.dtype})\")\n",
    "        else:\n",
    "            print(\" \" * indent + f\"Unknown item: {name}\")\n",
    "\n",
    "\n",
    "def print_dict_structure(cur_dict, indent=0):\n",
    "    \"\"\"\n",
    "    Python dict 구조를 재귀적으로 출력합니다.\n",
    "    \"\"\"\n",
    "    for name in cur_dict.keys():\n",
    "        item = cur_dict[name]\n",
    "        print(\" \" * indent + f\"name: {name}\")\n",
    "        if isinstance(item, dict):\n",
    "            print(\" \" * indent + f\"Dict: {name}\")\n",
    "            print_dict_structure(item, indent + 2)\n",
    "        elif isinstance(item, np.ndarray):\n",
    "            print(\" \" * indent + f\"Array: {name} (Shape: {item.shape}, Dtype: {item.dtype})\")\n",
    "        else:\n",
    "            print(\" \" * indent + f\"Unknown item: {name}\")\n",
    "\n",
    "\n",
    "def to_numpy(x):\n",
    "    \"\"\"\n",
    "    중첩된 torch.Tensor를 재귀적으로 numpy 배열로 변환합니다.\n",
    "    \"\"\"\n",
    "    def f(tensor):\n",
    "        if tensor.is_cuda:\n",
    "            return tensor.detach().cpu().numpy()\n",
    "        else:\n",
    "            return tensor.detach().numpy()\n",
    "\n",
    "    return recursive_dict_list_tuple_apply(\n",
    "        x,\n",
    "        {\n",
    "            torch.Tensor: f,\n",
    "            np.ndarray: lambda x: x,\n",
    "            type(None): lambda x: x,\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "def recursive_dict_list_tuple_apply(x, type_func_dict):\n",
    "    \"\"\"\n",
    "    중첩된 dict/list/tuple 내부 요소에 주어진 함수를 적용합니다.\n",
    "    \"\"\"\n",
    "    assert (list not in type_func_dict)\n",
    "    assert (tuple not in type_func_dict)\n",
    "    assert (dict not in type_func_dict)\n",
    "\n",
    "    if isinstance(x, (dict, collections.OrderedDict)):\n",
    "        new_x = collections.OrderedDict() if isinstance(x, collections.OrderedDict) else dict()\n",
    "        for k, v in x.items():\n",
    "            new_x[k] = recursive_dict_list_tuple_apply(v, type_func_dict)\n",
    "        return new_x\n",
    "    elif isinstance(x, (list, tuple)):\n",
    "        ret = [recursive_dict_list_tuple_apply(v, type_func_dict) for v in x]\n",
    "        return tuple(ret) if isinstance(x, tuple) else ret\n",
    "    else:\n",
    "        for t, f in type_func_dict.items():\n",
    "            if isinstance(x, t):\n",
    "                return f(x)\n",
    "        return x  # 그 외 타입은 그대로 반환\n",
    "\n",
    "\n",
    "def matrix_to_rotation_6d(matrix: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    3x3 회전 행렬을 6D 표현으로 변환합니다 (첫 두 열 사용).\n",
    "    \"\"\"\n",
    "    batch_dim = matrix.size()[:-2]\n",
    "    return matrix[..., :2, :].clone().reshape(batch_dim + (6,))\n",
    "\n",
    "\n",
    "def euler_angles_to_rot_6d(euler_angles, convention=\"XYZ\"):\n",
    "    \"\"\"\n",
    "    Euler 각도를 6D 회전 표현으로 변환합니다.\n",
    "    \"\"\"\n",
    "    rot_mat = euler_angles_to_matrix(euler_angles, convention=\"XYZ\")\n",
    "    return matrix_to_rotation_6d(rot_mat)\n",
    "\n",
    "\n",
    "def _axis_angle_rotation(axis: str, angle: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    X/Y/Z 축을 기준으로 회전 행렬을 생성합니다.\n",
    "    \"\"\"\n",
    "    cos = torch.cos(angle)\n",
    "    sin = torch.sin(angle)\n",
    "    one = torch.ones_like(angle)\n",
    "    zero = torch.zeros_like(angle)\n",
    "\n",
    "    if axis == \"X\":\n",
    "        R_flat = (one, zero, zero, zero, cos, -sin, zero, sin, cos)\n",
    "    elif axis == \"Y\":\n",
    "        R_flat = (cos, zero, sin, zero, one, zero, -sin, zero, cos)\n",
    "    elif axis == \"Z\":\n",
    "        R_flat = (cos, -sin, zero, sin, cos, zero, zero, zero, one)\n",
    "    else:\n",
    "        raise ValueError(\"letter must be either X, Y or Z.\")\n",
    "\n",
    "    return torch.stack(R_flat, -1).reshape(angle.shape + (3, 3))\n",
    "\n",
    "\n",
    "def euler_angles_to_matrix(euler_angles: torch.Tensor, convention: str) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Euler 각도를 3x3 회전 행렬로 변환합니다.\n",
    "    \"\"\"\n",
    "    if euler_angles.dim() == 0 or euler_angles.shape[-1] != 3:\n",
    "        raise ValueError(\"Invalid input euler angles.\")\n",
    "    if len(convention) != 3:\n",
    "        raise ValueError(\"Convention must have 3 letters.\")\n",
    "    if convention[1] in (convention[0], convention[2]):\n",
    "        raise ValueError(f\"Invalid convention {convention}.\")\n",
    "    for letter in convention:\n",
    "        if letter not in (\"X\", \"Y\", \"Z\"):\n",
    "            raise ValueError(f\"Invalid letter {letter} in convention string.\")\n",
    "    matrices = [\n",
    "        _axis_angle_rotation(c, e) for c, e in zip(convention, torch.unbind(euler_angles, -1))\n",
    "    ]\n",
    "    return torch.matmul(torch.matmul(matrices[0], matrices[1]), matrices[2])\n",
    "\n",
    "\n",
    "def convert_h5py2np_dict(group, state_np_dict, indent=0):\n",
    "    \"\"\"\n",
    "    HDF5 그룹을 순회하며 numpy dict로 변환하고 구조 출력합니다.\n",
    "    \"\"\"\n",
    "    for name in group:\n",
    "        item = group[name]\n",
    "        print(\" \" * indent + f\"name: {name}\")\n",
    "        if isinstance(item, h5py.Group):\n",
    "            state_np_dict[name] = {}\n",
    "            convert_h5py2np_dict(item, state_np_dict[name], indent + 2)\n",
    "        elif isinstance(item, h5py.Dataset):\n",
    "            state_np_dict[name] = item[...]\n",
    "            print(\" \" * indent + f\"Dataset: {name} (Shape: {item.shape}, Dtype: {item.dtype})\")\n",
    "        else:\n",
    "            state_np_dict[name] = item\n",
    "\n",
    "\n",
    "def print_name(name):\n",
    "    \"\"\"단순히 이름을 출력\"\"\"\n",
    "    print(name)\n",
    "\n",
    "def generate_h5(obs_replay, action_replay, cfg, total_traj_cnt, act_root_dir_path, edit_flag):\n",
    "    \"\"\"\n",
    "    주어진 관측(obs_replay)과 행동(action_replay)을 이용해 HDF5 파일로 저장합니다.\n",
    "    - obs_replay: {'qpos', 'qvel', 'images': {cam1, cam2, ...}}\n",
    "    - cfg: 카메라 이름, 이미지 크기, 상태/행동 차원, 언어 지시문 등 설정\n",
    "    \"\"\"\n",
    "    data_dict = {\n",
    "        '/observations/qpos': obs_replay['qpos'],  # 위치 정보\n",
    "        '/observations/qvel': obs_replay['qvel'],  # 속도 정보\n",
    "        '/action': action_replay,  # 행동 벡터\n",
    "        'is_edited': np.array(edit_flag)  # 편집 플래그\n",
    "    }\n",
    "    # 이미지 데이터 추가\n",
    "    for cam_name in cfg['camera_names']:\n",
    "        data_dict[f'/observations/images/{cam_name}'] = obs_replay['images'][cam_name]\n",
    "\n",
    "    max_timesteps = len(data_dict['/observations/qpos'])\n",
    "    print(f'max_timesteps: {max_timesteps}')\n",
    "\n",
    "    data_dir = act_root_dir_path  # 저장 디렉토리\n",
    "    dataset_path = os.path.join(data_dir, f'episode_{total_traj_cnt}')\n",
    "    with h5py.File(dataset_path + '.hdf5', 'w', rdcc_nbytes=1024**2*2) as root:\n",
    "        root.attrs['sim'] = True  # 시뮬레이션 메타데이터\n",
    "        obs = root.create_group('observations')\n",
    "        image = obs.create_group('images')\n",
    "        # 카메라별 이미지 데이터셋 생성\n",
    "        for cam_name in cfg['camera_names']:\n",
    "            image.create_dataset(cam_name,\n",
    "                (max_timesteps, cfg['cam_height'], cfg['cam_width'], 3),\n",
    "                dtype='uint8', chunks=(1, cfg['cam_height'], cfg['cam_width'], 3))\n",
    "        # 상태 데이터셋 생성\n",
    "        obs.create_dataset('qpos', (max_timesteps, cfg['state_dim']))\n",
    "        obs.create_dataset('qvel', (max_timesteps, cfg['state_dim']))\n",
    "        # 행동 데이터셋 생성\n",
    "        root.create_dataset('action', (max_timesteps, cfg['action_dim']))\n",
    "        root.create_dataset('is_edited', (1,))\n",
    "        # 언어 지시문 저장\n",
    "        root.create_dataset(\"language_raw\", data=[cfg['lang_intrs']])\n",
    "\n",
    "        print(f'==== generate h5 ======')\n",
    "        # 실제 데이터 쓰기\n",
    "        for name, array in data_dict.items():\n",
    "            print(f\"name: {name}, array: {array.shape}\")\n",
    "            root[name][...] = array\n",
    "\n",
    "user_input = None  # GUI 입력용 전역 변수\n",
    "\n",
    "def show_gif(images):\n",
    "    \"\"\"이미지 리스트를 GIF로 저장하여 보여줍니다.\"\"\"\n",
    "    # 폴더 + 파일명(.gif)로 저장 경로 지정\n",
    "    path = os.path.join('/home/parkjeongsu/TinyVLA_pre/droid_image', 'result.gif')\n",
    "    images[0].save(path, save_all=True, append_images=images[1:], duration=int(1000/15), loop=0)\n",
    "    display(IPyImage(filename=path))\n",
    "\n",
    "\n",
    "# Jupyter 환경에선 argparse 대신 직접 지정\n",
    "# ✅ 사용자 정의 설정 (Jupyter용 경로)\n",
    "class Args:\n",
    "    pass\n",
    "\n",
    "args = Args()\n",
    "args.src_root = \"/home/parkjeongsu/TinyVLA/Droid\"  # ✅ TFDS 경로\n",
    "args.name = \"droid_100\"  # ✅ TFDS 데이터셋 이름\n",
    "\n",
    "# ✅ HDF5 저장 경로 구성\n",
    "task_name = \"droid_1dot7t_lang\"\n",
    "act_target_root = os.path.join(args.src_root, \"droid_with_lang\")\n",
    "os.makedirs(act_target_root, exist_ok=True)\n",
    "\n",
    "# ✅ 서브디렉토리명: smoothing 정보 포함\n",
    "act_root_dir_name = f\"{task_name}_succ_t0001_s-0-0\"\n",
    "act_root_dir_path = os.path.join(act_target_root, act_root_dir_name)\n",
    "os.makedirs(act_root_dir_path, exist_ok=True)\n",
    "\n",
    "\n",
    "# ✅ cfg 설정 (저장 파라미터 포함)\n",
    "cfg = {\n",
    "    \"task_name\": task_name,\n",
    "    \"camera_names\": [\"left\", \"right\", \"wrist\"],  # ✅ wrist 포함\n",
    "    \"dataset_dir\": act_target_root,\n",
    "    \"cam_height\": 180,\n",
    "    \"cam_width\": 320,\n",
    "    \"state_dim\": 7,\n",
    "    \"action_dim\": 7,  # ✅ rot6D 제거로 7차원 사용\n",
    "    \"lang_intrs\": \"close the lid of the box\",\n",
    "}\n",
    "# ✅ TFDS 로드\n",
    "print(\"Loading TFDS dataset...\")\n",
    "ds = tfds.load(args.name, data_dir=args.src_root, split=\"train\")\n",
    "\n",
    "# ✅ 경로 확인 출력\n",
    "print(\"✅ TFDS 경로:\", os.path.join(args.src_root, args.name))\n",
    "print(\"✅ 저장 경로:\", act_root_dir_path)\n",
    "\n",
    "raw_lang = cfg['lang_intrs']  # 원시 언어 지시문\n",
    "print('raw_lang:', raw_lang)\n",
    "\n",
    "#parser = argparse.ArgumentParser()  # 명령행 파서 생성\n",
    "#parser.add_argument(\"/home/parkjeongsu/TinyVLA_pre/Droid\", default='/media/rl/PSSD-6')  # TFDS 루트 경로 : parser.add_argument(\"--src_root\", default='/media/rl/PSSD-6')\n",
    "#parser.add_argument(\"/home/parkjeongsu/TinyVLA_pre/Droid/droid_100\", default=\"droid\")  # 데이터셋 이름\n",
    "#args = parser.parse_args()\n",
    "\n",
    "# 출력 디렉토리 생성\n",
    "act_target_root = os.path.join(args.src_root, \"droid_with_lang\")\n",
    "os.makedirs(act_target_root, exist_ok=True)\n",
    "\n",
    "smooth_action = False  # 부드러운 행동 처리 여부\n",
    "smooth_order = 0  # 부드러운 순서\n",
    "smooth_window_size = 0  # 부드러운 윈도우 크기\n",
    "\n",
    "framework = 'droid'  # 프레임워크 종류\n",
    "act_pos_thres = 0.001  # 행동 임계값\n",
    "\n",
    "# 저장 경로 설정\n",
    "act_root_dir_name = f'{cfg[\"task_name\"]}_succ_t0001_s-0-0'\n",
    "act_root_dir_path = os.path.join(act_target_root, act_root_dir_name)\n",
    "os.makedirs(act_root_dir_path, exist_ok=True)\n",
    "\n",
    "# tfds 데이터셋 로드\n",
    "ds = tfds.load(args.name, data_dir=args.src_root, split=\"train\")\n",
    "\n",
    "# TFDS 로드 및 HDF5 변환 루프\n",
    "\n",
    "# 카메라 이름과 이미지 파일명을 매핑하기 위한 빈 딕셔너리 초기화\n",
    "IMAGE_NAME_TO_CAM_KEY_MAPPING = dict()\n",
    "\n",
    "# 성공/실패 및 전체 트래젝토리 카운트를 저장할 변수 초기화\n",
    "succ_traj_count = 0    # 성공한 에피소드 수\n",
    "fail_traj_count = 0    # 실패한 에피소드 수\n",
    "total_traj_cnt = 0     # 전체 처리한 에피소드 수\n",
    "\n",
    "# 액션 값의 최대/최소, 정규화 통계, 전체 상태 딕셔너리 초기화\n",
    "max_action_np = None                      # 액션 데이터 중 최대값 저장용\n",
    "min_action_np = None                      # 액션 데이터 중 최소값 저장용\n",
    "data_normalize_stats = dict()             # 정규화 통계(평균·표준편차 등) 저장용\n",
    "all_traj_state_total_np_dict = dict()     # 모든 트래젝토리 상태 데이터를 모아둘 딕셔너리\n",
    "\n",
    "# TFDS 데이터셋 로드 (droid 이름, 로컬 경로, train 분할)\n",
    "ds = tfds.load(args.name, data_dir=args.src_root, split=\"train\")\n",
    "\n",
    "# 각 에피소드를 순회하며 HDF5로 변환\n",
    "for episode in tqdm(ds):\n",
    "    if os.path.exists(os.path.join(act_root_dir_path, f'episode_{total_traj_cnt}.hdf5')):\n",
    "        total_traj_cnt += 1\n",
    "        continue\n",
    "\n",
    "    state_total_np_dict = dict()\n",
    "    cur_actions = []\n",
    "    cur_obs_image = {'1': [], '2': [], 'wrist': []}\n",
    "    cur_obs_gripper_pos = []\n",
    "    cur_obs_joint_state = []\n",
    "    cur_obs_cartesian_position = []\n",
    "    raw_lang = \"\"\n",
    "    cur_actions_dict = {}\n",
    "    edit_flag = 0\n",
    "\n",
    "    for idx, step in enumerate(episode['steps']):\n",
    "        lang1 = step['language_instruction'].numpy().decode('utf-8').strip()\n",
    "        lang2 = step['language_instruction_2'].numpy().decode('utf-8').strip()\n",
    "        lang3 = step['language_instruction_3'].numpy().decode('utf-8').strip()\n",
    "\n",
    "        if all(len(lang) < 4 for lang in [lang1, lang2, lang3]):\n",
    "            print(\"No valid language instruction in this episode....\")\n",
    "            edit_flag = 1\n",
    "            break  # ✅ 모든 스텝이 이럴 가능성 고려해서 break 추가\n",
    "        else:\n",
    "            # ✅ 언어 선택은 한 번만 하면 되므로, idx==0에서만 수행\n",
    "            if idx == 0:\n",
    "                raw_lang = lang1 if len(lang1) >= 4 else (lang2 if len(lang2) >= 4 else lang3)\n",
    "\n",
    "    # 🔽 전체 에피소드 스킵 조건\n",
    "    if edit_flag == 1:\n",
    "        total_traj_cnt += 1\n",
    "        continue\n",
    "\n",
    "\n",
    "    # 🔽 3. 실제 step 처리 루프\n",
    "    for idx, step in enumerate(episode['steps']):\n",
    "        if idx == 0:\n",
    "            cur_actions_dict = {k: [] for k in step['action_dict'].keys()}\n",
    "\n",
    "        cur_actions.append(step['action'].numpy())\n",
    "        cur_obs_image['1'].append(step['observation']['exterior_image_1_left'].numpy())\n",
    "        cur_obs_image['2'].append(step['observation']['exterior_image_2_left'].numpy())\n",
    "        cur_obs_image['wrist'].append(step['observation']['wrist_image_left'].numpy())\n",
    "        cur_obs_gripper_pos.append(step['observation']['gripper_position'].numpy())\n",
    "        cur_obs_joint_state.append(step['observation']['joint_position'].numpy())\n",
    "        raw_lang = step['language_instruction'].numpy().decode('utf-8')\n",
    "        cur_obs_cartesian_position.append(step['observation']['cartesian_position'].numpy())\n",
    "\n",
    "        for k, v in cur_actions_dict.items():\n",
    "            cur_actions_dict[k].append(step['action_dict'][k].numpy())\n",
    "\n",
    "    if idx == 0 or edit_flag == 1:\n",
    "        all_images_np = np.concatenate((np.array(cur_obs_image['1']), np.array(cur_obs_image['2'])), axis=2)\n",
    "        all_images = [Image.fromarray(each) for each in all_images_np]\n",
    "        show_gif(all_images)\n",
    "        raw_lang = input(\"please write a language instruction:\")\n",
    "        print(f\"Your input: {raw_lang}\")\n",
    "\n",
    "    cur_obs_image = {k: np.array(v) for k, v in cur_obs_image.items()}\n",
    "    cur_obs_cartesian_position = torch.from_numpy(np.array(cur_obs_cartesian_position))\n",
    "\n",
    "    state_total_np_dict['obs_cartesian_position'] = cur_obs_cartesian_position\n",
    "    state_total_np_dict['obs_gripper_position'] = torch.from_numpy(np.array(cur_obs_gripper_pos))\n",
    "    state_total_np_dict['obs_joint_positions'] = torch.from_numpy(np.array(cur_obs_joint_state))\n",
    "\n",
    "    traj_len = min(len(cur_obs_image['1']), len(cur_obs_image['2']), len(cur_obs_image['wrist']))\n",
    "    print(f'traj_len: {traj_len}')\n",
    "\n",
    "    traj_actions = np.array(cur_actions)[:traj_len]  # ✅ 그대로 사용\n",
    "    print(f\"traj_actions shape: {traj_actions.shape}\")\n",
    "\n",
    "    traj_qpos = np.concatenate((state_total_np_dict['obs_cartesian_position'], state_total_np_dict['obs_gripper_position']), axis=-1)[:traj_len]\n",
    "    traj_qvel = np.zeros_like(traj_qpos)\n",
    "    print(f\"traj_qpos shape: {traj_qpos.shape}\")\n",
    "    print(f\"traj_qvel shape: {traj_qvel.shape}\")\n",
    "\n",
    "    left_imgs = cur_obs_image['1'][:traj_len]\n",
    "    right_imgs = cur_obs_image['2'][:traj_len]\n",
    "    wrist_imgs = cur_obs_image['wrist'][:traj_len]  # ✅ wrist\n",
    "    print(f\"left_imgs shape: {left_imgs.shape}\")\n",
    "    print(f\"right_imgs shape: {right_imgs.shape}\")\n",
    "    print(f\"wrist_imgs shape: {wrist_imgs.shape}\")\n",
    "\n",
    "    obs_replay = {\n",
    "        'qpos': traj_qpos,\n",
    "        'qvel': traj_qvel,\n",
    "        'images': {\n",
    "            'left': left_imgs,\n",
    "            'right': right_imgs,\n",
    "            'wrist': wrist_imgs  # ✅ wrist 포함\n",
    "        }\n",
    "    }\n",
    "    cfg['lang_intrs'] = raw_lang\n",
    "    generate_h5(obs_replay, traj_actions, cfg, total_traj_cnt, act_root_dir_path, edit_flag)\n",
    "    total_traj_cnt += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a466538",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tiny_data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
